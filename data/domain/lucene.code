1	public Arc<T> getFirstArc(Arc<T> arc) {\n    T NO_OUTPUT = outputs.getNoOutput();\n\n    if (emptyOutput != null) {\n      arc.flags = BIT_FINAL_ARC | BIT_LAST_ARC;\n      arc.nextFinalOutput = emptyOutput;\n      if (emptyOutput != NO_OUTPUT) {\n        arc.flags |= BIT_ARC_HAS_FINAL_OUTPUT;\n      }\n    } else {\n      arc.flags = BIT_LAST_ARC;\n      arc.nextFinalOutput = NO_OUTPUT;\n    }\n    arc.output = NO_OUTPUT;\n\n            arc.target = startNode;\n    return arc;\n  }
2	public void add(BytesRef utf8, int bucket) throws IOException {\n    if (bucket < 0 || bucket >= buckets) {\n      throw new IllegalArgumentException(\n          "Bucket outside of the allowed range [0, " + buckets + "): " + bucket);\n    }\n    \n    scratch.grow(utf8.length + 10);\n    scratch.clear();\n    scratch.append((byte) bucket);\n    scratch.append(utf8);\n    sorter.add(scratch.get());\n  }
3	Map<BytesRef, Spans> getTermToSpans(LeafReader leafReader, int doc)\n      throws IOException {\n    if (spanQueries.isEmpty()) {\n      return Collections.emptyMap();\n    }\n    final LeafReader filteredReader = new SingleFieldFilterLeafReader(leafReader, fieldName);\n        Map<BytesRef, Spans> result = new HashMap<>();\n    for (SpanQuery spanQuery : spanQueries) {\n      getTermToSpans(spanQuery, filteredReader.getContext(), doc, result);\n    }\n    return result;\n  }
4	public synchronized void replaceTaxonomy(Directory taxoDir) throws IOException {\n        indexWriter.deleteAll();\n    indexWriter.addIndexes(taxoDir);\n    shouldRefreshReaderManager = true;\n    initReaderManager();     refreshReaderManager();\n    nextID = indexWriter.maxDoc();\n    taxoArrays = null;     \n            cache.clear();\n    cacheIsComplete = false;\n    shouldFillCache = true;\n    cacheMisses.set(0);\n    \n        ++indexEpoch;\n  }
5	public void register(TermState state, final int ord) {\n    assert state != null : "state must not be null";\n    assert ord >= 0 && ord < states.length;\n    assert states[ord] == null : "state for ord: " + ord\n        + " already registered";\n    states[ord] = state;\n  }
6	private static TopDocs mergeAux(Sort sort, int start, int size, TopDocs[] shardHits, boolean setShardIndex) {\n\n    final PriorityQueue<ShardRef> queue;\n    if (sort == null) {\n      queue = new ScoreMergeSortQueue(shardHits);\n    } else {\n      queue = new MergeSortQueue(sort, shardHits);\n    }\n\n    long totalHitCount = 0;\n    int availHitCount = 0;\n    float maxScore = Float.MIN_VALUE;\n    for(int shardIDX=0;shardIDX<shardHits.length;shardIDX++) {\n      final TopDocs shard = shardHits[shardIDX];\n                  totalHitCount += shard.totalHits;\n      if (shard.scoreDocs != null && shard.scoreDocs.length > 0) {\n        availHitCount += shard.scoreDocs.length;\n        queue.add(new ShardRef(shardIDX, setShardIndex == false));\n        maxScore = Math.max(maxScore, shard.getMaxScore());\n      }\n    }\n\n    if (availHitCount == 0) {\n      maxScore = Float.NaN;\n    }\n\n    final ScoreDoc[] hits;\n    if (availHitCount <= start) {\n      hits = new ScoreDoc[0];\n    } else {\n      hits = new ScoreDoc[Math.min(size, availHitCount - start)];\n      int requestedResultWindow = start + size;\n      int numIterOnHits = Math.min(availHitCount, requestedResultWindow);\n      int hitUpto = 0;\n      while (hitUpto < numIterOnHits) {\n        assert queue.size() > 0;\n        ShardRef ref = queue.top();\n        final ScoreDoc hit = shardHits[ref.shardIndex].scoreDocs[ref.hitIndex++];\n        if (setShardIndex) {\n                    hit.shardIndex = ref.shardIndex;\n        } else if (hit.shardIndex == -1) {\n          throw new IllegalArgumentException("setShardIndex is false but TopDocs[" + ref.shardIndex + "].scoreDocs[" + (ref.hitIndex-1) + "] is not set");\n        }\n          \n        if (hitUpto >= start) {\n          hits[hitUpto - start] = hit;\n        }\n\n        hitUpto++;\n\n        if (ref.hitIndex < shardHits[ref.shardIndex].scoreDocs.length) {\n                    queue.updateTop();\n        } else {\n          queue.pop();\n        }\n      }\n    }\n\n    if (sort == null) {\n      return new TopDocs(totalHitCount, hits, maxScore);\n    } else {\n      return new TopFieldDocs(totalHitCount, hits, sort.getSort(), maxScore);\n    }\n  }
7	private int numVowels(char s[], int len) {\n    int n = 0;\n    for (int i = 0; i < len; i++) {\n      switch(s[i]) {\n        case 'a': case 'e': case 'i':  \n        case 'o': case 'u': case 'ā':  \n        case 'ī': case 'ē': case 'ū':\n          n++;\n      }\n    }\n    return n;\n  }
8	public int step(int state, int label) {\n    assert state >= 0;\n    assert label >= 0;\n    int trans = states[2*state];\n    int limit = trans + 3*states[2*state+1];\n        while (trans < limit) {\n      int dest = transitions[trans];\n      int min = transitions[trans+1];\n      int max = transitions[trans+2];\n      if (min <= label && label <= max) {\n        return dest;\n      }\n      trans += 3;\n    }\n\n    return -1;\n  }
9	protected synchronized void updateMergeThreads() {\n\n            final List<MergeThread> activeMerges = new ArrayList<>();\n\n    int threadIdx = 0;\n    while (threadIdx < mergeThreads.size()) {\n      final MergeThread mergeThread = mergeThreads.get(threadIdx);\n      if (!mergeThread.isAlive()) {\n                mergeThreads.remove(threadIdx);\n        continue;\n      }\n      activeMerges.add(mergeThread);\n      threadIdx++;\n    }\n\n        CollectionUtil.timSort(activeMerges);\n\n    final int activeMergeCount = activeMerges.size();\n\n    int bigMergeCount = 0;\n\n    for (threadIdx=activeMergeCount-1;threadIdx>=0;threadIdx--) {\n      MergeThread mergeThread = activeMerges.get(threadIdx);\n      if (mergeThread.merge.estimatedMergeBytes > MIN_BIG_MERGE_MB*1024*1024) {\n        bigMergeCount = 1+threadIdx;\n        break;\n      }\n    }\n\n    long now = System.nanoTime();\n\n    StringBuilder message;\n    if (verbose()) {\n      message = new StringBuilder();\n      message.append(String.format(Locale.ROOT, "updateMergeThreads ioThrottle=%s targetMBPerSec=%.1f MB/sec", doAutoIOThrottle, targetMBPerSec));\n    } else {\n      message = null;\n    }\n\n    for (threadIdx=0;threadIdx<activeMergeCount;threadIdx++) {\n      MergeThread mergeThread = activeMerges.get(threadIdx);\n\n      OneMerge merge = mergeThread.merge;\n\n            final boolean doPause = threadIdx < bigMergeCount - maxThreadCount;\n\n      double newMBPerSec;\n      if (doPause) {\n        newMBPerSec = 0.0;\n      } else if (merge.maxNumSegments != -1) {\n        newMBPerSec = forceMergeMBPerSec;\n      } else if (doAutoIOThrottle == false) {\n        newMBPerSec = Double.POSITIVE_INFINITY;\n      } else if (merge.estimatedMergeBytes < MIN_BIG_MERGE_MB*1024*1024) {\n                newMBPerSec = Double.POSITIVE_INFINITY;\n      } else {\n        newMBPerSec = targetMBPerSec;\n      }\n\n      MergeRateLimiter rateLimiter = mergeThread.rateLimiter;\n      double curMBPerSec = rateLimiter.getMBPerSec();\n\n      if (verbose()) {\n        long mergeStartNS = merge.mergeStartNS;\n        if (mergeStartNS == -1) {\n                    mergeStartNS = now;\n        }\n        message.append('\n');\n        message.append(String.format(Locale.ROOT, "merge thread %s estSize=%.1f MB (written=%.1f MB) runTime=%.1fs (stopped=%.1fs, paused=%.1fs) rate=%s\n",\n                                     mergeThread.getName(),\n                                     bytesToMB(merge.estimatedMergeBytes),\n                                     bytesToMB(rateLimiter.getTotalBytesWritten()),\n                                     nsToSec(now - mergeStartNS),\n                                     nsToSec(rateLimiter.getTotalStoppedNS()),\n                                     nsToSec(rateLimiter.getTotalPausedNS()),\n                                     rateToString(rateLimiter.getMBPerSec())));\n\n        if (newMBPerSec != curMBPerSec) {\n          if (newMBPerSec == 0.0) {\n            message.append("  now stop");\n          } else if (curMBPerSec == 0.0) {\n            if (newMBPerSec == Double.POSITIVE_INFINITY) {\n              message.append("  now resume");\n            } else {\n              message.append(String.format(Locale.ROOT, "  now resume to %.1f MB/sec", newMBPerSec));\n            }\n          } else {\n            message.append(String.format(Locale.ROOT, "  now change from %.1f MB/sec to %.1f MB/sec", curMBPerSec, newMBPerSec));\n          }\n        } else if (curMBPerSec == 0.0) {\n          message.append("  leave stopped");\n        } else {\n          message.append(String.format(Locale.ROOT, "  leave running at %.1f MB/sec", curMBPerSec));\n        }\n      }\n\n      rateLimiter.setMBPerSec(newMBPerSec);\n    }\n    if (verbose()) {\n      message(message.toString());\n    }\n  }
10	private PhraseQuery addSlopToPhrase(PhraseQuery query, int slop) {\n    PhraseQuery.Builder builder = new PhraseQuery.Builder();\n    builder.setSlop(slop);\n    org.apache.lucene.index.Term[] terms = query.getTerms();\n    int[] positions = query.getPositions();\n    for (int i = 0; i < terms.length; ++i) {\n      builder.add(terms[i], positions[i]);\n    }\n\n    return builder.build();\n  }
11	public static CharArraySet copy(final Set<?> set) {\n    if(set == EMPTY_SET)\n      return EMPTY_SET;\n    if(set instanceof CharArraySet) {\n      final CharArraySet source = (CharArraySet) set;\n      return new CharArraySet(CharArrayMap.copy(source.map));\n    }\n    return new CharArraySet(set, false);\n  }
12	public static BytesRef intsRefToBytesRef(IntsRef ints) {\n    byte[] bytes = new byte[ints.length];\n    for(int i=0;i<ints.length;i++) {\n      int x = ints.ints[ints.offset+i];\n      if (x < 0 || x > 255) {\n        throw new IllegalArgumentException("int at pos=" + i + " with value=" + x + " is out-of-bounds for byte");\n      }\n      bytes[i] = (byte) x;\n    }\n\n    return new BytesRef(bytes);\n  }
13	public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n            return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n                while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = "";\n      } else {\n        messagePrefix = "iter " + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n                        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled("BD")) {\n            infoStream.message("BD", "packet matches no segments");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled("BD")) {\n          infoStream.message("BD", String.format(Locale.ROOT,\n                                                 messagePrefix + "now apply del packet (%s) to %d segments, mergeGen %d",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n                        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n                delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n            writer.readerPool.writeSomeDocValuesUpdates();\n\n                  totalDelCount += delCount;\n\n      if (infoStream.isEnabled("BD")) {\n        infoStream.message("BD", String.format(Locale.ROOT,\n                                               messagePrefix + "done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n                \n        break;\n      }\n\n                  synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n                    \n                    writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n                    break;\n        }\n      }\n\n      if (infoStream.isEnabled("BD")) {\n        infoStream.message("BD", messagePrefix + "concurrent merges finished; move to next iter");\n      }\n        \n            \n      iter++;\n    }\n\n    if (finished == false) {\n            writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled("BD")) {\n      String message = String.format(Locale.ROOT,\n                                     "done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += "; " + (iter+1) + " iters due to concurrent merges";\n      }\n      message += "; " + writer.bufferedUpdatesStream.getPendingUpdatesCount() + " packets remain";\n      infoStream.message("BD", message);\n    }\n  }
14	private DocValuesProducer initDocValuesProducer() throws IOException {\n\n    if (fieldInfos.hasDocValues() == false) {\n      return null;\n    } else {\n      Directory dir;\n      if (core.cfsReader != null) {\n        dir = core.cfsReader;\n      } else {\n        dir = si.info.dir;\n      }\n      if (si.hasFieldUpdates()) {\n        return new SegmentDocValuesProducer(si, dir, core.coreFieldInfos, fieldInfos, segDocValues);\n      } else {\n                return segDocValues.getDocValuesProducer(-1L, si, dir, fieldInfos);\n      }\n    }\n  }
15	static CopyState readCopyState(DataInput in) throws IOException {\n\n        byte[] infosBytes = new byte[in.readVInt()];\n    in.readBytes(infosBytes, 0, infosBytes.length);\n\n    long gen = in.readVLong();\n    long version = in.readVLong();\n    Map<String,FileMetaData> files = readFilesMetaData(in);\n\n    int count = in.readVInt();\n    Set<String> completedMergeFiles = new HashSet<>();\n    for(int i=0;i<count;i++) {\n      completedMergeFiles.add(in.readString());\n    }\n    long primaryGen = in.readVLong();\n\n    return new CopyState(files, version, gen, infosBytes, completedMergeFiles, primaryGen, null);\n  }
16	public static IntsRef getByOutput(FST<Long> fst, long targetOutput, BytesReader in, Arc<Long> arc, Arc<Long> scratchArc, IntsRefBuilder result) throws IOException {\n    long output = arc.output;\n    int upto = 0;\n\n    \n    while(true) {\n            if (arc.isFinal()) {\n        final long finalOutput = output + arc.nextFinalOutput;\n                if (finalOutput == targetOutput) {\n          result.setLength(upto);\n                    return result.get();\n        } else if (finalOutput > targetOutput) {\n                    return null;\n        }\n      }\n\n      if (FST.targetHasArcs(arc)) {\n                result.grow(1+upto);\n        \n        fst.readFirstRealTargetArc(arc.target, arc, in);\n\n        if (arc.bytesPerArc != 0) {\n\n          int low = 0;\n          int high = arc.numArcs-1;\n          int mid = 0;\n                    boolean exact = false;\n          while (low <= high) {\n            mid = (low + high) >>> 1;\n            in.setPosition(arc.posArcsStart);\n            in.skipBytes(arc.bytesPerArc*mid);\n            final byte flags = in.readByte();\n            fst.readLabel(in);\n            final long minArcOutput;\n            if ((flags & FST.BIT_ARC_HAS_OUTPUT) != 0) {\n              final long arcOutput = fst.outputs.read(in);\n              minArcOutput = output + arcOutput;\n            } else {\n              minArcOutput = output;\n            }\n                        if (minArcOutput == targetOutput) {\n              exact = true;\n              break;\n            } else if (minArcOutput < targetOutput) {\n              low = mid + 1;\n            } else {\n              high = mid - 1;\n            }\n          }\n\n          if (high == -1) {\n            return null;\n          } else if (exact) {\n            arc.arcIdx = mid-1;\n          } else {\n            arc.arcIdx = low-2;\n          }\n\n          fst.readNextRealArc(arc, in);\n          result.setIntAt(upto++, arc.label);\n          output += arc.output;\n\n        } else {\n\n          FST.Arc<Long> prevArc = null;\n\n          while(true) {\n            \n                                    final long minArcOutput = output + arc.output;\n\n            if (minArcOutput == targetOutput) {\n                                          output = minArcOutput;\n              result.setIntAt(upto++, arc.label);\n              break;\n            } else if (minArcOutput > targetOutput) {\n              if (prevArc == null) {\n                                return null;\n              } else {\n                                arc.copyFrom(prevArc);\n                result.setIntAt(upto++, arc.label);\n                output += arc.output;\n                                break;\n              }\n            } else if (arc.isLast()) {\n                            output = minArcOutput;\n                            result.setIntAt(upto++, arc.label);\n              break;\n            } else {\n                            prevArc = scratchArc;\n              prevArc.copyFrom(arc);\n                            fst.readNextRealArc(arc, in);\n            }\n          }\n        }\n      } else {\n                return null;\n      }\n    }    \n  }
17	protected static int comparePrefix(UnitNRShape a, UnitNRShape b) {\n    int minLevel = Math.min(a.getLevel(), b.getLevel());\n    for (int level = 1; level <= minLevel; level++) {\n      int diff = a.getValAtLevel(level) - b.getValAtLevel(level);\n      if (diff != 0)\n        return diff;\n    }\n    return 0;\n  }
18	public int normalize(char s[], int len) {\n\n    for (int i = 0; i < len; i++) {\n      switch (s[i]) {\n      case ALEF_MADDA:\n      case ALEF_HAMZA_ABOVE:\n      case ALEF_HAMZA_BELOW:\n        s[i] = ALEF;\n        break;\n      case DOTLESS_YEH:\n        s[i] = YEH;\n        break;\n      case TEH_MARBUTA:\n        s[i] = HEH;\n        break;\n      case TATWEEL:\n      case KASRATAN:\n      case DAMMATAN:\n      case FATHATAN:\n      case FATHA:\n      case DAMMA:\n      case KASRA:\n      case SHADDA:\n      case SUKUN:\n        len = delete(s, i, len);\n        i--;\n        break;\n      default:\n        break;\n      }\n    }\n\n    return len;\n  }
19	protected final CharArraySet getWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n                  words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        List<String> wlist = getLines(loader, file.trim());\n        words.addAll(StopFilter.makeStopSet(wlist, ignoreCase));\n      }\n    }\n    return words;\n  }
20	protected static GeoPoint[] glueTogether(final GeoPoint[]... pointArrays) {\n    int count = 0;\n    for (final GeoPoint[] pointArray : pointArrays) {\n      count += pointArray.length;\n    }\n    final GeoPoint[] rval = new GeoPoint[count];\n    count = 0;\n    for (final GeoPoint[] pointArray : pointArrays) {\n      for (final GeoPoint point : pointArray) {\n        rval[count++] = point;\n      }\n    }\n    return rval;\n  }
21	static void writeInt(final OutputStream outputStream, final int value) throws IOException {\n    outputStream.write(value);\n    outputStream.write(value >> 8);\n    outputStream.write(value >> 16);\n    outputStream.write(value >> 24);\n  }
22	public synchronized CopyState getCopyState() throws IOException {\n    ensureOpen(false);\n        assert curInfos == copyState.infos;\n    writer.incRefDeleter(copyState.infos);\n    int count = copyingCount.incrementAndGet();\n    assert count > 0;\n    return copyState;\n  }
23	public static SpatialPrefixTree makeSPT(Map<String,String> args, ClassLoader classLoader, SpatialContext ctx) {\n    SpatialPrefixTreeFactory instance;\n    String cname = args.get(PREFIX_TREE);\n    if (cname == null)\n      cname = ctx.isGeo() ? "geohash" : "quad";\n    if ("geohash".equalsIgnoreCase(cname))\n      instance = new GeohashPrefixTree.Factory();\n    else if ("quad".equalsIgnoreCase(cname))\n      instance = new QuadPrefixTree.Factory();\n    else if ("packedQuad".equalsIgnoreCase(cname))\n      instance = new PackedQuadPrefixTree.Factory();\n    else {\n      try {\n        Class<?> c = classLoader.loadClass(cname);\n        instance = (SpatialPrefixTreeFactory) c.newInstance();\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    }\n    instance.init(args,ctx);\n    return instance.newSPT();\n  }
24	@SuppressWarnings("fallthrough")\n  public static Automaton toAutomaton(Term wildcardquery) {\n    List<Automaton> automata = new ArrayList<>();\n    \n    String wildcardText = wildcardquery.text();\n    \n    for (int i = 0; i < wildcardText.length();) {\n      final int c = wildcardText.codePointAt(i);\n      int length = Character.charCount(c);\n      switch(c) {\n        case WILDCARD_STRING: \n          automata.add(Automata.makeAnyString());\n          break;\n        case WILDCARD_CHAR:\n          automata.add(Automata.makeAnyChar());\n          break;\n        case WILDCARD_ESCAPE:\n                    if (i + length < wildcardText.length()) {\n            final int nextChar = wildcardText.codePointAt(i + length);\n            length += Character.charCount(nextChar);\n            automata.add(Automata.makeChar(nextChar));\n            break;\n          }         default:\n          automata.add(Automata.makeChar(c));\n      }\n      i += length;\n    }\n    \n    return Operations.concatenate(automata);\n  }
25	public void reset(Reader reader) {\n    this.reader = reader;\n    nextPos = 0;\n    nextWrite = 0;\n    count = 0;\n    end = false;\n  }
26	public static void main(String[] args) throws Exception {\n    String usage =\n      "Usage:\tjava org.apache.lucene.demo.SearchFiles [-index dir] [-field f] [-repeat n] [-queries file] [-query string] [-raw] [-paging hitsPerPage]\n\nSee http://lucene.apache.org/core/4_1_0/demo/ for details.";\n    if (args.length > 0 && ("-h".equals(args[0]) || "-help".equals(args[0]))) {\n      System.out.println(usage);\n      System.exit(0);\n    }\n\n    String index = "index";\n    String field = "contents";\n    String queries = null;\n    int repeat = 0;\n    boolean raw = false;\n    String queryString = null;\n    int hitsPerPage = 10;\n    \n    for(int i = 0;i < args.length;i++) {\n      if ("-index".equals(args[i])) {\n        index = args[i+1];\n        i++;\n      } else if ("-field".equals(args[i])) {\n        field = args[i+1];\n        i++;\n      } else if ("-queries".equals(args[i])) {\n        queries = args[i+1];\n        i++;\n      } else if ("-query".equals(args[i])) {\n        queryString = args[i+1];\n        i++;\n      } else if ("-repeat".equals(args[i])) {\n        repeat = Integer.parseInt(args[i+1]);\n        i++;\n      } else if ("-raw".equals(args[i])) {\n        raw = true;\n      } else if ("-paging".equals(args[i])) {\n        hitsPerPage = Integer.parseInt(args[i+1]);\n        if (hitsPerPage <= 0) {\n          System.err.println("There must be at least 1 hit per page.");\n          System.exit(1);\n        }\n        i++;\n      }\n    }\n    \n    IndexReader reader = DirectoryReader.open(FSDirectory.open(Paths.get(index)));\n    IndexSearcher searcher = new IndexSearcher(reader);\n    Analyzer analyzer = new StandardAnalyzer();\n\n    BufferedReader in = null;\n    if (queries != null) {\n      in = Files.newBufferedReader(Paths.get(queries), StandardCharsets.UTF_8);\n    } else {\n      in = new BufferedReader(new InputStreamReader(System.in, StandardCharsets.UTF_8));\n    }\n    QueryParser parser = new QueryParser(field, analyzer);\n    while (true) {\n      if (queries == null && queryString == null) {                                System.out.println("Enter query: ");\n      }\n\n      String line = queryString != null ? queryString : in.readLine();\n\n      if (line == null || line.length() == -1) {\n        break;\n      }\n\n      line = line.trim();\n      if (line.length() == 0) {\n        break;\n      }\n      \n      Query query = parser.parse(line);\n      System.out.println("Searching for: " + query.toString(field));\n            \n      if (repeat > 0) {                                   Date start = new Date();\n        for (int i = 0; i < repeat; i++) {\n          searcher.search(query, 100);\n        }\n        Date end = new Date();\n        System.out.println("Time: "+(end.getTime()-start.getTime())+"ms");\n      }\n\n      doPagingSearch(in, searcher, query, hitsPerPage, raw, queries == null && queryString == null);\n\n      if (queryString != null) {\n        break;\n      }\n    }\n    reader.close();\n  }
27	public void trimToSize() {\n        balance();\n\n        redimNodeArrays(freenode);\n\n        CharVector kx = new CharVector();\n    kx.alloc(1);\n    TernaryTree map = new TernaryTree();\n    compact(kx, map, root);\n    kv = kx;\n    kv.trimToSize();\n  }
28	public static <T> List<Path<T>> intersectPrefixPaths(Automaton a, FST<T> fst)\n      throws IOException {\n    assert a.isDeterministic();\n    final List<Path<T>> queue = new ArrayList<>();\n    final List<Path<T>> endNodes = new ArrayList<>();\n    if (a.getNumStates() == 0) {\n      return endNodes;\n    }\n\n    queue.add(new Path<>(0, fst\n        .getFirstArc(new FST.Arc<T>()), fst.outputs.getNoOutput(),\n        new IntsRefBuilder()));\n    \n    final FST.Arc<T> scratchArc = new FST.Arc<>();\n    final FST.BytesReader fstReader = fst.getBytesReader();\n\n    Transition t = new Transition();\n\n    while (queue.size() != 0) {\n      final Path<T> path = queue.remove(queue.size() - 1);\n      if (a.isAccept(path.state)) {\n        endNodes.add(path);\n                        continue;\n      }\n      \n      IntsRefBuilder currentInput = path.input;\n      int count = a.initTransition(path.state, t);\n      for (int i=0;i<count;i++) {\n        a.getNextTransition(t);\n        final int min = t.min;\n        final int max = t.max;\n        if (min == max) {\n          final FST.Arc<T> nextArc = fst.findTargetArc(t.min,\n              path.fstNode, scratchArc, fstReader);\n          if (nextArc != null) {\n            final IntsRefBuilder newInput = new IntsRefBuilder();\n            newInput.copyInts(currentInput.get());\n            newInput.append(t.min);\n            queue.add(new Path<>(t.dest, new FST.Arc<T>()\n                .copyFrom(nextArc), fst.outputs\n                .add(path.output, nextArc.output), newInput));\n          }\n        } else {\n                                                                                FST.Arc<T> nextArc = Util.readCeilArc(min, fst, path.fstNode,\n              scratchArc, fstReader);\n          while (nextArc != null && nextArc.label <= max) {\n            assert nextArc.label <=  max;\n            assert nextArc.label >= min : nextArc.label + " "\n                + min;\n            final IntsRefBuilder newInput = new IntsRefBuilder();\n            newInput.copyInts(currentInput.get());\n            newInput.append(nextArc.label);\n            queue.add(new Path<>(t.dest, new FST.Arc<T>()\n                .copyFrom(nextArc), fst.outputs\n                .add(path.output, nextArc.output), newInput));\n            final int label = nextArc.label;             nextArc = nextArc.isLast() ? null : fst.readNextRealArc(nextArc,\n                fstReader);\n            assert nextArc == null || label < nextArc.label : "last: " + label\n                + " next: " + nextArc.label;\n          }\n        }\n      }\n    }\n    return endNodes;\n  }
29	private static Edge createTree(double polyLats[], double polyLons[]) {\n    Edge edges[] = new Edge[polyLats.length - 1];\n    for (int i = 1; i < polyLats.length; i++) {\n      double lat1 = polyLats[i-1];\n      double lon1 = polyLons[i-1];\n      double lat2 = polyLats[i];\n      double lon2 = polyLons[i];\n      edges[i - 1] = new Edge(lat1, lon1, lat2, lon2, Math.min(lat1, lat2), Math.max(lat1, lat2));\n    }\n        Arrays.sort(edges, (left, right) -> {\n      int ret = Double.compare(left.low, right.low);\n      if (ret == 0) {\n        ret = Double.compare(left.max, right.max);\n      }\n      return ret;\n    });\n    return createTree(edges, 0, edges.length - 1);\n  }
30	protected void findIntersectionBounds(final PlanetModel planetModel, final Bounds boundsInfo, final Plane q, final Membership... bounds) {\n            final double lineVectorX = y * q.z - z * q.y;\n    final double lineVectorY = z * q.x - x * q.z;\n    final double lineVectorZ = x * q.y - y * q.x;\n    if (Math.abs(lineVectorX) < MINIMUM_RESOLUTION && Math.abs(lineVectorY) < MINIMUM_RESOLUTION && Math.abs(lineVectorZ) < MINIMUM_RESOLUTION) {\n                  return;\n    }\n\n                                                                                    final double denomYZ = this.y * q.z - this.z * q.y;\n    final double denomXZ = this.x * q.z - this.z * q.x;\n    final double denomXY = this.x * q.y - this.y * q.x;\n    if (Math.abs(denomYZ) >= Math.abs(denomXZ) && Math.abs(denomYZ) >= Math.abs(denomXY)) {\n                  if (Math.abs(denomYZ) < MINIMUM_RESOLUTION_SQUARED) {\n                return;\n      }\n      final double denom = 1.0 / denomYZ;\n            recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        0.0, (-(this.D+MINIMUM_RESOLUTION) * q.z - this.z * -(q.D+MINIMUM_RESOLUTION)) * denom, (this.y * -(q.D+MINIMUM_RESOLUTION) + (this.D+MINIMUM_RESOLUTION) * q.y) * denom,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        0.0, (-(this.D-MINIMUM_RESOLUTION) * q.z - this.z * -(q.D+MINIMUM_RESOLUTION)) * denom, (this.y * -(q.D+MINIMUM_RESOLUTION) + (this.D-MINIMUM_RESOLUTION) * q.y) * denom,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        0.0, (-(this.D+MINIMUM_RESOLUTION) * q.z - this.z * -(q.D-MINIMUM_RESOLUTION)) * denom, (this.y * -(q.D-MINIMUM_RESOLUTION) + (this.D+MINIMUM_RESOLUTION) * q.y) * denom,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        0.0, (-(this.D-MINIMUM_RESOLUTION) * q.z - this.z * -(q.D-MINIMUM_RESOLUTION)) * denom, (this.y * -(q.D-MINIMUM_RESOLUTION) + (this.D-MINIMUM_RESOLUTION) * q.y) * denom,\n        bounds);\n    } else if (Math.abs(denomXZ) >= Math.abs(denomXY) && Math.abs(denomXZ) >= Math.abs(denomYZ)) {\n                  if (Math.abs(denomXZ) < MINIMUM_RESOLUTION_SQUARED) {\n                return;\n      }\n      final double denom = 1.0 / denomXZ;\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        (-(this.D+MINIMUM_RESOLUTION) * q.z - this.z * -(q.D+MINIMUM_RESOLUTION)) * denom, 0.0, (this.x * -(q.D+MINIMUM_RESOLUTION) + (this.D+MINIMUM_RESOLUTION) * q.x) * denom,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        (-(this.D-MINIMUM_RESOLUTION) * q.z - this.z * -(q.D+MINIMUM_RESOLUTION)) * denom, 0.0, (this.x * -(q.D+MINIMUM_RESOLUTION) + (this.D-MINIMUM_RESOLUTION) * q.x) * denom,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        (-(this.D+MINIMUM_RESOLUTION) * q.z - this.z * -(q.D-MINIMUM_RESOLUTION)) * denom, 0.0, (this.x * -(q.D-MINIMUM_RESOLUTION) + (this.D+MINIMUM_RESOLUTION) * q.x) * denom,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        (-(this.D-MINIMUM_RESOLUTION) * q.z - this.z * -(q.D-MINIMUM_RESOLUTION)) * denom, 0.0, (this.x * -(q.D-MINIMUM_RESOLUTION) + (this.D-MINIMUM_RESOLUTION) * q.x) * denom,\n        bounds);\n    } else {\n                  if (Math.abs(denomXY) < MINIMUM_RESOLUTION_SQUARED) {\n                return;\n      }\n      final double denom = 1.0 / denomXY;\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        (-(this.D+MINIMUM_RESOLUTION) * q.y - this.y * -(q.D+MINIMUM_RESOLUTION)) * denom, (this.x * -(q.D+MINIMUM_RESOLUTION) + (this.D+MINIMUM_RESOLUTION) * q.x) * denom, 0.0,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        (-(this.D-MINIMUM_RESOLUTION) * q.y - this.y * -(q.D+MINIMUM_RESOLUTION)) * denom, (this.x * -(q.D+MINIMUM_RESOLUTION) + (this.D-MINIMUM_RESOLUTION) * q.x) * denom, 0.0,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        (-(this.D+MINIMUM_RESOLUTION) * q.y - this.y * -(q.D-MINIMUM_RESOLUTION)) * denom, (this.x * -(q.D-MINIMUM_RESOLUTION) + (this.D+MINIMUM_RESOLUTION) * q.x) * denom, 0.0,\n        bounds);\n      recordLineBounds(planetModel, boundsInfo,\n        lineVectorX, lineVectorY, lineVectorZ,\n        (-(this.D-MINIMUM_RESOLUTION) * q.y - this.y * -(q.D-MINIMUM_RESOLUTION)) * denom, (this.x * -(q.D-MINIMUM_RESOLUTION) + (this.D-MINIMUM_RESOLUTION) * q.x) * denom, 0.0,\n        bounds);\n    }\n  }
31	public static void main(String[] args) throws Exception {\n    System.out.println("Facet counting over multiple category lists example:");\n    System.out.println("-----------------------");\n    List<FacetResult> results = new MultiCategoryListsFacetsExample().runSearch();\n    System.out.println("Author: " + results.get(0));\n    System.out.println("Publish Date: " + results.get(1));\n  }
32	void buffer(char[] termPart, int startPos, int endPos, int startPart, int endPart) {\n    "buffer: pos=""-"" part=""-""  termIn=""  term="\n    assert endPos > startPos: "startPos=" + startPos + " endPos=" + endPos;\n    assert endPart > startPart || (endPart == 0 && startPart == 0 && savedTermLength == 0): "startPart=" + startPart + " endPart=" + endPart;\n    if ((bufferedLen+1)*4 > bufferedParts.length) {\n      bufferedParts = ArrayUtil.grow(bufferedParts, (bufferedLen+1)*4);\n    }\n    if (bufferedTermParts.length == bufferedLen) {\n      int newSize = ArrayUtil.oversize(bufferedLen+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF);\n      char[][] newArray = new char[newSize][];\n      System.arraycopy(bufferedTermParts, 0, newArray, 0, bufferedTermParts.length);\n      bufferedTermParts = newArray;\n    }\n    bufferedTermParts[bufferedLen] = termPart;\n    bufferedParts[bufferedLen*4] = startPos;\n    bufferedParts[bufferedLen*4+1] = endPos;\n    bufferedParts[bufferedLen*4+2] = startPart;\n    bufferedParts[bufferedLen*4+3] = endPart;\n    bufferedLen++;\n  }
33	public static void writeHeader(DataOutput out, String codec, int version) throws IOException {\n    BytesRef bytes = new BytesRef(codec);\n    if (bytes.length != codec.length() || bytes.length >= 128) {\n      throw new IllegalArgumentException("codec must be simple ASCII, less than 128 characters in length [got " + codec + "]");\n    }\n    out.writeInt(CODEC_MAGIC);\n    out.writeString(codec);\n    out.writeInt(version);\n  }
34	private void deleteCommits() throws IOException {\n\n    int size = commitsToDelete.size();\n\n    if (size > 0) {\n\n                  Throwable firstThrowable = null;\n      for(int i=0;i<size;i++) {\n        CommitPoint commit = commitsToDelete.get(i);\n        if (infoStream.isEnabled("IFD")) {\n          infoStream.message("IFD", "deleteCommits: now decRef commit \"" + commit.getSegmentsFileName() + "\"");\n        }\n        try {\n          decRef(commit.files);\n        } catch (Throwable t) {\n          if (firstThrowable == null) {\n            firstThrowable = t;\n          }\n        }\n      }\n      commitsToDelete.clear();\n\n      if (firstThrowable != null) {\n        throw IOUtils.rethrowAlways(firstThrowable);\n      }\n\n            size = commits.size();\n      int readFrom = 0;\n      int writeTo = 0;\n      while(readFrom < size) {\n        CommitPoint commit = commits.get(readFrom);\n        if (!commit.deleted) {\n          if (writeTo != readFrom) {\n            commits.set(writeTo, commits.get(readFrom));\n          }\n          writeTo++;\n        }\n        readFrom++;\n      }\n\n      while(size > writeTo) {\n        commits.remove(size-1);\n        size--;\n      }\n    }\n  }
35	public int put(String[] entry) {\n    short leftId = Short.parseShort(entry[1]);\n    short rightId = Short.parseShort(entry[2]);\n    short wordCost = Short.parseShort(entry[3]);\n    \n    StringBuilder sb = new StringBuilder();\n    \n        for (int i = 4; i < 8; i++) {\n      String part = entry[i];\n      assert part.length() > 0;\n      if (!"*".equals(part)) {\n        if (sb.length() > 0) {\n          sb.append('-');\n        }\n        sb.append(part);\n      }\n    }\n    \n    String posData = sb.toString();\n    \n    sb.setLength(0);\n    sb.append(CSVUtil.quoteEscape(posData));\n    sb.append(',');\n    if (!"*".equals(entry[8])) {\n      sb.append(CSVUtil.quoteEscape(entry[8]));\n    }\n    sb.append(',');\n    if (!"*".equals(entry[9])) {\n      sb.append(CSVUtil.quoteEscape(entry[9]));\n    }\n    String fullPOSData = sb.toString();\n    \n    String baseForm = entry[10];\n    String reading = entry[11];\n    String pronunciation = entry[12];\n    \n        int left = buffer.remaining();\n        int worstCase = 4 + 3 + 2*(baseForm.length() + reading.length() + pronunciation.length());\n    if (worstCase > left) {\n      ByteBuffer newBuffer = ByteBuffer.allocate(ArrayUtil.oversize(buffer.limit() + worstCase - left, 1));\n      buffer.flip();\n      newBuffer.put(buffer);\n      buffer = newBuffer;\n    }\n\n    int flags = 0;\n    if (!("*".equals(baseForm) || baseForm.equals(entry[0]))) {\n      flags |= BinaryDictionary.HAS_BASEFORM;\n    }\n    if (!reading.equals(toKatakana(entry[0]))) {\n      flags |= BinaryDictionary.HAS_READING;\n    }\n    if (!pronunciation.equals(reading)) {\n      flags |= BinaryDictionary.HAS_PRONUNCIATION;\n    }\n\n    assert leftId == rightId;\n    assert leftId < 4096;         int toFill = 1+leftId - posDict.size();\n    for (int i = 0; i < toFill; i++) {\n      posDict.add(null);\n    }\n    \n    String existing = posDict.get(leftId);\n    assert existing == null || existing.equals(fullPOSData);\n    posDict.set(leftId, fullPOSData);\n    \n    buffer.putShort((short)(leftId << 3 | flags));\n    buffer.putShort(wordCost);\n\n    if ((flags & BinaryDictionary.HAS_BASEFORM) != 0) {\n      assert baseForm.length() < 16;\n      int shared = sharedPrefix(entry[0], baseForm);\n      int suffix = baseForm.length() - shared;\n      buffer.put((byte) (shared << 4 | suffix));\n      for (int i = shared; i < baseForm.length(); i++) {\n        buffer.putChar(baseForm.charAt(i));\n      }\n    }\n    \n    if ((flags & BinaryDictionary.HAS_READING) != 0) {\n      if (isKatakana(reading)) {\n        buffer.put((byte) (reading.length() << 1 | 1));\n        writeKatakana(reading);\n      } else {\n        buffer.put((byte) (reading.length() << 1));\n        for (int i = 0; i < reading.length(); i++) {\n          buffer.putChar(reading.charAt(i));\n        }\n      }\n    }\n    \n    if ((flags & BinaryDictionary.HAS_PRONUNCIATION) != 0) {\n                              if (isKatakana(pronunciation)) {\n        buffer.put((byte) (pronunciation.length() << 1 | 1));\n        writeKatakana(pronunciation);\n      } else {\n        buffer.put((byte) (pronunciation.length() << 1));\n        for (int i = 0; i < pronunciation.length(); i++) {\n          buffer.putChar(pronunciation.charAt(i));\n        }\n      }\n    }\n    \n    return buffer.position();\n  }
36	private int collide(PhrasePositions pp) {\n    int tpPos = tpPos(pp);\n    PhrasePositions[] rg = rptGroups[pp.rptGroup];\n    for (int i=0; i<rg.length; i++) {\n      PhrasePositions pp2 = rg[i];\n      if (pp2 != pp && tpPos(pp2) == tpPos) {\n        return pp2.rptInd;\n      }\n    }\n    return -1;\n  }
37	public int freeBlocks(int num) {\n    assert num >= 0 : "free blocks must be >= 0 but was: "+ num;\n    final int stop;\n    final int count;\n    if (num > freeBlocks) {\n      stop = 0;\n      count = freeBlocks;\n    } else {\n      stop = freeBlocks - num;\n      count = num;\n    }\n    while (freeBlocks > stop) {\n      freeByteBlocks[--freeBlocks] = null;\n    }\n    bytesUsed.addAndGet(-count*blockSize);\n    assert bytesUsed.get() >= 0;\n    return count;\n  }
38	public void addEpsilon(int source, int dest) {\n    Transition t = new Transition();\n    int count = initTransition(dest, t);\n    for(int i=0;i<count;i++) {\n      getNextTransition(t);\n      addTransition(source, t.dest, t.min, t.max);\n    }\n    if (isAccept(dest)) {\n      setAccept(source, true);\n    }\n  }
39	long add(Term term, DeleteSlice slice) {\n    final TermNode termNode = new TermNode(term);\n    long seqNo = add(termNode);\n    \n    slice.sliceTail = termNode;\n    assert slice.sliceHead != slice.sliceTail : "slice head and tail must differ after add";\n    tryApplyGlobalSlice();     \n    return seqNo;\n  }
40	protected GeoPoint[] findIntersections(final PlanetModel planetModel, final Plane q, final Membership[] bounds, final Membership[] moreBounds) {\n            final double lineVectorX = y * q.z - z * q.y;\n    final double lineVectorY = z * q.x - x * q.z;\n    final double lineVectorZ = x * q.y - y * q.x;\n    if (Math.abs(lineVectorX) < MINIMUM_RESOLUTION && Math.abs(lineVectorY) < MINIMUM_RESOLUTION && Math.abs(lineVectorZ) < MINIMUM_RESOLUTION) {\n                  return NO_POINTS;\n    }\n\n                                                                                double x0;\n    double y0;\n    double z0;\n        final double denomYZ = this.y * q.z - this.z * q.y;\n    final double denomXZ = this.x * q.z - this.z * q.x;\n    final double denomXY = this.x * q.y - this.y * q.x;\n    if (Math.abs(denomYZ) >= Math.abs(denomXZ) && Math.abs(denomYZ) >= Math.abs(denomXY)) {\n            if (Math.abs(denomYZ) < MINIMUM_RESOLUTION_SQUARED) {\n                return NO_POINTS;\n      }\n      final double denom = 1.0 / denomYZ;\n      x0 = 0.0;\n      y0 = (-this.D * q.z - this.z * -q.D) * denom;\n      z0 = (this.y * -q.D + this.D * q.y) * denom;\n    } else if (Math.abs(denomXZ) >= Math.abs(denomXY) && Math.abs(denomXZ) >= Math.abs(denomYZ)) {\n            if (Math.abs(denomXZ) < MINIMUM_RESOLUTION_SQUARED) {\n                return NO_POINTS;\n      }\n      final double denom = 1.0 / denomXZ;\n      x0 = (-this.D * q.z - this.z * -q.D) * denom;\n      y0 = 0.0;\n      z0 = (this.x * -q.D + this.D * q.x) * denom;\n    } else {\n            if (Math.abs(denomXY) < MINIMUM_RESOLUTION_SQUARED) {\n                return NO_POINTS;\n      }\n      final double denom = 1.0 / denomXY;\n      x0 = (-this.D * q.y - this.y * -q.D) * denom;\n      y0 = (this.x * -q.D + this.D * q.x) * denom;\n      z0 = 0.0;\n    }\n\n                                final double A = lineVectorX * lineVectorX * planetModel.inverseAbSquared +\n      lineVectorY * lineVectorY * planetModel.inverseAbSquared +\n      lineVectorZ * lineVectorZ * planetModel.inverseCSquared;\n    final double B = 2.0 * (lineVectorX * x0 * planetModel.inverseAbSquared + lineVectorY * y0 * planetModel.inverseAbSquared + lineVectorZ * z0 * planetModel.inverseCSquared);\n    final double C = x0 * x0 * planetModel.inverseAbSquared + y0 * y0 * planetModel.inverseAbSquared + z0 * z0 * planetModel.inverseCSquared - 1.0;\n\n    final double BsquaredMinus = B * B - 4.0 * A * C;\n    if (Math.abs(BsquaredMinus) < MINIMUM_RESOLUTION_SQUARED) {\n            final double inverse2A = 1.0 / (2.0 * A);\n            final double t = -B * inverse2A;\n            final double pointX = lineVectorX * t + x0;\n      final double pointY = lineVectorY * t + y0;\n      final double pointZ = lineVectorZ * t + z0;\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(pointX, pointY, pointZ)) {\n          return NO_POINTS;\n        }\n      }\n      for (final Membership bound : moreBounds) {\n        if (!bound.isWithin(pointX, pointY, pointZ)) {\n          return NO_POINTS;\n        }\n      }\n      return new GeoPoint[]{new GeoPoint(pointX, pointY, pointZ)};\n    } else if (BsquaredMinus > 0.0) {\n            final double inverse2A = 1.0 / (2.0 * A);\n            final double sqrtTerm = Math.sqrt(BsquaredMinus);\n      final double t1 = (-B + sqrtTerm) * inverse2A;\n      final double t2 = (-B - sqrtTerm) * inverse2A;\n            final double point1X = lineVectorX * t1 + x0;\n      final double point1Y = lineVectorY * t1 + y0;\n      final double point1Z = lineVectorZ * t1 + z0;\n      final double point2X = lineVectorX * t2 + x0;\n      final double point2Y = lineVectorY * t2 + y0;\n      final double point2Z = lineVectorZ * t2 + z0;\n      boolean point1Valid = true;\n      boolean point2Valid = true;\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(point1X, point1Y, point1Z)) {\n          point1Valid = false;\n          break;\n        }\n      }\n      if (point1Valid) {\n        for (final Membership bound : moreBounds) {\n          if (!bound.isWithin(point1X, point1Y, point1Z)) {\n            point1Valid = false;\n            break;\n          }\n        }\n      }\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(point2X, point2Y, point2Z)) {\n          point2Valid = false;\n          break;\n        }\n      }\n      if (point2Valid) {\n        for (final Membership bound : moreBounds) {\n          if (!bound.isWithin(point2X, point2Y, point2Z)) {\n            point2Valid = false;\n            break;\n          }\n        }\n      }\n\n      if (point1Valid && point2Valid) {\n        return new GeoPoint[]{new GeoPoint(point1X, point1Y, point1Z), new GeoPoint(point2X, point2Y, point2Z)};\n      }\n      if (point1Valid) {\n        return new GeoPoint[]{new GeoPoint(point1X, point1Y, point1Z)};\n      }\n      if (point2Valid) {\n        return new GeoPoint[]{new GeoPoint(point2X, point2Y, point2Z)};\n      }\n      return NO_POINTS;\n    } else {\n            return NO_POINTS;\n    }\n  }
41	public ArrayList<TernaryTreeNode> prefixCompletion(TernaryTreeNode root,\n          CharSequence s, int x) {\n\n    TernaryTreeNode p = root;\n    ArrayList<TernaryTreeNode> suggest = new ArrayList<>();\n\n    while (p != null) {\n      if (s.charAt(x) < p.splitchar) {\n        p = p.loKid;\n      } else if (s.charAt(x) == p.splitchar) {\n        if (x == s.length() - 1) {\n          break;\n        } else {\n          x++;\n        }\n        p = p.eqKid;\n      } else {\n        p = p.hiKid;\n      }\n    }\n\n    if (p == null) return suggest;\n    if (p.eqKid == null && p.token == null) return suggest;\n    if (p.eqKid == null && p.token != null) {\n      suggest.add(p);\n      return suggest;\n    }\n\n    if (p.token != null) {\n      suggest.add(p);\n    }\n    p = p.eqKid;\n\n    Stack<TernaryTreeNode> st = new Stack<>();\n    st.push(p);\n    while (!st.empty()) {\n      TernaryTreeNode top = st.peek();\n      st.pop();\n      if (top.token != null) {\n        suggest.add(top);\n      }\n      if (top.eqKid != null) {\n        st.push(top.eqKid);\n      }\n      if (top.loKid != null) {\n        st.push(top.loKid);\n      }\n      if (top.hiKid != null) {\n        st.push(top.hiKid);\n      }\n    }\n    return suggest;\n  }
42	protected void addPrefixMatch(StringBuilder sb, String surface, String analyzed, String prefixToken) {\n            if (prefixToken.length() >= surface.length()) {\n      addWholeMatch(sb, surface, analyzed);\n      return;\n    }\n    sb.append("<b>");\n    sb.append(surface.substring(0, prefixToken.length()));\n    sb.append("</b>");\n    sb.append(surface.substring(prefixToken.length()));\n  }
43	public static double axisLat(double centerLat, double radiusMeters) {\n                                                            final double PIO2 = Math.PI / 2D;\n    double l1 = toRadians(centerLat);\n    double r = (radiusMeters + 7E-2) / EARTH_MEAN_RADIUS_METERS;\n\n        if (Math.abs(l1) + r >= MAX_LAT_RADIANS) {\n      return centerLat >= 0 ? MAX_LAT_INCL : MIN_LAT_INCL;\n    }\n\n            l1 = centerLat >= 0 ? PIO2 - l1 : l1 + PIO2;\n\n    double l2 = Math.acos(Math.cos(l1) / Math.cos(r));\n    assert !Double.isNaN(l2);\n\n        l2 = centerLat >= 0 ? PIO2 - l2 : l2 - PIO2;\n\n    return toDegrees(l2);\n  }
44	private void validateIndexSort() throws CorruptIndexException {\n    Sort indexSort = config.getIndexSort();\n    if (indexSort != null) {\n      for(SegmentCommitInfo info : segmentInfos) {\n        Sort segmentIndexSort = info.info.getIndexSort();\n        if (segmentIndexSort != null && indexSort.equals(segmentIndexSort) == false) {\n          throw new IllegalArgumentException("cannot change previous indexSort=" + segmentIndexSort + " (from segment=" + info + ") to new indexSort=" + indexSort);\n        } else if (segmentIndexSort == null && info.info.getVersion().onOrAfter(Version.LUCENE_6_5_0)) {\n                    throw new CorruptIndexException("segment not sorted with indexSort=" + segmentIndexSort, info.info.toString());\n        }\n      }\n    }\n  }
45	private void flushBigram() {\n    clearAttributes();\n    char termBuffer[] = termAtt.resizeBuffer(4);     int len1 = Character.toChars(buffer[index], termBuffer, 0);\n    int len2 = len1 + Character.toChars(buffer[index+1], termBuffer, len1);\n    termAtt.setLength(len2);\n    offsetAtt.setOffset(startOffset[index], endOffset[index+1]);\n    typeAtt.setType(DOUBLE_TYPE);\n        if (outputUnigrams) {\n      posIncAtt.setPositionIncrement(0);\n      posLengthAtt.setPositionLength(2);\n    }\n    index++;\n  }
46	private void writeOutput(SortedSet<String> ASCIITLDs) throws IOException {\n    final DateFormat dateFormat = DateFormat.getDateTimeInstance\n      (DateFormat.FULL, DateFormat.FULL, Locale.ROOT);\n    dateFormat.setTimeZone(TimeZone.getTimeZone("UTC"));\n    final Writer writer = new OutputStreamWriter\n      (new FileOutputStream(outputFile), StandardCharsets.UTF_8);\n    try {\n      writer.write(APACHE_LICENSE);\n      writer.write("// Generated from IANA Root Zone Database <");\n      writer.write(tldFileURL.toString());\n      writer.write(">");\n      writer.write(NL);\n      if (tldFileLastModified > 0L) {\n        writer.write("// file version from ");\n        writer.write(dateFormat.format(tldFileLastModified));\n        writer.write(NL);\n      }\n      writer.write("// generated on ");\n      writer.write(dateFormat.format(new Date()));\n      writer.write(NL);\n      writer.write("// by ");\n      writer.write(this.getClass().getName());\n      writer.write(NL);\n      writer.write(NL);\n      writer.write("ASCIITLD = \".\" (");\n      writer.write(NL);\n      boolean isFirst = true;\n      for (String ASCIITLD : ASCIITLDs) {\n        writer.write("\t");\n        if (isFirst) {\n          isFirst = false;\n          writer.write("  "); \n        } else {\n          writer.write("| "); \n        }\n        writer.write(getCaseInsensitiveRegex(ASCIITLD));\n        writer.write(NL);\n      }\n      writer.write("\t) \".\"?   // Accept trailing root (empty) domain");\n      writer.write(NL);\n      writer.write(NL);\n    } finally {\n      writer.close();\n    }\n  }
47	public static boolean isParentClassLoader(final ClassLoader parent, final ClassLoader child) {\n    try {\n      ClassLoader cl = child;\n      while (cl != null) {\n        if (cl == parent) {\n          return true;\n        }\n        cl = cl.getParent();\n      }\n      return false;\n    } catch (SecurityException se) {\n      return false;\n    }\n  }
48	public static Automaton determinize(Automaton a, int maxDeterminizedStates) {\n    if (a.isDeterministic()) {\n            return a;\n    }\n    if (a.getNumStates() <= 1) {\n            return a;\n    }\n\n        Automaton.Builder b = new Automaton.Builder();\n\n        \n    SortedIntSet.FrozenIntSet initialset = new SortedIntSet.FrozenIntSet(0, 0);\n\n        b.createState();\n\n    ArrayDeque<SortedIntSet.FrozenIntSet> worklist = new ArrayDeque<>();\n    Map<SortedIntSet.FrozenIntSet,Integer> newstate = new HashMap<>();\n\n    worklist.add(initialset);\n\n    b.setAccept(0, a.isAccept(0));\n    newstate.put(initialset, 0);\n\n        final PointTransitionSet points = new PointTransitionSet();\n\n        final SortedIntSet statesSet = new SortedIntSet(5);\n\n    Transition t = new Transition();\n\n    while (worklist.size() > 0) {\n      SortedIntSet.FrozenIntSet s = worklist.removeFirst();\n      \n            for(int i=0;i<s.values.length;i++) {\n        final int s0 = s.values[i];\n        int numTransitions = a.getNumTransitions(s0);\n        a.initTransition(s0, t);\n        for(int j=0;j<numTransitions;j++) {\n          a.getNextTransition(t);\n          points.add(t);\n        }\n      }\n\n      if (points.count == 0) {\n                continue;\n      }\n\n      points.sort();\n\n      int lastPoint = -1;\n      int accCount = 0;\n\n      final int r = s.state;\n\n      for(int i=0;i<points.count;i++) {\n\n        final int point = points.points[i].point;\n\n        if (statesSet.upto > 0) {\n          assert lastPoint != -1;\n\n          statesSet.computeHash();\n          \n          Integer q = newstate.get(statesSet);\n          if (q == null) {\n            q = b.createState();\n            if (q >= maxDeterminizedStates) {\n              throw new TooComplexToDeterminizeException(a, maxDeterminizedStates);\n            }\n            final SortedIntSet.FrozenIntSet p = statesSet.freeze(q);\n                        worklist.add(p);\n            b.setAccept(q, accCount > 0);\n            newstate.put(p, q);\n          } else {\n            assert (accCount > 0 ? true:false) == b.isAccept(q): "accCount=" + accCount + " vs existing accept=" +\n              b.isAccept(q) + " states=" + statesSet;\n          }\n\n          \n          b.addTransition(r, q, lastPoint, point-1);\n        }\n\n                        int[] transitions = points.points[i].ends.transitions;\n        int limit = points.points[i].ends.next;\n        for(int j=0;j<limit;j+=3) {\n          int dest = transitions[j];\n          statesSet.decr(dest);\n          accCount -= a.isAccept(dest) ? 1:0;\n        }\n        points.points[i].ends.next = 0;\n\n                        transitions = points.points[i].starts.transitions;\n        limit = points.points[i].starts.next;\n        for(int j=0;j<limit;j+=3) {\n          int dest = transitions[j];\n          statesSet.incr(dest);\n          accCount += a.isAccept(dest) ? 1:0;\n        }\n        lastPoint = point;\n        points.points[i].starts.next = 0;\n      }\n      points.reset();\n      assert statesSet.upto == 0: "upto=" + statesSet.upto;\n    }\n\n    Automaton result = b.finish();\n    assert result.isDeterministic();\n    return result;\n  }
49	private void parseAffix(TreeMap<String,List<Integer>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns,\n                          Map<String,Integer> seenStrips) throws IOException, ParseException {\n    \n    BytesRefBuilder scratch = new BytesRefBuilder();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split("\\s+");\n\n    boolean crossProduct = args[2].equals("Y");\n    boolean isSuffix = conditionPattern == SUFFIX_CONDITION_REGEX_PATTERN;\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split("\\s+");\n\n                  if (ruleArgs.length < 4) {\n          throw new ParseException("The affix file contains a rule with less than four elements: " + line, reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals("0") ? "" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n            int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n        twoStageAffix = true;\n      }\n            if ("0".equals(affixArg)) {\n        affixArg = "";\n      }\n      \n      String condition = ruleArgs.length > 4 ? ruleArgs[4] : ".";\n            if (condition.startsWith("[") && condition.indexOf(']') == -1) {\n        condition = condition + "]";\n      }\n            if (condition.indexOf('-') >= 0) {\n        condition = escapeDash(condition);\n      }\n\n      final String regex;\n      if (".".equals(condition)) {\n        regex = ".*";       } else if (condition.equals(strip)) {\n        regex = ".*";                                                   } else {\n        regex = String.format(Locale.ROOT, conditionPattern, condition);\n      }\n      \n            Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException("Too many patterns, please report this to dev@lucene.apache.org");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        CharacterRunAutomaton pattern = new CharacterRunAutomaton(new RegExp(regex, RegExp.NONE).toAutomaton());\n        patterns.add(pattern);\n      }\n      \n      Integer stripOrd = seenStrips.get(strip);\n      if (stripOrd == null) {\n        stripOrd = seenStrips.size();\n        seenStrips.put(strip, stripOrd);\n        if (stripOrd > Character.MAX_VALUE) {\n          throw new UnsupportedOperationException("Too many unique strips, please report this to dev@lucene.apache.org");\n        }\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      encodeFlags(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch.get());\n      if (appendFlagsOrd < 0) {\n                appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n                throw new UnsupportedOperationException("Too many unique append flags, please report this to dev@lucene.apache.org");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd.intValue());\n            int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      if (isSuffix) {\n        affixArg = new StringBuilder(affixArg).reverse().toString();\n      }\n      \n      List<Integer> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<>();\n        affixes.put(affixArg, list);\n      }\n      list.add(currentAffix);\n      currentAffix++;\n    }\n  }
50	public Query rewrite(Query original) throws IOException {\n    Query query = original;\n    for (Query rewrittenQuery = query.rewrite(reader); rewrittenQuery != query;\n         rewrittenQuery = query.rewrite(reader)) {\n      query = rewrittenQuery;\n    }\n    return query;\n  }
51	private int newSlice(final int size) {\n    if (intUpto > INT_BLOCK_SIZE-size) {\n      nextBuffer();\n      assert assertSliceBuffer(buffer);\n    }\n      \n    final int upto = intUpto;\n    intUpto += size;\n    buffer[intUpto-1] = 1;\n    return upto;\n  }
52	private void zzDoEOF() {\n    if (!zzEOFDone) {\n      zzEOFDone = true;\n      switch (zzLexicalState) {\n    case SCRIPT:\n    case COMMENT:\n    case SCRIPT_COMMENT:\n    case STYLE:\n    case STYLE_COMMENT:\n    case SINGLE_QUOTED_STRING:\n    case DOUBLE_QUOTED_STRING:\n    case END_TAG_TAIL_EXCLUDE:\n    case END_TAG_TAIL_SUBSTITUTE:\n    case START_TAG_TAIL_EXCLUDE:\n    case SERVER_SIDE_INCLUDE:\n    case START_TAG_TAIL_SUBSTITUTE: {             cumulativeDiff += yychar - inputStart;\n            addOffCorrectMap(outputCharCount, cumulativeDiff);\n      outputSegment.clear();\n      eofReturnValue = -1;\n      break;\n    }\n    case CHARACTER_REFERENCE_TAIL: {                          cumulativeDiff += inputSegment.length() - outputSegment.length();\n            addOffCorrectMap(outputCharCount + outputSegment.length(), cumulativeDiff);\n      eofReturnValue = ( ! outputSegment.isRead()) ? outputSegment.nextChar() : -1;\n      break;\n    }\n    case BANG:\n    case CDATA:\n    case AMPERSAND:\n    case NUMERIC_CHARACTER:\n    case END_TAG_TAIL_INCLUDE:\n    case START_TAG_TAIL_INCLUDE:\n    case LEFT_ANGLE_BRACKET:\n    case LEFT_ANGLE_BRACKET_SLASH:\n    case LEFT_ANGLE_BRACKET_SPACE: {              outputSegment = inputSegment;\n      eofReturnValue = ( ! outputSegment.isRead()) ? outputSegment.nextChar() : -1;\n      break;\n    }\n    default: {\n      eofReturnValue = -1;\n    }\n  }\n\n    }\n  }
53	public static <V> CharArrayMap<V> unmodifiableMap(CharArrayMap<V> map) {\n    if (map == null)\n      throw new NullPointerException("Given map is null");\n    if (map == emptyMap() || map.isEmpty())\n      return emptyMap();\n    if (map instanceof UnmodifiableCharArrayMap)\n      return map;\n    return new UnmodifiableCharArrayMap<>(map);\n  }
54	MergeState merge() throws IOException {\n    if (!shouldMerge()) {\n      throw new IllegalStateException("Merge would result in 0 document segment");\n    }\n    mergeFieldInfos();\n    long t0 = 0;\n    if (mergeState.infoStream.isEnabled("SM")) {\n      t0 = System.nanoTime();\n    }\n    int numMerged = mergeFields();\n    if (mergeState.infoStream.isEnabled("SM")) {\n      long t1 = System.nanoTime();\n      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge stored fields [" + numMerged + " docs]");\n    }\n    assert numMerged == mergeState.segmentInfo.maxDoc(): "numMerged=" + numMerged + " vs mergeState.segmentInfo.maxDoc()=" + mergeState.segmentInfo.maxDoc();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, mergeState.segmentInfo,\n                                                                      mergeState.mergeFieldInfos, null, context);\n    if (mergeState.infoStream.isEnabled("SM")) {\n      t0 = System.nanoTime();\n    }\n    mergeTerms(segmentWriteState);\n    if (mergeState.infoStream.isEnabled("SM")) {\n      long t1 = System.nanoTime();\n      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge postings [" + numMerged + " docs]");\n    }\n\n    if (mergeState.infoStream.isEnabled("SM")) {\n      t0 = System.nanoTime();\n    }\n    if (mergeState.mergeFieldInfos.hasDocValues()) {\n      mergeDocValues(segmentWriteState);\n    }\n    if (mergeState.infoStream.isEnabled("SM")) {\n      long t1 = System.nanoTime();\n      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge doc values [" + numMerged + " docs]");\n    }\n\n    if (mergeState.infoStream.isEnabled("SM")) {\n      t0 = System.nanoTime();\n    }\n    if (mergeState.mergeFieldInfos.hasPointValues()) {\n      mergePoints(segmentWriteState);\n    }\n    if (mergeState.infoStream.isEnabled("SM")) {\n      long t1 = System.nanoTime();\n      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge points [" + numMerged + " docs]");\n    }\n    \n    if (mergeState.mergeFieldInfos.hasNorms()) {\n      if (mergeState.infoStream.isEnabled("SM")) {\n        t0 = System.nanoTime();\n      }\n      mergeNorms(segmentWriteState);\n      if (mergeState.infoStream.isEnabled("SM")) {\n        long t1 = System.nanoTime();\n        mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge norms [" + numMerged + " docs]");\n      }\n    }\n\n    if (mergeState.mergeFieldInfos.hasVectors()) {\n      if (mergeState.infoStream.isEnabled("SM")) {\n        t0 = System.nanoTime();\n      }\n      numMerged = mergeVectors();\n      if (mergeState.infoStream.isEnabled("SM")) {\n        long t1 = System.nanoTime();\n        mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge vectors [" + numMerged + " docs]");\n      }\n      assert numMerged == mergeState.segmentInfo.maxDoc();\n    }\n    \n        if (mergeState.infoStream.isEnabled("SM")) {\n      t0 = System.nanoTime();\n    }\n    codec.fieldInfosFormat().write(directory, mergeState.segmentInfo, "", mergeState.mergeFieldInfos, context);\n    if (mergeState.infoStream.isEnabled("SM")) {\n      long t1 = System.nanoTime();\n      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to write field infos [" + numMerged + " docs]");\n    }\n\n    return mergeState;\n  }
55	private String readLogicalPropertiesLine(BufferedReader reader) throws IOException {\n    final StringBuilder logicalLine = new StringBuilder();\n    String line;\n    do {\n      line = reader.readLine();\n      if (null == line) { \n        return null;\n      }\n    } while (BLANK_OR_COMMENT_LINE_PATTERN.matcher(line).matches());\n\n    Matcher backslashMatcher = TRAILING_BACKSLASH_PATTERN.matcher(line); \n        if (backslashMatcher.find() && 1 == (backslashMatcher.group(1).length() % 2)) {\n      final Matcher firstLineMatcher = TRAILING_WHITESPACE_BACKSLASH_PATTERN.matcher(line);\n      if (firstLineMatcher.matches()) {\n        logicalLine.append(firstLineMatcher.group(1));       }\n      line = reader.readLine();\n      while (null != line\n             && (backslashMatcher = TRAILING_BACKSLASH_PATTERN.matcher(line)).find()\n             && 1 == (backslashMatcher.group(1).length() % 2)) {\n                final Matcher goodStuffMatcher = WHITESPACE_GOODSTUFF_WHITESPACE_BACKSLASH_PATTERN.matcher(line);\n        if (goodStuffMatcher.matches()) {\n          logicalLine.append(goodStuffMatcher.group(1));\n        }\n        line = reader.readLine();\n      }\n      if (null != line) {\n                final Matcher leadingWhitespaceMatcher = LEADING_WHITESPACE_PATTERN.matcher(line);\n        if (leadingWhitespaceMatcher.matches()) {\n          line = leadingWhitespaceMatcher.group(1);         }\n        logicalLine.append(line);\n      }\n    } else {\n      logicalLine.append(line);\n    }\n        final Matcher leadingWhitespaceMatcher = LEADING_WHITESPACE_PATTERN.matcher(logicalLine);\n    final CharSequence leadingWhitespaceStripped = leadingWhitespaceMatcher.matches()\n                                                 ? leadingWhitespaceMatcher.group(1)\n                                                 : logicalLine;\n\n        StringBuilder output = new StringBuilder();\n    final int numChars = leadingWhitespaceStripped.length();\n    for (int pos = 0 ; pos < numChars - 1 ; ++pos) {\n      char ch = leadingWhitespaceStripped.charAt(pos);\n      if (ch == '\\') {\n        ch = leadingWhitespaceStripped.charAt(++pos);\n      }\n      output.append(ch);\n    }\n    if (numChars > 0) {\n      output.append(leadingWhitespaceStripped.charAt(numChars - 1));\n    }\n\n    return output.toString();\n  }
56	public  QualityStats [] execute(Judge judge, SubmissionReport submitRep, \n                                  PrintWriter qualityLog) throws Exception {\n    int nQueries = Math.min(maxQueries, qualityQueries.length);\n    QualityStats stats[] = new QualityStats[nQueries]; \n    for (int i=0; i<nQueries; i++) {\n      QualityQuery qq = qualityQueries[i];\n            Query q = qqParser.parse(qq);\n            long t1 = System.currentTimeMillis();\n      TopDocs td = searcher.search(q,maxResults);\n      long searchTime = System.currentTimeMillis()-t1;\n            if (judge!=null) {\n        stats[i] = analyzeQueryResults(qq, q, td, judge, qualityLog, searchTime);\n      }\n      if (submitRep!=null) {\n        submitRep.report(qq,td,docNameField,searcher);\n      }\n    } \n    if (submitRep!=null) {\n      submitRep.flush();\n    }\n    return stats;\n  }
57	private FieldInfos initFieldInfos() throws IOException {\n    if (!si.hasFieldUpdates()) {\n      return core.coreFieldInfos;\n    } else {\n            FieldInfosFormat fisFormat = si.info.getCodec().fieldInfosFormat();\n      final String segmentSuffix = Long.toString(si.getFieldInfosGen(), Character.MAX_RADIX);\n      return fisFormat.read(si.info.dir, si.info, segmentSuffix, IOContext.READONCE);\n    }\n  }
58	protected Query analyzeMultiPhrase(String field, TokenStream stream, int slop) throws IOException {\n    MultiPhraseQuery.Builder mpqb = newMultiPhraseQueryBuilder();\n    mpqb.setSlop(slop);\n    \n    TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n\n    PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class);\n    int position = -1;  \n    \n    List<Term> multiTerms = new ArrayList<>();\n    stream.reset();\n    while (stream.incrementToken()) {\n      int positionIncrement = posIncrAtt.getPositionIncrement();\n      \n      if (positionIncrement > 0 && multiTerms.size() > 0) {\n        if (enablePositionIncrements) {\n          mpqb.add(multiTerms.toArray(new Term[0]), position);\n        } else {\n          mpqb.add(multiTerms.toArray(new Term[0]));\n        }\n        multiTerms.clear();\n      }\n      position += positionIncrement;\n      multiTerms.add(new Term(field, termAtt.getBytesRef()));\n    }\n    \n    if (enablePositionIncrements) {\n      mpqb.add(multiTerms.toArray(new Term[0]), position);\n    } else {\n      mpqb.add(multiTerms.toArray(new Term[0]));\n    }\n    return mpqb.build();\n  }
59	public int stem(char s[], int len) {\n    if (len < 4)       return len;\n    \n    final int origLen = len;\n        len = rule0(s, len);\n    len = rule1(s, len);\n    len = rule2(s, len);\n    len = rule3(s, len);\n    len = rule4(s, len);\n    len = rule5(s, len);\n    len = rule6(s, len);\n    len = rule7(s, len);\n    len = rule8(s, len);\n    len = rule9(s, len);\n    len = rule10(s, len);\n    len = rule11(s, len);\n    len = rule12(s, len);\n    len = rule13(s, len);\n    len = rule14(s, len);\n    len = rule15(s, len);\n    len = rule16(s, len);\n    len = rule17(s, len);\n    len = rule18(s, len);\n    len = rule19(s, len);\n    len = rule20(s, len);\n        if (len == origLen)\n      len = rule21(s, len);\n    \n    return rule22(s, len);\n  }
60	public static String geoTermToString(long term) {\n    StringBuilder s = new StringBuilder(64);\n    final int numberOfLeadingZeros = Long.numberOfLeadingZeros(term);\n    for (int i = 0; i < numberOfLeadingZeros; i++) {\n      s.append('0');\n    }\n    if (term != 0) {\n      s.append(Long.toBinaryString(term));\n    }\n    return s.toString();\n  }
61	public synchronized void setHierarchical(String dimName, boolean v) {\n    DimConfig ft = fieldTypes.get(dimName);\n    if (ft == null) {\n      ft = new DimConfig();\n      fieldTypes.put(dimName, ft);\n    }\n    ft.hierarchical = v;\n  }
62	public final G acquire() throws IOException {\n    G ref;\n\n    do {\n      if ((ref = current) == null) {\n        throw new AlreadyClosedException(REFERENCE_MANAGER_IS_CLOSED_MSG);\n      }\n      if (tryIncRef(ref)) {\n        return ref;\n      }\n      if (getRefCount(ref) == 0 && current == ref) {\n        assert ref != null;\n        \n        throw new IllegalStateException("The managed reference has already closed - this is likely a bug when the reference count is modified outside of the ReferenceManager");\n      }\n    } while (true);\n  }
63	protected synchronized void maybeNewPrimary(long newPrimaryGen) throws IOException {\n    if (newPrimaryGen != lastPrimaryGen) {\n      message("top: now change lastPrimaryGen from " + lastPrimaryGen + " to " + newPrimaryGen + " pendingMergeFiles=" + pendingMergeFiles);\n\n      message("top: delete if no ref pendingMergeFiles=" + pendingMergeFiles);\n      for(String fileName : pendingMergeFiles) {\n        deleter.deleteIfNoRef(fileName);\n      }\n\n      assert newPrimaryGen > lastPrimaryGen: "newPrimaryGen=" + newPrimaryGen + " vs lastPrimaryGen=" + lastPrimaryGen;\n      lastPrimaryGen = newPrimaryGen;\n      pendingMergeFiles.clear();\n    } else {\n      message("top: keep current lastPrimaryGen=" + lastPrimaryGen);\n    }\n  }
64	final synchronized void mergeFinish(MergePolicy.OneMerge merge) {\n\n            notifyAll();\n\n            if (merge.registerDone) {\n      final List<SegmentCommitInfo> sourceSegments = merge.segments;\n      for (SegmentCommitInfo info : sourceSegments) {\n        mergingSegments.remove(info);\n      }\n      merge.registerDone = false;\n    }\n\n    runningMerges.remove(merge);\n  }
65	public void addLatLine(double lat, double minLon, double maxLon) {\n    String name = "latline" + nextShape;\n    nextShape++;\n\n    b.append("        var " + name + " = WE.polygon([\n");\n    double lon;\n    int steps = getStepCount(lat, minLon, lat, maxLon);\n    for(lon = minLon;lon<=maxLon;lon += (maxLon-minLon)/steps) {\n      b.append("          [" + lat + ", " + lon + "],\n");\n    }\n    b.append("          [" + lat + ", " + maxLon + "],\n");\n    lon -= (maxLon-minLon)/steps;\n    for(;lon>=minLon;lon -= (maxLon-minLon)/steps) {\n      b.append("          [" + lat + ", " + lon + "],\n");\n    }\n    b.append("        ], {color: \"#ff0000\", fillColor: \"#ffffff\", opacity: 1, fillOpacity: 0.0001});\n");\n    b.append("        " + name + ".addTo(earth);\n");\n  }
66	public void xor(DocIdSetIterator iter) throws IOException {\n    checkUnpositioned(iter);\n    if (BitSetIterator.getFixedBitSetOrNull(iter) != null) {\n      final FixedBitSet bits = BitSetIterator.getFixedBitSetOrNull(iter); \n      xor(bits);\n    } else {\n      int doc;\n      while ((doc = iter.nextDoc()) < numBits) {\n        flip(doc);\n      }\n    }\n  }
67	public void addTransition(int source, int dest, int min, int max) {\n    assert nextTransition%3 == 0;\n\n    if (source >= nextState/2) {\n      throw new IllegalArgumentException("source=" + source + " is out of bounds (maxState is " + (nextState/2-1) + ")");\n    }\n    if (dest >= nextState/2) {\n      throw new IllegalArgumentException("dest=" + dest + " is out of bounds (max state is " + (nextState/2-1) + ")");\n    }\n\n    growTransitions();\n    if (curState != source) {\n      if (curState != -1) {\n        finishCurrentState();\n      }\n\n            curState = source;\n      if (states[2*curState] != -1) {\n        throw new IllegalStateException("from state (" + source + ") already had transitions added");\n      }\n      assert states[2*curState+1] == 0;\n      states[2*curState] = nextTransition;\n    }\n\n    transitions[nextTransition++] = dest;\n    transitions[nextTransition++] = min;\n    transitions[nextTransition++] = max;\n\n        states[2*curState+1]++;\n  }
68	static void addVmOpt(StringBuilder b, String key, Object value) {\n    if (value == null) return;\n\n    b.append(" -D").append(key).append("=");\n    String v = value.toString();\n            if (Pattern.compile("[\\s=']").matcher(v).find()) {\n      v = '"' + v + '"';\n    }\n    b.append(v);\n  }
69	private ArrayList<Completion> lookupSortedByWeight(BytesRef key, \n      int num, boolean collectAll) throws IOException {\n                final ArrayList<Completion> res = new ArrayList<>(Math.min(10, num));\n\n    final BytesRef output = BytesRef.deepCopyOf(key);\n    for (int i = 0; i < rootArcs.length; i++) {\n      final FST.Arc<Object> rootArc = rootArcs[i];\n      final FST.Arc<Object> arc = new FST.Arc<>().copyFrom(rootArc);\n\n            if (descendWithPrefix(arc, key)) {\n                                output.length = key.length - 1;\n        if (collect(res, num, rootArc.label, output, arc) && !collectAll) {\n                                        if (exactFirst) {\n            if (!checkExistingAndReorder(res, key)) {\n              int exactMatchBucket = getExactMatchStartingFromRootArc(i, key);\n              if (exactMatchBucket != -1) {\n                                while (res.size() >= num) {\n                  res.remove(res.size() - 1);\n                }\n                res.add(0, new Completion(key, exactMatchBucket));\n              }\n            }\n          }\n          break;\n        }\n      }\n    }\n    return res;\n  }
70	void markEnd (int numParallelTasks, int count) {\n    elapsed = System.currentTimeMillis() - start;\n    long totMem = Runtime.getRuntime().totalMemory();\n    if (totMem > maxTotMem) {\n      maxTotMem = totMem;\n    }\n    long usedMem = totMem - Runtime.getRuntime().freeMemory();\n    if (usedMem > maxUsedMem) {\n      maxUsedMem = usedMem;\n    }\n    this.numParallelTasks = numParallelTasks;\n    this.count = count;\n  }
71	public static Document loadXML(Reader is) {\n    DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();\n    DocumentBuilder db = null;\n\n    try {\n      db = dbf.newDocumentBuilder();\n    }\n    catch (Exception se) {\n      throw new RuntimeException("Parser configuration error", se);\n    }\n\n        org.w3c.dom.Document doc = null;\n    try {\n      doc = db.parse(new InputSource(is));\n          }\n    catch (Exception se) {\n      throw new RuntimeException("Error parsing file:" + se, se);\n    }\n\n    return doc;\n  }
72	public long writeSkip(IndexOutput output) throws IOException {\n    long skipPointer = output.getFilePointer();\n        if (skipBuffer == null || skipBuffer.length == 0) return skipPointer;\n    \n    for (int level = numberOfSkipLevels - 1; level > 0; level--) {\n      long length = skipBuffer[level].getFilePointer();\n      if (length > 0) {\n        output.writeVLong(length);\n        skipBuffer[level].writeTo(output);\n      }\n    }\n    skipBuffer[0].writeTo(output);\n    \n    return skipPointer;\n  }
73	public static IndexSearcher wrapUnderlyingReader(Random random, final IndexSearcher s, final int edge)\n    throws IOException {\n\n    IndexReader r = s.getIndexReader();\n\n            IndexReader[] readers = new IndexReader[] {\n      edge < 0 ? r : new MultiReader(),\n      new MultiReader(),\n      new MultiReader(edge < 0 ? emptyReader(4) : new MultiReader(),\n          new MultiReader(),\n          0 == edge ? r : new MultiReader()),\n      0 < edge ? new MultiReader() : emptyReader(7),\n      new MultiReader(),\n      new MultiReader(0 < edge ? new MultiReader() : emptyReader(5),\n          new MultiReader(),\n          0 < edge ? r : new MultiReader())\n    };\n\n    IndexSearcher out = LuceneTestCase.newSearcher(new MultiReader(readers));\n    out.setSimilarity(s.getSimilarity(true));\n    return out;\n  }
74	public static Mutable getMutable(int valueCount,\n      int bitsPerValue, PackedInts.Format format) {\n    assert valueCount >= 0;\n    switch (format) {\n      case PACKED_SINGLE_BLOCK:\n        return Packed64SingleBlock.create(valueCount, bitsPerValue);\n      case PACKED:\n        switch (bitsPerValue) {\n          case 8:\n            return new Direct8(valueCount);\n          case 16:\n            return new Direct16(valueCount);\n          case 32:\n            return new Direct32(valueCount);\n          case 64:\n            return new Direct64(valueCount);\n          case 24:\n            if (valueCount <= Packed8ThreeBlocks.MAX_SIZE) {\n              return new Packed8ThreeBlocks(valueCount);\n            }\n            break;\n          case 48:\n            if (valueCount <= Packed16ThreeBlocks.MAX_SIZE) {\n              return new Packed16ThreeBlocks(valueCount);\n            }\n            break;\n        }\n        return new Packed64(valueCount, bitsPerValue);\n      default:\n        throw new AssertionError();\n    }\n  }
75	public static Trie load(InputStream stemmerTable) throws IOException {\n    DataInputStream in = null;\n    try {\n      in = new DataInputStream(new BufferedInputStream(stemmerTable));\n      String method = in.readUTF().toUpperCase(Locale.ROOT);\n      if (method.indexOf('M') < 0) {\n        return new org.egothor.stemmer.Trie(in);\n      } else {\n        return new org.egothor.stemmer.MultiTrie2(in);\n      }\n    } finally {\n      in.close();\n    }\n  }
76	private void expandDelimiterData() {\n    int i;\n    int cnt;\n            int delimiterIndex = 3755 + GB2312_FIRST_CHAR;\n    i = 0;\n    while (i < wordItem_charArrayTable[delimiterIndex].length) {\n      char c = wordItem_charArrayTable[delimiterIndex][i][0];\n      int j = getGB2312Id(c);      if (wordItem_charArrayTable[j] == null) {\n\n        int k = i;\n                while (k < wordItem_charArrayTable[delimiterIndex].length\n            && wordItem_charArrayTable[delimiterIndex][k][0] == c) {\n          k++;\n        }\n                        cnt = k - i;\n        if (cnt != 0) {\n          wordItem_charArrayTable[j] = new char[cnt][];\n          wordItem_frequencyTable[j] = new int[cnt];\n        }\n\n                for (k = 0; k < cnt; k++, i++) {\n                    wordItem_frequencyTable[j][k] = wordItem_frequencyTable[delimiterIndex][i];\n          wordItem_charArrayTable[j][k] = new char[wordItem_charArrayTable[delimiterIndex][i].length - 1];\n          System.arraycopy(wordItem_charArrayTable[delimiterIndex][i], 1,\n              wordItem_charArrayTable[j][k], 0,\n              wordItem_charArrayTable[j][k].length);\n        }\n        setTableIndex(c, j);\n      }\n    }\n        wordItem_charArrayTable[delimiterIndex] = null;\n    wordItem_frequencyTable[delimiterIndex] = null;\n  }
77	public synchronized void prune(Pruner pruner) throws IOException {\n                    final List<SearcherTracker> trackers = new ArrayList<>();\n    for(SearcherTracker tracker : searchers.values()) {\n      trackers.add(tracker);\n    }\n    Collections.sort(trackers);\n    double lastRecordTimeSec = 0.0;\n    final double now = System.nanoTime()/NANOS_PER_SEC;\n    for (SearcherTracker tracker: trackers) {\n      final double ageSec;\n      if (lastRecordTimeSec == 0.0) {\n        ageSec = 0.0;\n      } else {\n        ageSec = now - lastRecordTimeSec;\n      }\n                              if (pruner.doPrune(ageSec, tracker.searcher)) {\n                searchers.remove(tracker.version);\n        tracker.close();\n      }\n      lastRecordTimeSec = tracker.recordTimeSec;\n    }\n  }
78	int nextRun() {\n    final int runBase = runEnd(0);\n    assert runBase < to;\n    if (runBase == to - 1) {\n      return 1;\n    }\n    int o = runBase + 2;\n    if (compare(runBase, runBase+1) > 0) {\n            while (o < to && compare(o - 1, o) > 0) {\n        ++o;\n      }\n      reverse(runBase, o);\n    } else {\n            while (o < to && compare(o - 1, o) <= 0) {\n        ++o;\n      }\n    }\n    final int runHi = Math.max(o, Math.min(to, runBase + minRun));\n    binarySort(runBase, runHi, o);\n    return runHi - runBase;\n  }
79	private int allocSlice(final int[] slice, final int sliceOffset) {\n    final int level = slice[sliceOffset];\n    final int newLevel = NEXT_LEVEL_ARRAY[level-1];\n    final int newSize = LEVEL_SIZE_ARRAY[newLevel];\n        if (intUpto > INT_BLOCK_SIZE-newSize) {\n      nextBuffer();\n      assert assertSliceBuffer(buffer);\n    }\n\n    final int newUpto = intUpto;\n    final int offset = newUpto + intOffset;\n    intUpto += newSize;\n        slice[sliceOffset] = offset;\n        \n        buffer[intUpto-1] = newLevel;\n\n    return newUpto;\n  }
80	public synchronized TaskStats markTaskStart (PerfTask task, int round) {\n    TaskStats stats = new TaskStats(task, nextTaskRunNum(), round);\n    this.currentStats = stats;\n    points.add(stats);\n    return stats;\n  }
81	public int getCalPrecisionField(Calendar cal) {\n    int lastField = -1;\n    for (int level = YEAR_LEVEL; level < FIELD_BY_LEVEL.length; level++) {\n      int field = FIELD_BY_LEVEL[level];\n      if (!cal.isSet(field))\n        break;\n      lastField = field;\n    }\n    return lastField;\n  }
82	public static void checkHitCollector(Random random, Query query, String defaultFieldName,\n                                       IndexSearcher searcher, int[] results)\n    throws IOException {\n\n    QueryUtils.check(random,query,searcher);\n    \n    Set<Integer> correct = new TreeSet<>();\n    for (int i = 0; i < results.length; i++) {\n      correct.add(Integer.valueOf(results[i]));\n    }\n    final Set<Integer> actual = new TreeSet<>();\n    final Collector c = new SetCollector(actual);\n\n    searcher.search(query, c);\n    Assert.assertEquals("Simple: " + query.toString(defaultFieldName), \n                        correct, actual);\n\n    for (int i = -1; i < 2; i++) {\n      actual.clear();\n      IndexSearcher s = QueryUtils.wrapUnderlyingReader\n        (random, searcher, i);\n      s.search(query, c);\n      Assert.assertEquals("Wrap Reader " + i + ": " +\n                          query.toString(defaultFieldName),\n                          correct, actual);\n    }\n  }
83	boolean next() {\n    if (scriptLimit >= limit)\n      return false;\n\n    scriptCode = UScript.COMMON;\n    scriptStart = scriptLimit;\n\n    while (index < limit) {\n      final int ch = UTF16.charAt(text, start, limit, index - start);\n      final int sc = getScript(ch);\n\n      \n      if (isSameScript(scriptCode, sc)\n          || UCharacter.getType(ch) == ECharacterCategory.NON_SPACING_MARK) {\n        index += UTF16.getCharCount(ch);\n\n        \n        if (scriptCode <= UScript.INHERITED && sc > UScript.INHERITED) {\n          scriptCode = sc;\n        }\n\n      } else {\n        break;\n      }\n    }\n\n    scriptLimit = index;\n    return true;\n  }
84	public Map<String, String[]> highlightFields(String[] fieldsIn, Query query, int[] docidsIn, int[] maxPassagesIn)\n      throws IOException {\n    Map<String, String[]> snippets = new HashMap<>();\n    for (Map.Entry<String, Object[]> ent : highlightFieldsAsObjects(fieldsIn, query, docidsIn, maxPassagesIn).entrySet()) {\n      Object[] snippetObjects = ent.getValue();\n      String[] snippetStrings = new String[snippetObjects.length];\n      snippets.put(ent.getKey(), snippetStrings);\n      for (int i = 0; i < snippetObjects.length; i++) {\n        Object snippet = snippetObjects[i];\n        if (snippet != null) {\n          snippetStrings[i] = snippet.toString();\n        }\n      }\n    }\n\n    return snippets;\n  }
85	private boolean initComplex() throws IOException {\n        placeFirstPositions();\n    if (!advanceRepeatGroups()) {\n      return false;     }\n    fillQueue();\n    return true;   }
86	Query makeDisjoint(Rectangle bbox) {\n\n        \n            Query qMinY = this.makeNumericRangeQuery(field_minY, bbox.getMaxY(), null, false, false);\n    Query qMaxY = this.makeNumericRangeQuery(field_maxY, null, bbox.getMinY(), false, false);\n    Query yConditions = this.makeQuery(BooleanClause.Occur.SHOULD, qMinY, qMaxY);\n\n        Query xConditions;\n\n        if (!bbox.getCrossesDateLine()) {\n\n                  Query qMinX = this.makeNumericRangeQuery(field_minX, bbox.getMaxX(), null, false, false);\n      if (bbox.getMinX() == -180.0 && ctx.isGeo()) {        BooleanQuery.Builder bq = new BooleanQuery.Builder();\n        bq.add(qMinX, BooleanClause.Occur.MUST);\n        bq.add(makeNumberTermQuery(field_maxX, 180.0), BooleanClause.Occur.MUST_NOT);\n        qMinX = bq.build();\n      }\n      Query qMaxX = this.makeNumericRangeQuery(field_maxX, null, bbox.getMinX(), false, false);\n\n      if (bbox.getMaxX() == 180.0 && ctx.isGeo()) {        BooleanQuery.Builder bq = new BooleanQuery.Builder();\n        bq.add(qMaxX, BooleanClause.Occur.MUST);\n        bq.add(makeNumberTermQuery(field_minX, -180.0), BooleanClause.Occur.MUST_NOT);\n        qMaxX = bq.build();\n      }\n      Query qMinMax = this.makeQuery(BooleanClause.Occur.SHOULD, qMinX, qMaxX);\n      Query qNonXDL = this.makeXDL(false, qMinMax);\n\n      if (!ctx.isGeo()) {\n        xConditions = qNonXDL;\n      } else {\n        \n                                                        Query qMinXLeft = this.makeNumericRangeQuery(field_minX, bbox.getMaxX(), null, false, false);\n        Query qMaxXRight = this.makeNumericRangeQuery(field_maxX, null, bbox.getMinX(), false, false);\n        Query qLeftRight = this.makeQuery(BooleanClause.Occur.MUST, qMinXLeft, qMaxXRight);\n        Query qXDL = this.makeXDL(true, qLeftRight);\n\n                xConditions = this.makeQuery(BooleanClause.Occur.SHOULD, qNonXDL, qXDL);\n      }\n          } else {\n\n                              Query qMinXLeft = this.makeNumericRangeQuery(field_minX, 180.0, null, false, false);\n      Query qMaxXLeft = this.makeNumericRangeQuery(field_maxX, null, bbox.getMinX(), false, false);\n      Query qMinXRight = this.makeNumericRangeQuery(field_minX, bbox.getMaxX(), null, false, false);\n      Query qMaxXRight = this.makeNumericRangeQuery(field_maxX, null, -180.0, false, false);\n      Query qLeft = this.makeQuery(BooleanClause.Occur.SHOULD, qMinXLeft, qMaxXLeft);\n      Query qRight = this.makeQuery(BooleanClause.Occur.SHOULD, qMinXRight, qMaxXRight);\n      Query qLeftRight = this.makeQuery(BooleanClause.Occur.MUST, qLeft, qRight);\n\n      \n      xConditions = this.makeXDL(false, qLeftRight);\n    }\n\n        return this.makeQuery(BooleanClause.Occur.SHOULD, xConditions, yConditions);\n  }
87	private static void checkTermRanges(String field, int maxDoc, Terms terms, long numTerms) throws IOException {\n\n        double currentInterval = numTerms;\n\n    FixedBitSet normalDocs = new FixedBitSet(maxDoc);\n    FixedBitSet intersectDocs = new FixedBitSet(maxDoc);\n\n    \n    while (currentInterval >= 10.0) {\n      \n            TermsEnum termsEnum = terms.iterator();\n\n      long termCount = 0;\n\n      Deque<BytesRef> termBounds = new LinkedList<>();\n\n      long lastTermAdded = Long.MIN_VALUE;\n\n      BytesRefBuilder lastTerm = null;\n\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n                if (termCount >= lastTermAdded + currentInterval/4) {\n          termBounds.add(BytesRef.deepCopyOf(term));\n          lastTermAdded = termCount;\n          if (termBounds.size() == 5) {\n            BytesRef minTerm = termBounds.removeFirst();\n            BytesRef maxTerm = termBounds.getLast();\n            checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n          }\n        }\n        termCount++;\n\n        if (lastTerm == null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.copyBytes(term);\n        } else {\n          if (lastTerm.get().compareTo(term) >= 0) {\n            throw new RuntimeException("terms out of order: lastTerm=" + lastTerm.get() + " term=" + term);\n          }\n          lastTerm.copyBytes(term);\n        }\n      }\n      \n      if (lastTerm != null && termBounds.isEmpty() == false) {\n        BytesRef minTerm = termBounds.removeFirst();\n        BytesRef maxTerm = lastTerm.get();\n        checkSingleTermRange(field, maxDoc, terms, minTerm, maxTerm, normalDocs, intersectDocs);\n      }\n\n      currentInterval *= .75;\n    }\n  }
88	protected Set<BytesRef> decodeContexts(BytesRef scratch, ByteArrayDataInput tmpInput) {\n    tmpInput.reset(scratch.bytes, scratch.offset, scratch.length);\n    tmpInput.skipBytes(scratch.length - 2);     short ctxSetSize = tmpInput.readShort();\n    scratch.length -= 2;\n    final Set<BytesRef> contextSet = new HashSet<>();\n    for (short i = 0; i < ctxSetSize; i++) {\n      tmpInput.setPosition(scratch.offset + scratch.length - 2);\n      short curContextLength = tmpInput.readShort();\n      scratch.length -= 2;\n      tmpInput.setPosition(scratch.offset + scratch.length - curContextLength);\n      BytesRef contextSpare = new BytesRef(curContextLength);\n      tmpInput.readBytes(contextSpare.bytes, 0, curContextLength);\n      contextSpare.length = curContextLength;\n      contextSet.add(contextSpare);\n      scratch.length -= curContextLength;\n    }\n    return contextSet;\n  }
89	private void bufferWordParts() throws IOException {\n\n    saveState();\n\n            hasIllegalOffsets = (savedEndOffset - savedStartOffset != savedTermLength);\n\n    bufferedLen = 0;\n    lastConcatCount = 0;\n    wordPos = 0;\n\n    if (iterator.isSingleWord()) {\n      buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n      wordPos++;\n      iterator.next();\n    } else {\n\n            while (iterator.end != WordDelimiterIterator.DONE) {\n        int wordType = iterator.type();\n      \n                if (concat.isNotEmpty() && (concat.type & wordType) == 0) {\n          flushConcatenation(concat);\n        }\n\n                if (shouldConcatenate(wordType)) {\n          concatenate(concat);\n        }\n      \n                if (has(CATENATE_ALL)) {\n          concatenate(concatAll);\n        }\n      \n                if (shouldGenerateParts(wordType)) {\n          buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n          wordPos++;\n        }\n        iterator.next();\n      }\n\n      if (concat.isNotEmpty()) {\n                flushConcatenation(concat);\n      }\n        \n      if (concatAll.isNotEmpty()) {\n                if (concatAll.subwordCount > lastConcatCount) {\n          if (wordPos == concatAll.startPos) {\n                        wordPos++;\n          }\n          concatAll.write();\n        }\n        concatAll.clear();\n      }\n    }\n\n    if (has(PRESERVE_ORIGINAL)) {\n      if (wordPos == 0) {\n                wordPos++;\n      }\n            buffer(0, wordPos, 0, savedTermLength);\n    }\n            \n    sorter.sort(0, bufferedLen);\n    wordPos = 0;\n\n        bufferedPos = 0;\n  }
90	public static Automaton build(Collection<BytesRef> input) {\n    final DaciukMihovAutomatonBuilder builder = new DaciukMihovAutomatonBuilder();\n    \n    char[] chars = new char[0];\n    CharsRef ref = new CharsRef();\n    for (BytesRef b : input) {\n      chars = ArrayUtil.grow(chars, b.length);\n      final int len = UnicodeUtil.UTF8toUTF16(b, chars);\n      ref.chars = chars;\n      ref.length = len;\n      builder.add(ref);\n    }\n    \n    Automaton.Builder a = new Automaton.Builder();\n    convert(a,\n        builder.complete(), \n        new IdentityHashMap<State,Integer>());\n\n    return a.finish();\n  }
91	public void setRangeValues(double minLat, double minLon, double maxLat, double maxLon) {\n    checkArgs(minLat, minLon, maxLat, maxLon);\n    final byte[] bytes;\n    if (fieldsData == null) {\n      bytes = new byte[4*BYTES];\n      fieldsData = new BytesRef(bytes);\n    } else {\n      bytes = ((BytesRef)fieldsData).bytes;\n    }\n    encode(minLat, minLon, bytes, 0);\n    encode(maxLat, maxLon, bytes, 2 * BYTES);\n  }
92	public static int strcmp(char[] a, int startA, char[] b, int startB) {\n    for (; a[startA] == b[startB]; startA++, startB++) {\n      if (a[startA] == 0) {\n        return 0;\n      }\n    }\n    return a[startA] - b[startB];\n  }
93	private boolean resolveTransitively(File ivyXmlFile) {\n    boolean success = true;\n\n    ResolveOptions options = new ResolveOptions();\n    options.setDownload(false);               options.setTransitive(true);              options.setUseCacheOnly(false);           options.setOutputReport(false);           options.setLog(LogOptions.LOG_QUIET);     options.setConfs(new String[] {"*"}); \n            String moduleName = "unknown";\n    String ivyXmlContent = xmlToString(ivyXmlFile);\n    Matcher matcher = MODULE_NAME_PATTERN.matcher(ivyXmlContent);\n    if (matcher.find()) {\n      moduleName = matcher.group(1);\n    }\n    ivyXmlContent = ivyXmlContent.replaceAll("\\btransitive\\s*=\\s*[\"']false[\"']", "transitive=\"true\"");\n    File transitiveIvyXmlFile = null;\n    try {\n      File buildDir = new File(commonBuildDir, "ivy-transitive-resolve");\n      if ( ! buildDir.exists() && ! buildDir.mkdirs()) {\n        throw new BuildException("Could not create temp directory " + buildDir.getPath());\n      }\n      matcher = MODULE_DIRECTORY_PATTERN.matcher(ivyXmlFile.getCanonicalPath());\n      if ( ! matcher.matches()) {\n        throw new BuildException("Unknown ivy.xml module directory: " + ivyXmlFile.getCanonicalPath());\n      }\n      String moduleDirPrefix = matcher.group(1).replaceAll("[/\\\\]", ".");\n      transitiveIvyXmlFile = new File(buildDir, "transitive." + moduleDirPrefix + ".ivy.xml");\n      try (Writer writer = new OutputStreamWriter(new FileOutputStream(transitiveIvyXmlFile), StandardCharsets.UTF_8)) {\n        writer.write(ivyXmlContent);\n      }\n      ResolveReport resolveReport = ivy.resolve(transitiveIvyXmlFile.toURI().toURL(), options);\n      IvyNodeElement root = IvyNodeElementAdapter.adapt(resolveReport);\n      for (IvyNodeElement directDependency : root.getDependencies()) {\n        String coordinate = "/" + directDependency.getOrganization() + "/" + directDependency.getName();\n        Dependency dependency = directDependencies.get(coordinate);\n        if (null == dependency) {\n          log("ERROR: the following coordinate key does not appear in " \n              + centralizedVersionsFile.getName() + ": " + coordinate);\n          success = false;\n        } else {\n          dependency.directlyReferenced = true;\n          if (collectConflicts(directDependency, directDependency, moduleName)) {\n            success = false;\n          }\n        }\n      }\n    } catch (ParseException | IOException e) {\n      if (null != transitiveIvyXmlFile) {\n        log("Exception reading " + transitiveIvyXmlFile.getPath() + ": " + e.toString());\n      }\n      success = false;\n    }\n    return success;\n  }
94	public String normalizeNumber(String number) {\n    try {\n      BigDecimal normalizedNumber = parseNumber(new NumberBuffer(number));\n      if (normalizedNumber == null) {\n        return number;\n      }\n      return normalizedNumber.stripTrailingZeros().toPlainString();\n    } catch (NumberFormatException | ArithmeticException e) {\n            return number;\n    }\n  }
95	public static byte[] encode(InetAddress value) {\n    byte[] address = value.getAddress();\n    if (address.length == 4) {\n      byte[] mapped = new byte[16];\n      System.arraycopy(IPV4_PREFIX, 0, mapped, 0, IPV4_PREFIX.length);\n      System.arraycopy(address, 0, mapped, IPV4_PREFIX.length, address.length);\n      address = mapped;\n    } else if (address.length != 16) {\n            throw new UnsupportedOperationException("Only IPv4 and IPv6 addresses are supported");\n    }\n    return address;\n  }
96	public void getTransition(int state, int index, Transition t) {\n    int i = states[2*state] + 3*index;\n    t.source = state;\n    t.dest = transitions[i++];\n    t.min = transitions[i++];\n    t.max = transitions[i++];\n  }
97	public void init(long skipPointer, int df) throws IOException {\n    this.skipPointer[0] = skipPointer;\n    this.docCount = df;\n    assert skipPointer >= 0 && skipPointer <= skipStream[0].length() \n    : "invalid skip pointer: " + skipPointer + ", length=" + skipStream[0].length();\n    Arrays.fill(skipDoc, 0);\n    Arrays.fill(numSkipped, 0);\n    Arrays.fill(childPointer, 0);\n    \n    for (int i = 1; i < numberOfSkipLevels; i++) {\n      skipStream[i] = null;\n    }\n    loadSkipLevels();\n  }
98	protected String longestOp(Iterable<TaskStats> taskStats) {\n    String longest = OP;\n    for (final TaskStats stat : taskStats) {\n      if (stat.getElapsed()>=0) {         String name = stat.getTask().getName();\n        if (name.length() > longest.length()) {\n          longest = name;\n        }\n      }\n    }\n    return longest;\n  }
99	public static Polygon2D create(Polygon... polygons) {\n    Polygon2D components[] = new Polygon2D[polygons.length];\n    for (int i = 0; i < components.length; i++) {\n      Polygon gon = polygons[i];\n      Polygon gonHoles[] = gon.getHoles();\n      Polygon2D holes = null;\n      if (gonHoles.length > 0) {\n        holes = create(gonHoles);\n      }\n      components[i] = new Polygon2D(gon, holes);\n    }\n    return createTree(components, 0, components.length - 1, false);\n  }
100	private List<FacetResult> facetsOnly() throws IOException {\n    DirectoryReader indexReader = DirectoryReader.open(indexDir);\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);\n\n    FacetsCollector fc = new FacetsCollector();\n\n                searcher.search(new MatchAllDocsQuery(), fc);\n\n        List<FacetResult> results = new ArrayList<>();\n\n        Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, fc);\n   \n    results.add(facets.getTopChildren(10, "Author"));\n    results.add(facets.getTopChildren(10, "Publish Date"));\n    \n    indexReader.close();\n    taxoReader.close();\n    \n    return results;\n  }
101	private static byte[] encodeCeil(double latitude, double longitude) {\n    byte[] bytes = new byte[2 * Integer.BYTES];\n    NumericUtils.intToSortableBytes(encodeLatitudeCeil(latitude), bytes, 0);\n    NumericUtils.intToSortableBytes(encodeLongitudeCeil(longitude), bytes, Integer.BYTES);\n    return bytes;\n  }
102	private BigDecimal parseLargePair(NumberBuffer buffer) {\n    BigDecimal first = parseMediumNumber(buffer);\n    BigDecimal second = parseLargeKanjiNumeral(buffer);\n\n    if (first == null && second == null) {\n      return null;\n    }\n\n    if (second == null) {\n                  return first;\n    }\n\n    if (first == null) {\n                  return second;\n    }\n\n    return first.multiply(second);\n  }
103	private void shiftInputWindow() throws IOException {\n    InputWindowToken firstToken = null;\n    if (inputWindow.size() > 0) {\n      firstToken = inputWindow.removeFirst();\n    }\n    while (inputWindow.size() < maxShingleSize) {\n      if (null != firstToken) {          if (null != getNextToken(firstToken)) {\n          inputWindow.add(firstToken);           firstToken = null;\n        } else {\n          break;         }\n      } else {\n        InputWindowToken nextToken = getNextToken(null);\n        if (null != nextToken) {\n          inputWindow.add(nextToken);\n        } else {\n          break;         }\n      }\n    }\n    if (outputUnigramsIfNoShingles && noShingleOutput \n        && gramSize.minValue > 1 && inputWindow.size() < minShingleSize) {\n      gramSize.minValue = 1;\n    }\n    gramSize.reset();\n    isOutputHere = false;\n  }
104	private static int anyOfRightLength(Automaton.Builder builder, String x, int n) {\n    int s = builder.createState();\n    if (x.length() == n) {\n      builder.setAccept(s, true);\n    } else {\n      builder.addTransition(s, anyOfRightLength(builder, x, n + 1), '0', '9');\n    }\n    return s;\n  }
105	private static int atLeast(Automaton.Builder builder, String x, int n, Collection<Integer> initials,\n      boolean zeros) {\n    int s = builder.createState();\n    if (x.length() == n) {\n      builder.setAccept(s, true);\n    } else {\n      if (zeros) {\n        initials.add(s);\n      }\n      char c = x.charAt(n);\n      builder.addTransition(s, atLeast(builder, x, n + 1, initials, zeros && c == '0'), c);\n      if (c < '9') {\n        builder.addTransition(s, anyOfRightLength(builder, x, n + 1), (char) (c + 1), '9');\n      }\n    }\n    return s;\n  }
106	char caseFold(char c) {\n    if (alternateCasing) {\n      if (c == 'I') {\n        return 'ı';\n      } else if (c == 'İ') {\n        return 'i';\n      } else {\n        return Character.toLowerCase(c);\n      }\n    } else {\n      return Character.toLowerCase(c);\n    }\n  }
107	synchronized boolean visit() throws IOException {\n    if (exc != null) {\n            return true;\n    }\n\n    if (current == null) {\n      if (iter.hasNext() == false) {\n        c.close();\n        return true;\n      }\n\n      Map.Entry<String,FileMetaData> next = iter.next();\n      FileMetaData metaData = next.getValue();\n      String fileName = next.getKey();\n      long len = c.in.readVLong();\n      if (len != metaData.length) {\n        throw new IllegalStateException("file " + fileName + ": meta data says length=" + metaData.length + " but c.in says " + len);\n      }\n      current = new CopyOneFile(c.in, dest, fileName, metaData, copyBuffer);\n    }\n\n    if (current.visit()) {\n            copiedFiles.put(current.name, current.tmpName);\n      totBytesCopied += current.getBytesCopied();\n      assert totBytesCopied <= totBytes: "totBytesCopied=" + totBytesCopied + " totBytes=" + totBytes;\n      current = null;\n      return false;\n    }\n\n    return false;\n  }
108	public TermAutomatonQuery toQuery(String field, TokenStream in) throws IOException {\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    TermAutomatonQuery query = new TermAutomatonQuery(field);\n\n    int pos = -1;\n    int lastPos = 0;\n    int maxOffset = 0;\n    int maxPos = -1;\n    int state = -1;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 1) {\n        throw new IllegalArgumentException("cannot handle holes; to accept any term, use '*' term");\n      }\n\n      if (posInc > 0) {\n                pos += posInc;\n      }\n\n      int endPos = pos + posLengthAtt.getPositionLength();\n      while (state < endPos) {\n        state = query.createState();\n      }\n\n      BytesRef term = termBytesAtt.getBytesRef();\n            if (term.length == 1 && term.bytes[term.offset] == (byte) '*') {\n        query.addAnyTransition(pos, endPos);\n      } else {\n        query.addTransition(pos, endPos, term);\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n      maxPos = Math.max(maxPos, endPos);\n    }\n\n    in.end();\n\n    \n        query.setAccept(state, true);\n    query.finish();\n\n    return query;\n  }
109	public static PostingsEnum getTermDocsEnum(IndexReader r, String field, BytesRef term, int flags) throws IOException {\n    assert field != null;\n    assert term != null;\n    final Terms terms = getTerms(r, field);\n    if (terms != null) {\n      final TermsEnum termsEnum = terms.iterator();\n      if (termsEnum.seekExact(term)) {\n        return termsEnum.postings(null, flags);\n      }\n    }\n    return null;\n  }
110	private int doNext() throws IOException {\n    while (freq < minShouldMatch) {\n      assert freq > 0;\n      if (freq + tailSize >= minShouldMatch) {\n                        advanceTail();\n      } else {\n                pushBackLeads();\n        setDocAndFreq();\n      }\n    }\n\n    return doc;\n  }
111	private String dependencyToArtifactId(String newPropertyKey, String dependency) {\n    StringBuilder artifactId = new StringBuilder();\n    Matcher matcher = COMPILATION_OUTPUT_DIRECTORY_PATTERN.matcher(dependency);\n    if (matcher.matches()) {\n            String artifact = matcher.group(2);\n      artifact = artifact.replace('/', '-');\n      artifact = artifact.replaceAll("(?<!solr-)analysis-", "analyzers-");\n      if ("lucene".equals(matcher.group(1))) {\n        artifactId.append("lucene-");\n      }\n      artifactId.append(artifact);\n    } else {\n      matcher = internalJarPattern.matcher(dependency);\n      if (matcher.matches()) {\n                        artifactId.append(matcher.group(1));\n        artifactId.append(matcher.group(2));\n      } else {\n        throw new BuildException\n            ("Malformed module dependency from '" + newPropertyKey + "': '" + dependency + "'");\n      }\n    }\n    return artifactId.toString();\n  }
112	public double linearDistance(final PlanetModel planetModel, final double x, final double y, final double z, final Membership... bounds) {\n    if (evaluateIsZero(x,y,z)) {\n      if (meetsAllBounds(x,y,z, bounds))\n        return 0.0;\n      return Double.POSITIVE_INFINITY;\n    }\n    \n        final Plane perpPlane = new Plane(this.y * z - this.z * y, this.z * x - this.x * z, this.x * y - this.y * x, 0.0);\n\n                \n    final GeoPoint[] intersectionPoints = findIntersections(planetModel, perpPlane);\n    \n        double minDistance = Double.POSITIVE_INFINITY;\n    \n    for (final GeoPoint intersectionPoint : intersectionPoints) {\n      if (meetsAllBounds(intersectionPoint, bounds)) {\n        final double theDistance = intersectionPoint.linearDistance(x,y,z);\n        if (theDistance < minDistance) {\n          minDistance = theDistance;\n        }\n      }\n    }\n    return minDistance;\n  }
113	public static String fileNameFromGeneration(String base, String ext, long gen) {\n    if (gen == -1) {\n      return null;\n    } else if (gen == 0) {\n      return segmentFileName(base, "", ext);\n    } else {\n      assert gen > 0;\n                        StringBuilder res = new StringBuilder(base.length() + 6 + ext.length())\n          .append(base).append('_').append(Long.toString(gen, Character.MAX_RADIX));\n      if (ext.length() > 0) {\n        res.append('.').append(ext);\n      }\n      return res.toString();\n    }\n  }
114	public boolean intersects(final PlanetModel planetModel, final Plane q, final GeoPoint[] notablePoints, final GeoPoint[] moreNotablePoints, final Membership[] bounds, final Membership... moreBounds) {\n                        if (isNumericallyIdentical(q)) {\n                        for (GeoPoint p : notablePoints) {\n        if (meetsAllBounds(p, bounds, moreBounds)) {\n                    return true;\n        }\n      }\n      for (GeoPoint p : moreNotablePoints) {\n        if (meetsAllBounds(p, bounds, moreBounds)) {\n                    return true;\n        }\n      }\n            return false;\n    }\n    \n                final double lineVectorX = y * q.z - z * q.y;\n    final double lineVectorY = z * q.x - x * q.z;\n    final double lineVectorZ = x * q.y - y * q.x;\n\n    if (Math.abs(lineVectorX) < MINIMUM_RESOLUTION && Math.abs(lineVectorY) < MINIMUM_RESOLUTION && Math.abs(lineVectorZ) < MINIMUM_RESOLUTION) {\n                  return false;\n    }\n\n                                                                                double x0;\n    double y0;\n    double z0;\n        final double denomYZ = this.y * q.z - this.z * q.y;\n    final double denomXZ = this.x * q.z - this.z * q.x;\n    final double denomXY = this.x * q.y - this.y * q.x;\n    if (Math.abs(denomYZ) >= Math.abs(denomXZ) && Math.abs(denomYZ) >= Math.abs(denomXY)) {\n            if (Math.abs(denomYZ) < MINIMUM_RESOLUTION_SQUARED) {\n                return false;\n      }\n      final double denom = 1.0 / denomYZ;\n      x0 = 0.0;\n      y0 = (-this.D * q.z - this.z * -q.D) * denom;\n      z0 = (this.y * -q.D + this.D * q.y) * denom;\n    } else if (Math.abs(denomXZ) >= Math.abs(denomXY) && Math.abs(denomXZ) >= Math.abs(denomYZ)) {\n            if (Math.abs(denomXZ) < MINIMUM_RESOLUTION_SQUARED) {\n                return false;\n      }\n      final double denom = 1.0 / denomXZ;\n      x0 = (-this.D * q.z - this.z * -q.D) * denom;\n      y0 = 0.0;\n      z0 = (this.x * -q.D + this.D * q.x) * denom;\n    } else {\n            if (Math.abs(denomXY) < MINIMUM_RESOLUTION_SQUARED) {\n                return false;\n      }\n      final double denom = 1.0 / denomXY;\n      x0 = (-this.D * q.y - this.y * -q.D) * denom;\n      y0 = (this.x * -q.D + this.D * q.x) * denom;\n      z0 = 0.0;\n    }\n\n                                final double A = lineVectorX * lineVectorX * planetModel.inverseAbSquared +\n      lineVectorY * lineVectorY * planetModel.inverseAbSquared +\n      lineVectorZ * lineVectorZ * planetModel.inverseCSquared;\n    final double B = 2.0 * (lineVectorX * x0 * planetModel.inverseAbSquared + lineVectorY * y0 * planetModel.inverseAbSquared + lineVectorZ * z0 * planetModel.inverseCSquared);\n    final double C = x0 * x0 * planetModel.inverseAbSquared + y0 * y0 * planetModel.inverseAbSquared + z0 * z0 * planetModel.inverseCSquared - 1.0;\n\n    final double BsquaredMinus = B * B - 4.0 * A * C;\n    if (Math.abs(BsquaredMinus) < MINIMUM_RESOLUTION_SQUARED) {\n            final double inverse2A = 1.0 / (2.0 * A);\n            final double t = -B * inverse2A;\n            final double pointX = lineVectorX * t + x0;\n      final double pointY = lineVectorY * t + y0;\n      final double pointZ = lineVectorZ * t + z0;\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(pointX, pointY, pointZ)) {\n          return false;\n        }\n      }\n      for (final Membership bound : moreBounds) {\n        if (!bound.isWithin(pointX, pointY, pointZ)) {\n          return false;\n        }\n      }\n      return true;\n    } else if (BsquaredMinus > 0.0) {\n            final double inverse2A = 1.0 / (2.0 * A);\n            final double sqrtTerm = Math.sqrt(BsquaredMinus);\n      final double t1 = (-B + sqrtTerm) * inverse2A;\n      final double t2 = (-B - sqrtTerm) * inverse2A;\n            final double point1X = lineVectorX * t1 + x0;\n      final double point1Y = lineVectorY * t1 + y0;\n      final double point1Z = lineVectorZ * t1 + z0;\n      boolean point1Valid = true;\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(point1X, point1Y, point1Z)) {\n          point1Valid = false;\n          break;\n        }\n      }\n      if (point1Valid) {\n        for (final Membership bound : moreBounds) {\n          if (!bound.isWithin(point1X, point1Y, point1Z)) {\n            point1Valid = false;\n            break;\n          }\n        }\n      }\n      if (point1Valid) {\n        return true;\n      }\n      final double point2X = lineVectorX * t2 + x0;\n      final double point2Y = lineVectorY * t2 + y0;\n      final double point2Z = lineVectorZ * t2 + z0;\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(point2X, point2Y, point2Z)) {\n          return false;\n        }\n      }\n      for (final Membership bound : moreBounds) {\n        if (!bound.isWithin(point2X, point2Y, point2Z)) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n            return false;\n    }\n  }
115	public int freeBlocks(int num) {\n    assert num >= 0 : "free blocks must be >= 0 but was: "+ num;\n    final int stop;\n    final int count;\n    if (num > freeBlocks) {\n      stop = 0;\n      count = freeBlocks;\n    } else {\n      stop = freeBlocks - num;\n      count = num;\n    }\n    while (freeBlocks > stop) {\n      freeByteBlocks[--freeBlocks] = null;\n    }\n    bytesUsed.addAndGet(-count*blockSize*Integer.BYTES);\n    assert bytesUsed.get() >= 0;\n    return count;\n  }
116	private void removeParticleDenotion( StringBuilder buffer )\n    {\n      if ( buffer.length() > 4 ) {\n        for ( int c = 0; c < buffer.length() - 3; c++ ) {\n          if ( buffer.substring( c, c + 4 ).equals( "gege" ) ) {\n            buffer.delete( c, c + 2 );\n            return;\n          }\n        }\n      }\n    }
117	static SerializableObject readObject(final PlanetModel planetModel, final InputStream inputStream, final Class<?> clazz) throws IOException {\n    try {\n            final Constructor<?> c = clazz.getDeclaredConstructor(PlanetModel.class, InputStream.class);\n            final Object object = c.newInstance(planetModel, inputStream);\n            if (!(object instanceof SerializableObject)) {\n        throw new IOException("Object "+clazz.getName()+" does not implement SerializableObject");\n      }\n      return (SerializableObject)object;\n    } catch (InstantiationException e) {\n      throw new IOException("Instantiation exception for class "+clazz.getName()+": "+e.getMessage(), e);\n    } catch (IllegalAccessException e) {\n      throw new IOException("Illegal access creating class "+clazz.getName()+": "+e.getMessage(), e);\n    } catch (NoSuchMethodException e) {\n      throw new IOException("No such method exception for class "+clazz.getName()+": "+e.getMessage(), e);\n    } catch (InvocationTargetException e) {\n      throw new IOException("Exception instantiating class "+clazz.getName()+": "+e.getMessage(), e);\n    }\n\n  }
118	public static void checkFooter(ChecksumIndexInput in, Throwable priorException) throws IOException {\n    if (priorException == null) {\n      checkFooter(in);\n    } else {\n      try {\n        long remaining = in.length() - in.getFilePointer();\n        if (remaining < footerLength()) {\n                    priorException.addSuppressed(new CorruptIndexException("checksum status indeterminate: remaining=" + remaining +\n                                                                 ", please run checkindex for more details", in));\n        } else {\n                    in.skipBytes(remaining - footerLength());\n          \n                    try {\n            long checksum = checkFooter(in);\n            priorException.addSuppressed(new CorruptIndexException("checksum passed (" + Long.toHexString(checksum) + \n                                                                   "). possibly transient resource issue, or a Lucene or JVM bug", in));\n          } catch (CorruptIndexException t) {\n            priorException.addSuppressed(t);\n          }\n        }\n      } catch (Throwable t) {\n                priorException.addSuppressed(new CorruptIndexException("checksum status indeterminate: unexpected exception", in, t));\n      }\n      throw IOUtils.rethrowAlways(priorException);\n    }\n  }
119	public GeoPoint bisection(final GeoPoint pt1, final GeoPoint pt2) {\n    final double A0 = (pt1.x + pt2.x) * 0.5;\n    final double B0 = (pt1.y + pt2.y) * 0.5;\n    final double C0 = (pt1.z + pt2.z) * 0.5;\n      \n    final double denom = inverseAbSquared * A0 * A0 +\n      inverseAbSquared * B0 * B0 +\n      inverseCSquared * C0 * C0;\n          \n    if(denom < Vector.MINIMUM_RESOLUTION) {\n            return null;\n    }\n      \n    final double t = Math.sqrt(1.0 / denom);\n      \n    return new GeoPoint(t * A0, t * B0, t * C0);\n  }
120	public int initTransition(int state, Transition t) {\n    assert state < nextState/2: "state=" + state + " nextState=" + nextState;\n    t.source = state;\n    t.transitionUpto = states[2*state];\n    return getNumTransitions(state);\n  }
121	public static DistancePredicate createDistancePredicate(double lat, double lon, double radiusMeters) {\n    final Rectangle boundingBox = Rectangle.fromPointDistance(lat, lon, radiusMeters);\n    final double axisLat = Rectangle.axisLat(lat, radiusMeters);\n    final double distanceSortKey = GeoUtils.distanceQuerySortKey(radiusMeters);\n    final Function<Rectangle, Relation> boxToRelation = box -> GeoUtils.relate(\n        box.minLat, box.maxLat, box.minLon, box.maxLon, lat, lon, distanceSortKey, axisLat);\n    final Grid subBoxes = createSubBoxes(boundingBox, boxToRelation);\n\n    return new DistancePredicate(\n        subBoxes.latShift, subBoxes.lonShift,\n        subBoxes.latBase, subBoxes.lonBase,\n        subBoxes.maxLatDelta, subBoxes.maxLonDelta,\n        subBoxes.relations,\n        lat, lon, distanceSortKey);\n  }
122	public BigDecimal parseLargeKanjiNumeral(NumberBuffer buffer) {\n    int i = buffer.position();\n\n    if (i >= buffer.length()) {\n      return null;\n    }\n\n    char c = buffer.charAt(i);\n    int power = exponents[c];\n\n    if (power > 3) {\n      buffer.advance();\n      return BigDecimal.TEN.pow(power);\n    }\n\n    return null;\n  }
123	public static Query createJoinQuery(String joinField,\n                                      Query fromQuery,\n                                      Query toQuery,\n                                      IndexSearcher searcher,\n                                      ScoreMode scoreMode,\n                                      OrdinalMap ordinalMap,\n                                      int min,\n                                      int max) throws IOException {\n    int numSegments = searcher.getIndexReader().leaves().size();\n    final long valueCount;\n    if (numSegments == 0) {\n      return new MatchNoDocsQuery("JoinUtil.createJoinQuery with no segments");\n    } else if (numSegments == 1) {\n            ordinalMap = null;\n      LeafReader leafReader = searcher.getIndexReader().leaves().get(0).reader();\n      SortedDocValues joinSortedDocValues = leafReader.getSortedDocValues(joinField);\n      if (joinSortedDocValues != null) {\n        valueCount = joinSortedDocValues.getValueCount();\n      } else {\n        return new MatchNoDocsQuery("JoinUtil.createJoinQuery: no join values");\n      }\n    } else {\n      if (ordinalMap == null) {\n        throw new IllegalArgumentException("OrdinalMap is required, because there is more than 1 segment");\n      }\n      valueCount = ordinalMap.getValueCount();\n    }\n\n    final Query rewrittenFromQuery = searcher.rewrite(fromQuery);\n    final Query rewrittenToQuery = searcher.rewrite(toQuery);\n    GlobalOrdinalsWithScoreCollector globalOrdinalsWithScoreCollector;\n    switch (scoreMode) {\n      case Total:\n        globalOrdinalsWithScoreCollector = new GlobalOrdinalsWithScoreCollector.Sum(joinField, ordinalMap, valueCount, min, max);\n        break;\n      case Min:\n        globalOrdinalsWithScoreCollector = new GlobalOrdinalsWithScoreCollector.Min(joinField, ordinalMap, valueCount, min, max);\n        break;\n      case Max:\n        globalOrdinalsWithScoreCollector = new GlobalOrdinalsWithScoreCollector.Max(joinField, ordinalMap, valueCount, min, max);\n        break;\n      case Avg:\n        globalOrdinalsWithScoreCollector = new GlobalOrdinalsWithScoreCollector.Avg(joinField, ordinalMap, valueCount, min, max);\n        break;\n      case None:\n        if (min <= 0 && max == Integer.MAX_VALUE) {\n          GlobalOrdinalsCollector globalOrdinalsCollector = new GlobalOrdinalsCollector(joinField, ordinalMap, valueCount);\n          searcher.search(rewrittenFromQuery, globalOrdinalsCollector);\n          return new GlobalOrdinalsQuery(globalOrdinalsCollector.getCollectorOrdinals(), joinField, ordinalMap, rewrittenToQuery,\n              rewrittenFromQuery, searcher.getTopReaderContext().id());\n        } else {\n          globalOrdinalsWithScoreCollector = new GlobalOrdinalsWithScoreCollector.NoScore(joinField, ordinalMap, valueCount, min, max);\n          break;\n        }\n      default:\n        throw new IllegalArgumentException(String.format(Locale.ROOT, "Score mode %s isn't supported.", scoreMode));\n    }\n    searcher.search(rewrittenFromQuery, globalOrdinalsWithScoreCollector);\n    return new GlobalOrdinalsWithScoreQuery(globalOrdinalsWithScoreCollector, scoreMode, joinField, ordinalMap, rewrittenToQuery,\n        rewrittenFromQuery, min, max, searcher.getTopReaderContext().id());\n  }
124	public static CachingCollector create(Collector other, boolean cacheScores, double maxRAMMB) {\n    int bytesPerDoc = Integer.BYTES;\n    if (cacheScores) {\n      bytesPerDoc += Float.BYTES;\n    }\n    final int maxDocsToCache = (int) ((maxRAMMB * 1024 * 1024) / bytesPerDoc);\n    return create(other, cacheScores, maxDocsToCache);\n  }
125	protected SpanQuery analyzeGraphPhrase(TokenStream source, String field, int phraseSlop)\n      throws IOException {\n    source.reset();\n    GraphTokenStreamFiniteStrings graph = new GraphTokenStreamFiniteStrings(source);\n    List<SpanQuery> clauses = new ArrayList<>();\n    int[] articulationPoints = graph.articulationPoints();\n    int lastState = 0;\n    for (int i = 0; i <= articulationPoints.length; i++) {\n      int start = lastState;\n      int end = -1;\n      if (i < articulationPoints.length) {\n        end = articulationPoints[i];\n      }\n      lastState = end;\n      final SpanQuery queryPos;\n      if (graph.hasSidePath(start)) {\n        List<SpanQuery> queries = new ArrayList<>();\n        Iterator<TokenStream> it = graph.getFiniteStrings(start, end);\n        while (it.hasNext()) {\n          TokenStream ts = it.next();\n          SpanQuery q = createSpanQuery(ts, field);\n          if (q != null) {\n            queries.add(q);\n          }\n        }\n        if (queries.size() > 0) {\n          queryPos = new SpanOrQuery(queries.toArray(new SpanQuery[0]));\n        } else {\n          queryPos = null;\n        }\n      } else {\n        Term[] terms = graph.getTerms(field, start);\n        assert terms.length > 0;\n        if (terms.length == 1) {\n          queryPos = new SpanTermQuery(terms[0]);\n        } else {\n          SpanTermQuery[] orClauses = new SpanTermQuery[terms.length];\n          for (int idx = 0; idx < terms.length; idx++) {\n            orClauses[idx] = new SpanTermQuery(terms[idx]);\n          }\n\n          queryPos = new SpanOrQuery(orClauses);\n        }\n      }\n\n      if (queryPos != null) {\n        clauses.add(queryPos);\n      }\n    }\n\n    if (clauses.isEmpty()) {\n      return null;\n    } else if (clauses.size() == 1) {\n      return clauses.get(0);\n    } else {\n      return new SpanNearQuery(clauses.toArray(new SpanQuery[0]), phraseSlop, true);\n    }\n  }
126	public void loadPatterns(InputSource source) throws IOException {\n    PatternParser pp = new PatternParser(this);\n    ivalues = new TernaryTree();\n\n    pp.parse(source);\n\n            trimToSize();\n    vspace.trimToSize();\n    classmap.trimToSize();\n\n        ivalues = null;\n  }
127	public int newSlice(final int size) {\n    if (byteUpto > BYTE_BLOCK_SIZE-size)\n      nextBuffer();\n    final int upto = byteUpto;\n    byteUpto += size;\n    buffer[byteUpto-1] = 16;\n    return upto;\n  }
128	int next() {\n    current = end;\n    if (current == DONE) {\n      return DONE;\n    }\n    \n    if (skipPossessive) {\n      current += 2;\n      skipPossessive = false;\n    }\n\n    int lastType = 0;\n    \n    while (current < endBounds && (isSubwordDelim(lastType = charType(text[current])))) {\n      current++;\n    }\n\n    if (current >= endBounds) {\n      return end = DONE;\n    }\n    \n    for (end = current + 1; end < endBounds; end++) {\n      int type = charType(text[end]);\n      if (isBreak(lastType, type)) {\n        break;\n      }\n      lastType = type;\n    }\n    \n    if (end < endBounds - 1 && endsWithPossessive(end + 2)) {\n      skipPossessive = true;\n    }\n    \n    return end;\n  }
129	private FacetResult drillDown() throws IOException {\n    DirectoryReader indexReader = DirectoryReader.open(indexDir);\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);\n\n            DrillDownQuery q = new DrillDownQuery(config);\n\n        q.add("Publish Date", "2010");\n    FacetsCollector fc = new FacetsCollector();\n    FacetsCollector.search(searcher, q, 10, fc);\n\n        Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, fc);\n    FacetResult result = facets.getTopChildren(10, "Author");\n\n    indexReader.close();\n    taxoReader.close();\n    \n    return result;\n  }
130	private void createCT( String term ) {\n    CT = changeTerm(term) ;\n\n    if (CT.length() < 2) return ;\n\n        if ((CT.charAt(0) == '"')  ||\n        (CT.charAt(0) == '\'') ||\n        (CT.charAt(0) == '-')  ||\n        (CT.charAt(0) == ',')  ||\n        (CT.charAt(0) == ';')  ||\n        (CT.charAt(0) == '.')  ||\n        (CT.charAt(0) == '?')  ||\n        (CT.charAt(0) == '!')\n        ) {\n        CT = CT.substring(1);\n    }\n\n    if (CT.length() < 2) return ;\n\n    // if the last character is ... , remove it\n    if ((CT.charAt(CT.length()-1) == '-') ||\n        (CT.charAt(CT.length()-1) == ',') ||\n        (CT.charAt(CT.length()-1) == ';') ||\n        (CT.charAt(CT.length()-1) == '.') ||\n        (CT.charAt(CT.length()-1) == '?') ||\n        (CT.charAt(CT.length()-1) == '!') ||\n        (CT.charAt(CT.length()-1) == '\'') ||\n        (CT.charAt(CT.length()-1) == '"')\n        ) {\n        CT = CT.substring(0,CT.length()-1);\n    }\n  }
131	private static Polygon2D createTree(Polygon2D components[], int low, int high, boolean splitX) {\n    if (low > high) {\n      return null;\n    }\n    final int mid = (low + high) >>> 1;\n    if (low < high) {\n      Comparator<Polygon2D> comparator;\n      if (splitX) {\n        comparator = (left, right) -> {\n          int ret = Double.compare(left.minLon, right.minLon);\n          if (ret == 0) {\n            ret = Double.compare(left.maxX, right.maxX);\n          }\n          return ret;\n        };\n      } else {\n        comparator = (left, right) -> {\n          int ret = Double.compare(left.minLat, right.minLat);\n          if (ret == 0) {\n            ret = Double.compare(left.maxY, right.maxY);\n          }\n          return ret;\n        };\n      }\n      ArrayUtil.select(components, low, high + 1, mid, comparator);\n    }\n        Polygon2D newNode = components[mid];\n    newNode.splitX = splitX;\n        newNode.left = createTree(components, low, mid - 1, !splitX);\n    newNode.right = createTree(components, mid + 1, high, !splitX);\n        if (newNode.left != null) {\n      newNode.maxX = Math.max(newNode.maxX, newNode.left.maxX);\n      newNode.maxY = Math.max(newNode.maxY, newNode.left.maxY);\n    }\n    if (newNode.right != null) {\n      newNode.maxX = Math.max(newNode.maxX, newNode.right.maxX);\n      newNode.maxY = Math.max(newNode.maxY, newNode.right.maxY);\n    }\n    return newNode;\n  }
132	public long updateDocValues(Term term, Field... updates) throws IOException {\n    ensureOpen();\n    DocValuesUpdate[] dvUpdates = new DocValuesUpdate[updates.length];\n    for (int i = 0; i < updates.length; i++) {\n      final Field f = updates[i];\n      final DocValuesType dvType = f.fieldType().docValuesType();\n      if (dvType == null) {\n        throw new NullPointerException("DocValuesType must not be null (field: \"" + f.name() + "\")");\n      }\n      if (dvType == DocValuesType.NONE) {\n        throw new IllegalArgumentException("can only update NUMERIC or BINARY fields! field=" + f.name());\n      }\n      if (!globalFieldNumberMap.contains(f.name(), dvType)) {\n        throw new IllegalArgumentException("can only update existing docvalues fields! field=" + f.name() + ", type=" + dvType);\n      }\n      if (config.getIndexSortFields().contains(f.name())) {\n        throw new IllegalArgumentException("cannot update docvalues field involved in the index sort, field=" + f.name() + ", sort=" + config.getIndexSort());\n      }\n      switch (dvType) {\n        case NUMERIC:\n          dvUpdates[i] = new NumericDocValuesUpdate(term, f.name(), (Long) f.numericValue());\n          break;\n        case BINARY:\n          dvUpdates[i] = new BinaryDocValuesUpdate(term, f.name(), f.binaryValue());\n          break;\n        default:\n          throw new IllegalArgumentException("can only update NUMERIC or BINARY fields: field=" + f.name() + ", type=" + dvType);\n      }\n    }\n    try {\n      long seqNo = docWriter.updateDocValues(dvUpdates);\n      if (seqNo < 0) {\n        seqNo = -seqNo;\n        processEvents(true, false);\n      }\n      return seqNo;\n    } catch (VirtualMachineError tragedy) {\n      tragicEvent(tragedy, "updateDocValues");\n\n            return -1;\n    }\n  }
133	public Calendar toCalendar(UnitNRShape lv) {\n    if (lv.getLevel() == 0)\n      return newCal();\n    if (comparePrefix(lv, minLV) <= 0) {      return (Calendar) MINCAL.clone();    }\n    assert comparePrefix(lv, maxLV) <= 0;\n    Calendar cal = newCal();\n\n    int yearAdj = lv.getValAtLevel(1) * 1_000_000;\n    if (lv.getLevel() > 1) {\n      yearAdj += lv.getValAtLevel(2) * 1000;\n      if (lv.getLevel() > 2) {\n        yearAdj += lv.getValAtLevel(3);\n      }\n    }\n    if (yearAdj > AD_YEAR_BASE) {\n      cal.set(Calendar.ERA, 1);\n      cal.set(Calendar.YEAR, yearAdj - AD_YEAR_BASE);    } else {\n      cal.set(Calendar.ERA, 0);      cal.set(Calendar.YEAR, (AD_YEAR_BASE - yearAdj) + 1);\n    }\n    for (int level = YEAR_LEVEL + 1; level <= lv.getLevel(); level++) {\n      int field = FIELD_BY_LEVEL[level];\n      cal.set(field, lv.getValAtLevel(level) + cal.getActualMinimum(field));\n    }\n    assert yearAdj > AD_YEAR_BASE || ((Calendar)cal.clone()).get(Calendar.ERA) == 0 : "ERA / YEAR underflow";\n    return cal;\n  }
134	private boolean isBeforeDot(char s[], int pos, int len) {\n    for (int i = pos; i < len;) {\n      final int ch = Character.codePointAt(s, i, len);\n      if (Character.getType(ch) != Character.NON_SPACING_MARK)\n        return false;\n      if (ch == COMBINING_DOT_ABOVE)\n        return true;\n      i += Character.charCount(ch);\n    }\n    \n    return false;\n  }
135	void writeBytes(long dest, byte[] b, int offset, int len) {\n        assert dest + len <= getPosition(): "dest=" + dest + " pos=" + getPosition() + " len=" + len;\n\n                \n    "    cycle chunk="" len="\n\n    final long end = dest + len;\n    int blockIndex = (int) (end >> blockBits);\n    int downTo = (int) (end & blockMask);\n    if (downTo == 0) {\n      blockIndex--;\n      downTo = blockSize;\n    }\n    byte[] block = blocks.get(blockIndex);\n\n    while (len > 0) {\n            if (len <= downTo) {\n                System.arraycopy(b, offset, block, downTo-len, len);\n        break;\n      } else {\n        len -= downTo;\n                System.arraycopy(b, offset + len, block, 0, downTo);\n        blockIndex--;\n        block = blocks.get(blockIndex);\n        downTo = blockSize;\n      }\n    }\n  }
136	public Vector normalize() {\n    double denom = magnitude();\n    if (denom < MINIMUM_RESOLUTION)\n            return null;\n    double normFactor = 1.0 / denom;\n    return new Vector(x * normFactor, y * normFactor, z * normFactor);\n  }
137	public static Templates getTemplates(InputStream xslIs)\n      throws ParserConfigurationException, SAXException, IOException, TransformerConfigurationException {\n    dbf.setNamespaceAware(true);\n    DocumentBuilder builder = dbf.newDocumentBuilder();\n    org.w3c.dom.Document xslDoc = builder.parse(xslIs);\n    DOMSource ds = new DOMSource(xslDoc);\n    return tFactory.newTemplates(ds);\n  }
138	private boolean isStemmable( String term ) {\n    for ( int c = 0; c < term.length(); c++ ) {\n            if ( !Character.isLetter(term.charAt(c))) {\n        return false;\n      }\n    }\n    return true;\n  }
139	private MatchingDocs createSample(MatchingDocs docs) {\n    int maxdoc = docs.context.reader().maxDoc();\n    \n        FixedBitSet sampleDocs = new FixedBitSet(maxdoc);\n    \n    int binSize = (int) (1.0 / samplingRate);\n    \n    try {\n      int counter = 0;\n      int limit, randomIndex;\n      if (leftoverBin != NOT_CALCULATED) {\n        limit = leftoverBin;\n                        randomIndex = leftoverIndex;\n      } else {\n        limit = binSize;\n        randomIndex = random.nextInt(binSize);\n      }\n      final DocIdSetIterator it = docs.bits.iterator();\n      for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n        if (counter == randomIndex) {\n          sampleDocs.set(doc);\n        }\n        counter++;\n        if (counter >= limit) {\n          counter = 0;\n          limit = binSize;\n          randomIndex = random.nextInt(binSize);\n        }\n      }\n      \n      if (counter == 0) {\n                                        leftoverBin = leftoverIndex = NOT_CALCULATED;\n      } else {\n        leftoverBin = limit - counter;\n        if (randomIndex > counter) {\n                    leftoverIndex = randomIndex - counter;\n        } else if (randomIndex < counter) {\n                              leftoverIndex = NOT_CALCULATED;\n        }\n      }\n      \n      return new MatchingDocs(docs.context, new BitDocIdSet(sampleDocs), docs.totalHits, null);\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }
140	public void serialize(DataOutput out) throws IOException {\n    out.writeUTF(id);\n    out.writeUTF(version);\n    out.writeInt(sourceFiles.size());\n    for (Entry<String,List<RevisionFile>> e : sourceFiles.entrySet()) {\n      out.writeUTF(e.getKey());\n      List<RevisionFile> files = e.getValue();\n      out.writeInt(files.size());\n      for (RevisionFile file : files) {\n        out.writeUTF(file.fileName);\n        out.writeLong(file.size);\n      }\n    }\n  }
141	private static Buffer concat(List<Buffer> buffers) {\n    int totalLength = 0;\n    Buffer largestBuffer = null;\n    for (Buffer buffer : buffers) {\n      totalLength += buffer.length;\n      if (largestBuffer == null || buffer.array.length > largestBuffer.array.length) {\n        largestBuffer = buffer;\n      }\n    }\n    if (largestBuffer == null) {\n      return new Buffer(1);\n    }\n    int[] docs = largestBuffer.array;\n    if (docs.length < totalLength + 1) {\n      docs = Arrays.copyOf(docs, totalLength + 1);\n    }\n    totalLength = largestBuffer.length;\n    for (Buffer buffer : buffers) {\n      if (buffer != largestBuffer) {\n        System.arraycopy(buffer.array, 0, docs, totalLength, buffer.length);\n        totalLength += buffer.length;\n      }\n    }\n    return new Buffer(docs, totalLength);\n  }
142	private void addTermFrequencies(Map<String, Map<String, Int>> field2termFreqMap, Terms vector, String fieldName) throws IOException {\n    Map<String, Int> termFreqMap = field2termFreqMap.get(fieldName);\n    if (termFreqMap == null) {\n      termFreqMap = new HashMap<>();\n      field2termFreqMap.put(fieldName, termFreqMap);\n    }\n    final TermsEnum termsEnum = vector.iterator();\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    BytesRef text;\n    while((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (isNoiseWord(term)) {\n        continue;\n      }\n      final int freq = (int) termsEnum.totalTermFreq();\n\n            Int cnt = termFreqMap.get(term);\n      if (cnt == null) {\n        cnt = new Int();\n        termFreqMap.put(term, cnt);\n        cnt.x = freq;\n      } else {\n        cnt.x += freq;\n      }\n    }\n  }
143	private Map<String, FileEntry> readEntries(byte[] segmentID, Directory dir, String entriesFileName) throws IOException {\n    Map<String,FileEntry> mapping = null;\n    try (ChecksumIndexInput entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE)) {\n      Throwable priorE = null;\n      try {\n        version = CodecUtil.checkIndexHeader(entriesStream, Lucene50CompoundFormat.ENTRY_CODEC, \n                                                              Lucene50CompoundFormat.VERSION_START, \n                                                              Lucene50CompoundFormat.VERSION_CURRENT, segmentID, "");\n        final int numEntries = entriesStream.readVInt();\n        mapping = new HashMap<>(numEntries);\n        for (int i = 0; i < numEntries; i++) {\n          final FileEntry fileEntry = new FileEntry();\n          final String id = entriesStream.readString();\n          FileEntry previous = mapping.put(id, fileEntry);\n          if (previous != null) {\n            throw new CorruptIndexException("Duplicate cfs entry id=" + id + " in CFS ", entriesStream);\n          }\n          fileEntry.offset = entriesStream.readLong();\n          fileEntry.length = entriesStream.readLong();\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(entriesStream, priorE);\n      }\n    }\n    return Collections.unmodifiableMap(mapping);\n  }
144	public final void setReader(Reader input) {\n    if (input == null) {\n      throw new NullPointerException("input must not be null");\n    } else if (this.input != ILLEGAL_STATE_READER) {\n      throw new IllegalStateException("TokenStream contract violation: close() call missing");\n    }\n    this.inputPending = input;\n    setReaderTestPoint();\n  }
145	private void indexPoint(PerField fp, IndexableField field) throws IOException {\n    int pointDimensionCount = field.fieldType().pointDimensionCount();\n\n    int dimensionNumBytes = field.fieldType().pointNumBytes();\n\n            if (fp.fieldInfo.getPointDimensionCount() == 0) {\n      fieldInfos.globalFieldNumbers.setDimensions(fp.fieldInfo.number, fp.fieldInfo.name, pointDimensionCount, dimensionNumBytes);\n    }\n\n    fp.fieldInfo.setPointDimensions(pointDimensionCount, dimensionNumBytes);\n\n    if (fp.pointValuesWriter == null) {\n      fp.pointValuesWriter = new PointValuesWriter(docWriter, fp.fieldInfo);\n    }\n    fp.pointValuesWriter.addPackedValue(docState.docID, field.binaryValue());\n  }
146	private Query createQuery(PriorityQueue<ScoreTerm> q) {\n    BooleanQuery.Builder query = new BooleanQuery.Builder();\n    ScoreTerm scoreTerm;\n    float bestScore = -1;\n\n    while ((scoreTerm = q.pop()) != null) {\n      Query tq = new TermQuery(new Term(scoreTerm.topField, scoreTerm.word));\n\n      if (boost) {\n        if (bestScore == -1) {\n          bestScore = (scoreTerm.score);\n        }\n        float myScore = (scoreTerm.score);\n        tq = new BoostQuery(tq, boostFactor * myScore / bestScore);\n      }\n\n      try {\n        query.add(tq, BooleanClause.Occur.SHOULD);\n      }\n      catch (BooleanQuery.TooManyClauses ignore) {\n        break;\n      }\n    }\n    return query.build();\n  }
147	private void doDrillDownAdvanceScoring(Bits acceptDocs, LeafCollector collector, DocsAndCost[] dims) throws IOException {\n    final int maxDoc = context.reader().maxDoc();\n    final int numDims = dims.length;\n\n            \n        int[] filledSlots = new int[CHUNK];\n    int[] docIDs = new int[CHUNK];\n    float[] scores = new float[CHUNK];\n    int[] missingDims = new int[CHUNK];\n    int[] counts = new int[CHUNK];\n\n    docIDs[0] = -1;\n    int nextChunkStart = CHUNK;\n\n    final FixedBitSet seen = new FixedBitSet(CHUNK);\n\n    while (true) {\n                  \n                              DocsAndCost dc = dims[0];\n      int docID = dc.approximation.docID();\n      while (docID < nextChunkStart) {\n        if (acceptDocs == null || acceptDocs.get(docID)) {\n          int slot = docID & MASK;\n\n          if (docIDs[slot] != docID && (dc.twoPhase == null || dc.twoPhase.matches())) {\n            seen.set(slot);\n                                                            docIDs[slot] = docID;\n            missingDims[slot] = 1;\n            counts[slot] = 1;\n          }\n        }\n\n        docID = dc.approximation.nextDoc();\n      }\n      \n                              dc = dims[1];\n      docID = dc.approximation.docID();\n      while (docID < nextChunkStart) {\n        if (acceptDocs == null || acceptDocs.get(docID)\n            && (dc.twoPhase == null || dc.twoPhase.matches())) {\n          int slot = docID & MASK;\n\n          if (docIDs[slot] != docID) {\n                        seen.set(slot);\n                                                docIDs[slot] = docID;\n            missingDims[slot] = 0;\n            counts[slot] = 1;\n          } else {\n                                    if (missingDims[slot] >= 1) {\n              missingDims[slot] = 2;\n              counts[slot] = 2;\n                                                      } else {\n              counts[slot] = 1;\n                                                      }\n          }\n        }\n\n        docID = dc.approximation.nextDoc();\n      }\n\n                  \n                  \n            int filledCount = 0;\n      int slot0 = 0;\n      while (slot0 < CHUNK && (slot0 = seen.nextSetBit(slot0)) != DocIdSetIterator.NO_MORE_DOCS) {\n        int ddDocID = docIDs[slot0];\n        assert ddDocID != -1;\n\n        int baseDocID = baseIterator.docID();\n        if (baseDocID < ddDocID) {\n          baseDocID = baseIterator.advance(ddDocID);\n        }\n        if (baseDocID == ddDocID) {\n                                        scores[slot0] = baseScorer.score();\n          filledSlots[filledCount++] = slot0;\n          counts[slot0]++;\n        } else {\n                                        docIDs[slot0] = -1;\n\n                                      }\n        slot0++;\n      }\n      seen.clear(0, CHUNK);\n\n      if (filledCount == 0) {\n        if (nextChunkStart >= maxDoc) {\n          break;\n        }\n        nextChunkStart += CHUNK;\n        continue;\n      }\n      \n                  for (int dim=2;dim<numDims;dim++) {\n                                dc = dims[dim];\n        docID = dc.approximation.docID();\n        while (docID < nextChunkStart) {\n          int slot = docID & MASK;\n          if (docIDs[slot] == docID\n              && counts[slot] >= dim\n              && (dc.twoPhase == null || dc.twoPhase.matches())) {\n                                    if (missingDims[slot] >= dim) {\n                                                        missingDims[slot] = dim+1;\n              counts[slot] = dim+2;\n            } else {\n                                                        counts[slot] = dim+1;\n            }\n          }\n\n                    docID = dc.approximation.nextDoc();\n        }\n      }\n\n                              for (int i=0;i<filledCount;i++) {\n        int slot = filledSlots[i];\n        collectDocID = docIDs[slot];\n        collectScore = scores[slot];\n                                if (counts[slot] == 1+numDims) {\n          collectHit(collector, dims);\n        } else if (counts[slot] == numDims) {\n          collectNearMiss(dims[missingDims[slot]].sidewaysLeafCollector);\n        }\n      }\n\n      if (nextChunkStart >= maxDoc) {\n        break;\n      }\n\n      nextChunkStart += CHUNK;\n    }\n  }
148	public static String quoteEscape(String original) {\n    String result = original;\n    \n    if (result.indexOf('\"') >= 0) {\n      result = result.replace("\"", ESCAPED_QUOTE);\n    }\n    if(result.indexOf(COMMA) >= 0) {\n      result = "\"" + result + "\"";\n    }\n    return result;\n  }
149	public void copyBytes(long src, long dest, int len) {\n        assert src < dest;\n\n                \n    "  cycle: chunk="" len="\n\n    long end = src + len;\n\n    int blockIndex = (int) (end >> blockBits);\n    int downTo = (int) (end & blockMask);\n    if (downTo == 0) {\n      blockIndex--;\n      downTo = blockSize;\n    }\n    byte[] block = blocks.get(blockIndex);\n\n    while (len > 0) {\n            if (len <= downTo) {\n                writeBytes(dest, block, downTo-len, len);\n        break;\n      } else {\n                len -= downTo;\n        writeBytes(dest + len, block, 0, downTo);\n        blockIndex--;\n        block = blocks.get(blockIndex);\n        downTo = blockSize;\n      }\n    }\n  }
150	public String sort(String inputFileName) throws IOException {\n    \n    sortInfo = new SortInfo();\n    long startMS = System.currentTimeMillis();\n\n    List<Future<Partition>> segments = new ArrayList<>();\n    int[] levelCounts = new int[1];\n\n        TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n\n    boolean success = false;\n    try (ByteSequencesReader is = getReader(dir.openChecksumInput(inputFileName, IOContext.READONCE), inputFileName)) {\n      while (true) {\n        Partition part = readPartition(is);\n        if (part.count == 0) {\n          if (partitionsInRAM != null) {\n            partitionsInRAM.release();\n          }\n          assert part.exhausted;\n          break;\n        }\n\n        Callable<Partition> job = new SortPartitionTask(trackingDir, part);\n\n        segments.add(exec.submit(job));\n        sortInfo.tempMergeFiles++;\n        sortInfo.lineCount += part.count;\n        levelCounts[0]++;\n\n                int mergeLevel = 0;\n        while (levelCounts[mergeLevel] == maxTempFiles) {\n          mergePartitions(trackingDir, segments);\n          if (mergeLevel+2 > levelCounts.length) {\n            levelCounts = ArrayUtil.grow(levelCounts, mergeLevel+2);\n          }\n          levelCounts[mergeLevel+1]++;\n          levelCounts[mergeLevel] = 0;\n          mergeLevel++;\n        }\n\n        if (part.exhausted) {\n          break;\n        }\n      }\n      \n            \n            while (segments.size() > 1) {     \n        mergePartitions(trackingDir, segments);\n      }\n\n      String result;\n      if (segments.isEmpty()) {\n        try (IndexOutput out = trackingDir.createTempOutput(tempFileNamePrefix, "sort", IOContext.DEFAULT)) {\n                    CodecUtil.writeFooter(out);\n          result = out.getName();\n        }\n      } else {\n        result = getPartition(segments.get(0)).fileName;\n      }\n\n            assert trackingDir.getCreatedFiles().size() == 1 && trackingDir.getCreatedFiles().contains(result);\n\n      sortInfo.totalTimeMS = System.currentTimeMillis() - startMS;\n\n      CodecUtil.checkFooter(is.in);\n\n      success = true;\n\n      return result;\n\n    } catch (InterruptedException ie) {\n      throw new ThreadInterruptedException(ie);\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(trackingDir, trackingDir.getCreatedFiles());\n      }\n    }\n  }
151	public long deleteAll() throws IOException {\n    ensureOpen();\n        boolean success = false;\n    \n    "point in time semantics"\n    try {\n      synchronized (fullFlushLock) { \n        docWriter.lockAndAbortAll(this);\n        processEvents(false, true);\n        synchronized (this) {\n          try {\n                        abortMerges();\n                        stopMerges = false;\n            adjustPendingNumDocs(-segmentInfos.totalMaxDoc());\n                        segmentInfos.clear();\n                        deleter.checkpoint(segmentInfos, false);\n\n            \n                        readerPool.dropAll(false);\n                        changeCount.incrementAndGet();\n            segmentInfos.changed();\n            globalFieldNumberMap.clear();\n            success = true;\n            long seqNo = docWriter.deleteQueue.getNextSequenceNumber();\n            docWriter.setLastSeqNo(seqNo);\n            return seqNo;\n          } finally {\n            docWriter.unlockAllAfterAbortAll(this);\n            if (!success) {\n              if (infoStream.isEnabled("IW")) {\n                infoStream.message("IW", "hit exception during deleteAll");\n              }\n            }\n          }\n        }\n      }\n    } catch (VirtualMachineError tragedy) {\n      tragicEvent(tragedy, "deleteAll");\n\n            return -1;\n    }\n  }
152	public synchronized String exec(String a, String b) {\n    if (a == null || b == null) {\n      return null;\n    }\n    \n    int x;\n    int y;\n    int maxx;\n    int maxy;\n    int go[] = new int[4];\n    final int X = 1;\n    final int Y = 2;\n    final int R = 3;\n    final int D = 0;\n    \n    \n    maxx = a.length() + 1;\n    maxy = b.length() + 1;\n    if ((maxx >= sizex) || (maxy >= sizey)) {\n      sizex = maxx + 8;\n      sizey = maxy + 8;\n      net = new int[sizex][sizey];\n      way = new int[sizex][sizey];\n    }\n    \n    \n    for (x = 0; x < maxx; x++) {\n      for (y = 0; y < maxy; y++) {\n        net[x][y] = 0;\n      }\n    }\n    \n    \n    for (x = 1; x < maxx; x++) {\n      net[x][0] = x;\n      way[x][0] = X;\n    }\n    for (y = 1; y < maxy; y++) {\n      net[0][y] = y;\n      way[0][y] = Y;\n    }\n    \n    for (x = 1; x < maxx; x++) {\n      for (y = 1; y < maxy; y++) {\n        go[X] = net[x - 1][y] + DELETE;\n                go[Y] = net[x][y - 1] + INSERT;\n                go[R] = net[x - 1][y - 1] + REPLACE;\n        go[D] = net[x - 1][y - 1]\n            + ((a.charAt(x - 1) == b.charAt(y - 1)) ? NOOP : 100);\n                short min = D;\n        if (go[min] >= go[X]) {\n          min = X;\n        }\n        if (go[min] > go[Y]) {\n          min = Y;\n        }\n        if (go[min] > go[R]) {\n          min = R;\n        }\n        way[x][y] = min;\n        net[x][y] = (short) go[min];\n      }\n    }\n    \n        StringBuilder result = new StringBuilder();\n    final char base = 'a' - 1;\n    char deletes = base;\n    char equals = base;\n    for (x = maxx - 1, y = maxy - 1; x + y != 0;) {\n      switch (way[x][y]) {\n        case X:\n          if (equals != base) {\n            result.append("-" + (equals));\n            equals = base;\n          }\n          deletes++;\n          x--;\n          break;\n                case Y:\n          if (deletes != base) {\n            result.append("D" + (deletes));\n            deletes = base;\n          }\n          if (equals != base) {\n            result.append("-" + (equals));\n            equals = base;\n          }\n          result.append('I');\n          result.append(b.charAt(--y));\n          break;\n                case R:\n          if (deletes != base) {\n            result.append("D" + (deletes));\n            deletes = base;\n          }\n          if (equals != base) {\n            result.append("-" + (equals));\n            equals = base;\n          }\n          result.append('R');\n          result.append(b.charAt(--y));\n          x--;\n          break;\n                case D:\n          if (deletes != base) {\n            result.append("D" + (deletes));\n            deletes = base;\n          }\n          equals++;\n          x--;\n          y--;\n          break;\n              }\n    }\n    if (deletes != base) {\n      result.append("D" + (deletes));\n      deletes = base;\n    }\n    \n    return result.toString();\n  }
153	protected Query createFieldQuery(TokenStream source, BooleanClause.Occur operator, String field, boolean quoted, int phraseSlop) {\n    assert operator == BooleanClause.Occur.SHOULD || operator == BooleanClause.Occur.MUST;\n\n        try (CachingTokenFilter stream = new CachingTokenFilter(source)) {\n      \n      TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n      PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n      PositionLengthAttribute posLenAtt = stream.addAttribute(PositionLengthAttribute.class);\n\n      if (termAtt == null) {\n        return null; \n      }\n      \n                  \n      int numTokens = 0;\n      int positionCount = 0;\n      boolean hasSynonyms = false;\n      boolean isGraph = false;\n\n      stream.reset();\n      while (stream.incrementToken()) {\n        numTokens++;\n        int positionIncrement = posIncAtt.getPositionIncrement();\n        if (positionIncrement != 0) {\n          positionCount += positionIncrement;\n        } else {\n          hasSynonyms = true;\n        }\n\n        int positionLength = posLenAtt.getPositionLength();\n        if (enableGraphQueries && positionLength > 1) {\n          isGraph = true;\n        }\n      }\n      \n                  \n      if (numTokens == 0) {\n        return null;\n      } else if (numTokens == 1) {\n                return analyzeTerm(field, stream);\n      } else if (isGraph) {\n                if (quoted) {\n          return analyzeGraphPhrase(stream, field, phraseSlop);\n        } else {\n          return analyzeGraphBoolean(field, stream, operator);\n        }\n      } else if (quoted && positionCount > 1) {\n                if (hasSynonyms) {\n                    return analyzeMultiPhrase(field, stream, phraseSlop);\n        } else {\n                    return analyzePhrase(field, stream, phraseSlop);\n        }\n      } else {\n                if (positionCount == 1) {\n                    return analyzeBoolean(field, stream);\n        } else {\n                    return analyzeMultiBoolean(field, stream, operator);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException("Error analyzing query text", e);\n    }\n  }
154	public static IntsRef toUTF32(CharSequence s, IntsRefBuilder scratch) {\n    int charIdx = 0;\n    int intIdx = 0;\n    final int charLimit = s.length();\n    while(charIdx < charLimit) {\n      scratch.grow(intIdx+1);\n      final int utf32 = Character.codePointAt(s, charIdx);\n      scratch.setIntAt(intIdx, utf32);\n      charIdx += Character.charCount(utf32);\n      intIdx++;\n    }\n    scratch.setLength(intIdx);\n    return scratch.get();\n  }
155	public final static QueryNode logicalAnd(QueryNode q1, QueryNode q2) {\n    if (q1 == null)\n      return q2;\n    if (q2 == null)\n      return q1;\n\n    ANDOperation op = null;\n    if (q1 instanceof AndQueryNode && q2 instanceof AndQueryNode)\n      op = ANDOperation.BOTH;\n    else if (q1 instanceof AndQueryNode)\n      op = ANDOperation.Q1;\n    else if (q2 instanceof AndQueryNode)\n      op = ANDOperation.Q2;\n    else\n      op = ANDOperation.NONE;\n\n    try {\n      QueryNode result = null;\n      switch (op) {\n      case NONE:\n        List<QueryNode> children = new ArrayList<>();\n        children.add(q1.cloneTree());\n        children.add(q2.cloneTree());\n        result = new AndQueryNode(children);\n        return result;\n      case Q1:\n        result = q1.cloneTree();\n        result.add(q2.cloneTree());\n        return result;\n      case Q2:\n        result = q2.cloneTree();\n        result.add(q1.cloneTree());\n        return result;\n      case BOTH:\n        result = q1.cloneTree();\n        result.add(q2.cloneTree().getChildren());\n        return result;\n      }\n    } catch (CloneNotSupportedException e) {\n      throw new QueryNodeError(e);\n    }\n\n    return null;\n\n  }
156	private String replaceSuffix( String value, String toReplace, String changeTo ) {\n    String vvalue ;\n\n        if ((value == null) ||\n        (toReplace == null) ||\n        (changeTo == null) ) {\n      return value ;\n    }\n\n    vvalue = removeSuffix(value,toReplace) ;\n\n    if (value.equals(vvalue)) {\n      return value ;\n    } else {\n      return vvalue + changeTo ;\n    }\n  }
157	public void addField(String fieldName, String text, Analyzer analyzer) {\n    if (fieldName == null)\n      throw new IllegalArgumentException("fieldName must not be null");\n    if (text == null)\n      throw new IllegalArgumentException("text must not be null");\n    if (analyzer == null)\n      throw new IllegalArgumentException("analyzer must not be null");\n    \n    TokenStream stream = analyzer.tokenStream(fieldName, text);\n    storeTerms(getInfo(fieldName, defaultFieldType), stream,\n        analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));\n  }
158	public void setRangeValues(InetAddress min, InetAddress max) {\n    final byte[] bytes;\n    if (fieldsData == null) {\n      bytes = new byte[BYTES*2];\n      fieldsData = new BytesRef(bytes);\n    } else {\n      bytes = ((BytesRef)fieldsData).bytes;\n    }\n    encode(min, max, bytes);\n  }
159	private int appendBlock(RAMOutputStream writeBuffer, List<byte[]> blocks) throws IOException {\n    int pos = Math.toIntExact(writeBuffer.getFilePointer());\n    byte[] bytes = new byte[pos];\n    writeBuffer.writeTo(bytes, 0);\n    writeBuffer.reset();\n    blocks.add(bytes);\n    return pos;\n  }
160	public static Fields getFields(IndexReader reader) throws IOException {\n    final List<LeafReaderContext> leaves = reader.leaves();\n    switch (leaves.size()) {\n      case 1:\n                return new LeafReaderFields(leaves.get(0).reader());\n      default:\n        final List<Fields> fields = new ArrayList<>(leaves.size());\n        final List<ReaderSlice> slices = new ArrayList<>(leaves.size());\n        for (final LeafReaderContext ctx : leaves) {\n          final LeafReader r = ctx.reader();\n          final Fields f = new LeafReaderFields(r);\n          fields.add(f);\n          slices.add(new ReaderSlice(ctx.docBase, r.maxDoc(), fields.size()-1));\n        }\n        if (fields.size() == 1) {\n          return fields.get(0);\n        } else {\n          return new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                         slices.toArray(ReaderSlice.EMPTY_ARRAY));\n        }\n    }\n  }
161	private void step5() {\n    if (RV == null) return  ;\n\n    if (suffix(RV,"e")) {\n      if (suffixPreceded(RV,"e","gu")) {\n        CT = removeSuffix(CT,"e") ;\n        CT = removeSuffix(CT,"u") ;\n        return ;\n      }\n\n      if (suffixPreceded(RV,"e","ci")) {\n        CT = removeSuffix(CT,"e") ;\n        CT = removeSuffix(CT,"i") ;\n        return ;\n      }\n\n      CT = removeSuffix(CT,"e") ; return ;\n    }\n  }
162	private static void checkFunctionClassLoader(Method method, ClassLoader parent) {\n    boolean ok = false;\n    try {\n      final Class<?> clazz = method.getDeclaringClass();\n      ok = Class.forName(clazz.getName(), false, parent) == clazz;\n    } catch (ClassNotFoundException e) {\n      ok = false;\n    }\n    if (!ok) {\n      throw new IllegalArgumentException(method + " is not declared by a class which is accessible by the given parent ClassLoader.");\n    }\n  }
163	public void releaseCopyState(CopyState copyState) throws IOException {\n        assert copyState.infos != null;\n    writer.decRefDeleter(copyState.infos);\n    int count = copyingCount.decrementAndGet();\n    assert count >= 0;\n  }
164	static boolean tieBreakLessThan(ShardRef first, ScoreDoc firstDoc, ShardRef second, ScoreDoc secondDoc) {\n    final int firstShardIndex = first.getShardIndex(firstDoc);\n    final int secondShardIndex = second.getShardIndex(secondDoc);\n        if (firstShardIndex< secondShardIndex) {\n      return true;\n    } else if (firstShardIndex > secondShardIndex) {\n      return false;\n    } else {\n                  assert first.hitIndex != second.hitIndex;\n      return first.hitIndex < second.hitIndex;\n    }\n  }
165	private static int computeShift(long a, long b) {\n    assert a <= b;\n                    for (int shift = 1; ; ++shift) {\n      final long delta = (b >>> shift) - (a >>> shift);\n      if (delta >= 0 && delta < Grid.ARITY) {\n        return shift;\n      }\n    }\n  }
166	protected final List<String> splitFileNames(String fileNames) {\n    if (fileNames == null)\n      return Collections.<String>emptyList();\n\n    List<String> result = new ArrayList<>();\n    for (String file : fileNames.split("(?<!\\\\),")) {\n      result.add(file.replaceAll("\\\\(?=,)", ""));\n    }\n\n    return result;\n  }
167	public CharSequence[] decompose(CharSequence cmd) {\n    int parts = 0;\n    \n    for (int i = 0; 0 <= i && i < cmd.length();) {\n      int next = dashEven(cmd, i);\n      if (i == next) {\n        parts++;\n        i = next + 2;\n      } else {\n        parts++;\n        i = next;\n      }\n    }\n    \n    CharSequence part[] = new CharSequence[parts];\n    int x = 0;\n    \n    for (int i = 0; 0 <= i && i < cmd.length();) {\n      int next = dashEven(cmd, i);\n      if (i == next) {\n        part[x++] = cmd.subSequence(i, i + 2);\n        i = next + 2;\n      } else {\n        part[x++] = (next < 0) ? cmd.subSequence(i, cmd.length()) : cmd.subSequence(i, next);\n        i = next;\n      }\n    }\n    return part;\n  }
168	private byte[] packIndex(long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n\n    int numLeaves = leafBlockFPs.length;\n\n                if (numDims == 1 && numLeaves > 1) {\n      int levelCount = 2;\n      while (true) {\n        if (numLeaves >= levelCount && numLeaves <= 2*levelCount) {\n          int lastLevel = 2*(numLeaves - levelCount);\n          assert lastLevel >= 0;\n          if (lastLevel != 0) {\n                                    long[] newLeafBlockFPs = new long[numLeaves];\n            System.arraycopy(leafBlockFPs, lastLevel, newLeafBlockFPs, 0, leafBlockFPs.length - lastLevel);\n            System.arraycopy(leafBlockFPs, 0, newLeafBlockFPs, leafBlockFPs.length - lastLevel, lastLevel);\n            leafBlockFPs = newLeafBlockFPs;\n          }\n          break;\n        }\n\n        levelCount *= 2;\n      }\n    }\n\n    \n    RAMOutputStream writeBuffer = new RAMOutputStream();\n\n        List<byte[]> blocks = new ArrayList<>();\n    byte[] lastSplitValues = new byte[bytesPerDim * numDims];\n        int totalSize = recursePackIndex(writeBuffer, leafBlockFPs, splitPackedValues, 0l, blocks, 1, lastSplitValues, new boolean[numDims], false);\n\n        byte[] index = new byte[totalSize];\n    int upto = 0;\n    for(byte[] block : blocks) {\n      System.arraycopy(block, 0, index, upto, block.length);\n      upto += block.length;\n    }\n    assert upto == totalSize;\n\n    return index;\n  }
169	static XMLReader createParser() {\n    try {\n      SAXParserFactory factory = SAXParserFactory.newInstance();\n      factory.setNamespaceAware(true);\n      return factory.newSAXParser().getXMLReader();\n    } catch (Exception e) {\n      throw new RuntimeException("Couldn't create XMLReader: " + e.getMessage());\n    }\n  }
170	private static SafePath findSafePath(final SafePath currentPath, final List<GeoPoint> points, final int pointIndex,\n    final int startPointIndex, final double leniencyValue) {\n          \n        int considerPointIndex = pointIndex;\n    while (true) {\n            final GeoPoint considerStartPoint = currentPath.lastPoint;\n      final GeoPoint considerEndPoint = points.get(considerPointIndex);\n      final int nextPointIndex = getLegalIndex(considerPointIndex + 1, points.size());\n      if (!considerStartPoint.isNumericallyIdentical(considerEndPoint)) {\n                final Plane considerPlane = new Plane(considerStartPoint, considerEndPoint);\n        \n        boolean isChoiceLegal = true;\n\n                if (isChoiceLegal) {\n                    if (currentPath.lastPlane != null) {\n            if (currentPath.lastPlane.evaluateIsZero(considerEndPoint)) {\n                                          isChoiceLegal = false;\n            } else if (considerPlane.evaluateIsZero(currentPath.previous.lastPoint)) {\n                            isChoiceLegal = false;\n            } else {\n                                                                                                                                                                                                    final Plane thirdPlane = new Plane(currentPath.previous.lastPoint, considerEndPoint);\n              if (thirdPlane.evaluateIsZero(considerStartPoint)) {\n                isChoiceLegal = false;\n              }\n            }\n          }\n        }\n        \n        if (isChoiceLegal && considerPointIndex == startPointIndex) {\n                    final SafePath firstPlaneEndpoint = currentPath.findFirstEndpoint();\n          if (firstPlaneEndpoint == null) {\n                        isChoiceLegal = false;\n          } else {\n            if (firstPlaneEndpoint.lastPlane.evaluateIsZero(considerStartPoint)) {\n                            isChoiceLegal = false;\n            } else if (considerPlane.evaluateIsZero(firstPlaneEndpoint.lastPoint)) {\n                            isChoiceLegal = false;\n            } else {\n                                          final Plane thirdPlane = new Plane(considerStartPoint, firstPlaneEndpoint.lastPoint);\n              if (thirdPlane.evaluateIsZero(considerEndPoint)) {\n                isChoiceLegal = false;\n              }\n            }\n          }\n        }\n        \n        if (isChoiceLegal) {\n                    int checkIndex = getLegalIndex(currentPath.lastPointIndex + 1, points.size());\n          while (checkIndex != considerPointIndex) {\n            if (Math.abs(considerPlane.evaluate(points.get(checkIndex))) >= Vector.MINIMUM_RESOLUTION + leniencyValue) {\n                                                                                                  return null;\n            }\n            checkIndex = getLegalIndex(checkIndex + 1, points.size());\n          }\n        }\n        \n        if (isChoiceLegal) {\n                    if (considerPointIndex == startPointIndex) {\n                        return currentPath;\n          }\n                    final SafePath newPath = new SafePath(currentPath, considerEndPoint, considerPointIndex, considerPlane);\n          final SafePath result = findSafePath(newPath, points, nextPointIndex, startPointIndex, leniencyValue);\n          if (result != null) {\n            return result;\n          }\n        }\n\n      }\n      \n      if (considerPointIndex == startPointIndex) {\n        break;\n      }\n      considerPointIndex = nextPointIndex;\n    }\n    return null;\n  }
171	private void pruneBlockedQueue(final DocumentsWriterDeleteQueue flushingQueue) {\n    Iterator<BlockedFlush> iterator = blockedFlushes.iterator();\n    while (iterator.hasNext()) {\n      BlockedFlush blockedFlush = iterator.next();\n      if (blockedFlush.dwpt.deleteQueue == flushingQueue) {\n        iterator.remove();\n        assert !flushingWriters.containsKey(blockedFlush.dwpt) : "DWPT is already flushing";\n                flushingWriters.put(blockedFlush.dwpt, Long.valueOf(blockedFlush.bytes));\n                flushQueue.add(blockedFlush.dwpt);\n      }\n    }\n  }
172	public Transition[][] getSortedTransitions() {\n    int numStates = getNumStates();\n    Transition[][] transitions = new Transition[numStates][];\n    for(int s=0;s<numStates;s++) {\n      int numTransitions = getNumTransitions(s);\n      transitions[s] = new Transition[numTransitions];\n      for(int t=0;t<numTransitions;t++) {\n        Transition transition = new Transition();\n        getTransition(s, t, transition);\n        transitions[s][t] = transition;\n      }\n    }\n\n    return transitions;\n  }
173	public synchronized void setRequireDimCount(String dimName, boolean v) {\n    DimConfig ft = fieldTypes.get(dimName);\n    if (ft == null) {\n      ft = new DimConfig();\n      fieldTypes.put(dimName, ft);\n    }\n    ft.requireDimCount = v;\n  }
174	private String changeTerm( String value ) {\n    int     j;\n    String  r = "" ;\n\n        if (value == null) {\n      return null ;\n    }\n\n    value = value.toLowerCase(locale) ;\n    for (j=0 ; j < value.length() ; j++) {\n      if ((value.charAt(j) == 'á') ||\n          (value.charAt(j) == 'â') ||\n          (value.charAt(j) == 'ã')) {\n        r= r + "a" ; continue ;\n      }\n      if ((value.charAt(j) == 'é') ||\n          (value.charAt(j) == 'ê')) {\n        r= r + "e" ; continue ;\n      }\n      if (value.charAt(j) == 'í') {\n        r= r + "i" ; continue ;\n      }\n      if ((value.charAt(j) == 'ó') ||\n          (value.charAt(j) == 'ô') ||\n          (value.charAt(j) == 'õ')) {\n        r= r + "o" ; continue ;\n      }\n      if ((value.charAt(j) == 'ú') ||\n          (value.charAt(j) == 'ü')) {\n        r= r + "u" ; continue ;\n      }\n      if (value.charAt(j) == 'ç') {\n        r= r + "c" ; continue ;\n      }\n      if (value.charAt(j) == 'ñ') {\n        r= r + "n" ; continue ;\n      }\n\n      r= r+ value.charAt(j) ;\n    }\n\n    return r ;\n  }
175	private InputOutput getByOutput(long targetOrd) throws IOException {\n\n    final IntsRefBuilder result = new IntsRefBuilder();\n\n    fr.index.getFirstArc(arc);\n    Output output = arc.output;\n    int upto = 0;\n\n    int bestUpto = 0;\n    Output bestOutput = null;\n\n    "/tmp/out.dot"\n\n    \n    while (true) {\n            if (arc.isFinal()) {\n        final Output finalOutput = OrdsBlockTreeTermsWriter.FST_OUTPUTS.add(output, arc.nextFinalOutput);\n                if (targetOrd >= finalOutput.startOrd && targetOrd <= Long.MAX_VALUE-finalOutput.endOrd) {\n                              bestOutput = finalOutput;\n          bestUpto = upto;\n        }\n      }\n\n      if (FST.targetHasArcs(arc)) {\n                result.grow(1+upto);\n        \n        fr.index.readFirstRealTargetArc(arc.target, arc, fstReader);\n\n        if (arc.bytesPerArc != 0) {\n          \n          int low = 0;\n          int high = arc.numArcs-1;\n          int mid = 0;\n                    boolean found = false;\n          while (low <= high) {\n            mid = (low + high) >>> 1;\n            fstReader.setPosition(arc.posArcsStart);\n            fstReader.skipBytes(arc.bytesPerArc*mid);\n            final byte flags = fstReader.readByte();\n            fr.index.readLabel(fstReader);\n            final Output minArcOutput;\n            if ((flags & FST.BIT_ARC_HAS_OUTPUT) != 0) {\n              minArcOutput = OrdsBlockTreeTermsWriter.FST_OUTPUTS.add(output, OrdsBlockTreeTermsWriter.FST_OUTPUTS.read(fstReader));\n            } else {\n              minArcOutput = output;\n            }\n                        if (targetOrd > Long.MAX_VALUE-minArcOutput.endOrd) {\n              low = mid + 1;\n            } else if (targetOrd < minArcOutput.startOrd) {\n              high = mid - 1;\n            } else {\n                            found = true;\n              break;\n            }\n          }\n\n          if (found) {\n                        arc.arcIdx = mid-1;\n          } else {\n            result.setLength(bestUpto);\n            InputOutput io = new InputOutput();\n            io.input = result.get();\n            io.output = bestOutput;\n                        return io;\n          }\n\n          fr.index.readNextRealArc(arc, fstReader);\n\n                    result.setIntAt(upto++, arc.label);\n          output = OrdsBlockTreeTermsWriter.FST_OUTPUTS.add(output, arc.output);\n\n        } else {\n          \n          while (true) {\n            \n                                    final Output minArcOutput = OrdsBlockTreeTermsWriter.FST_OUTPUTS.add(output, arc.output);\n            long endOrd = Long.MAX_VALUE - minArcOutput.endOrd;\n            \n            if (targetOrd >= minArcOutput.startOrd && targetOrd <= endOrd) {\n                            output = minArcOutput;\n              result.setIntAt(upto++, arc.label);\n              break;\n            } else if (targetOrd < endOrd || arc.isLast()) {\n              result.setLength(bestUpto);\n              InputOutput io = new InputOutput();\n              io.input = result.get();\n              assert bestOutput != null;\n              io.output = bestOutput;\n                            return io;\n            } else {\n                                          fr.index.readNextRealArc(arc, fstReader);\n            }\n          }\n        }\n      } else {\n        result.setLength(bestUpto);\n        InputOutput io = new InputOutput();\n        io.input = result.get();\n        io.output = bestOutput;\n                return io;\n      }\n    }\n  }
176	public static boolean spins(Path path) throws IOException {\n        path = path.toRealPath();\n    \n        if (!Constants.LINUX) {\n      return true;     }\n\n    try {\n      return spinsLinux(path);\n    } catch (Exception exc) {\n            return true;\n    }\n  }
177	public GeoPoint[] findArcDistancePoints(final PlanetModel planetModel, final double arcDistanceValue, final GeoPoint startPoint, final Membership... bounds) {\n    if (Math.abs(D) >= MINIMUM_RESOLUTION) {\n      throw new IllegalStateException("Can't find arc distance using plane that doesn't go through origin");\n    }\n    if (!evaluateIsZero(startPoint)) {\n      throw new IllegalArgumentException("Start point is not on plane");\n    }\n    \n            \n                        \n        final double azimuthMagnitude = Math.sqrt(this.x * this.x + this.y * this.y);\n    final double cosPlaneAltitude = this.z;\n    final double sinPlaneAltitude = azimuthMagnitude;\n    final double cosPlaneAzimuth = this.x / azimuthMagnitude;\n    final double sinPlaneAzimuth = this.y / azimuthMagnitude;\n    \n    assert Math.abs(sinPlaneAltitude * sinPlaneAltitude + cosPlaneAltitude * cosPlaneAltitude - 1.0) < MINIMUM_RESOLUTION : "Improper sin/cos of altitude: "+(sinPlaneAltitude * sinPlaneAltitude + cosPlaneAltitude * cosPlaneAltitude);\n    assert Math.abs(sinPlaneAzimuth * sinPlaneAzimuth + cosPlaneAzimuth * cosPlaneAzimuth - 1.0) < MINIMUM_RESOLUTION : "Improper sin/cos of azimuth: "+(sinPlaneAzimuth * sinPlaneAzimuth + cosPlaneAzimuth * cosPlaneAzimuth);\n\n                            \n        final double x0 = startPoint.x;\n    final double y0 = startPoint.y;\n    final double z0 = startPoint.z;\n    \n    final double x1 = x0 * cosPlaneAzimuth + y0 * sinPlaneAzimuth;\n    final double y1 = -x0 * sinPlaneAzimuth + y0 * cosPlaneAzimuth;\n    final double z1 = z0;\n    \n        final double x2 = x1 * cosPlaneAltitude - z1 * sinPlaneAltitude;\n    final double y2 = y1;\n    final double z2 = +x1 * sinPlaneAltitude + z1 * cosPlaneAltitude;\n    \n    assert Math.abs(z2) < MINIMUM_RESOLUTION : "Rotation should have put startpoint on x-y plane, instead has value "+z2;\n    \n            final double startAngle = Math.atan2(y2, x2);\n    \n        final double point1Angle = startAngle + arcDistanceValue;\n    final double point2Angle = startAngle - arcDistanceValue;\n        final double point1x2 = Math.cos(point1Angle);\n    final double point1y2 = Math.sin(point1Angle);\n    final double point1z2 = 0.0;\n    \n    final double point2x2 = Math.cos(point2Angle);\n    final double point2y2 = Math.sin(point2Angle);\n    final double point2z2 = 0.0;\n    \n            final double point1x1 = point1x2 * cosPlaneAltitude + point1z2 * sinPlaneAltitude;\n    final double point1y1 = point1y2;\n    final double point1z1 = -point1x2 * sinPlaneAltitude + point1z2 * cosPlaneAltitude;\n    \n    final double point2x1 = point2x2 * cosPlaneAltitude + point2z2 * sinPlaneAltitude;\n    final double point2y1 = point2y2;\n    final double point2z1 = -point2x2 * sinPlaneAltitude + point2z2 * cosPlaneAltitude;\n\n        final double point1x0 = point1x1 * cosPlaneAzimuth - point1y1 * sinPlaneAzimuth;\n    final double point1y0 = point1x1 * sinPlaneAzimuth + point1y1 * cosPlaneAzimuth;\n    final double point1z0 = point1z1;\n\n    final double point2x0 = point2x1 * cosPlaneAzimuth - point2y1 * sinPlaneAzimuth;\n    final double point2y0 = point2x1 * sinPlaneAzimuth + point2y1 * cosPlaneAzimuth;\n    final double point2z0 = point2z1;\n\n    final GeoPoint point1 = planetModel.createSurfacePoint(point1x0, point1y0, point1z0);\n    final GeoPoint point2 = planetModel.createSurfacePoint(point2x0, point2y0, point2z0);\n    \n        boolean isPoint1Inside = meetsAllBounds(point1, bounds);\n    boolean isPoint2Inside = meetsAllBounds(point2, bounds);\n    \n    if (isPoint1Inside) {\n      if (isPoint2Inside) {\n        return new GeoPoint[]{point1, point2};\n      } else {\n        return new GeoPoint[]{point1};\n      }\n    } else {\n      if (isPoint2Inside) {\n        return new GeoPoint[]{point2};\n      } else {\n        return new GeoPoint[0];\n      }\n    }\n  }
178	public void copy(BytesRef bytes, BytesRef out) {\n    int left = blockSize - upto;\n    if (bytes.length > left || currentBlock==null) {\n      if (currentBlock != null) {\n        addBlock(currentBlock);\n        didSkipBytes = true;\n      }\n      currentBlock = new byte[blockSize];\n      upto = 0;\n      left = blockSize;\n      assert bytes.length <= blockSize;\n          }\n\n    out.bytes = currentBlock;\n    out.offset = upto;\n    out.length = bytes.length;\n\n    System.arraycopy(bytes.bytes, bytes.offset, currentBlock, upto, bytes.length);\n    upto += bytes.length;\n  }
179	private static int between(Automaton.Builder builder,\n      String x, String y, int n,\n      Collection<Integer> initials, boolean zeros) {\n    int s = builder.createState();\n    if (x.length() == n) {\n      builder.setAccept(s, true);\n    } else {\n      if (zeros) {\n        initials.add(s);\n      }\n      char cx = x.charAt(n);\n      char cy = y.charAt(n);\n      if (cx == cy) {\n        builder.addTransition(s, between(builder, x, y, n + 1, initials, zeros && cx == '0'), cx);\n      } else {         builder.addTransition(s, atLeast(builder, x, n + 1, initials, zeros && cx == '0'), cx);\n        builder.addTransition(s, atMost(builder, y, n + 1), cy);\n        if (cx + 1 < cy) {\n          builder.addTransition(s, anyOfRightLength(builder, x, n+1), (char) (cx + 1), (char) (cy - 1));\n        }\n      }\n    }\n\n    return s;\n  }
180	private FieldFragList getFieldFragList( FragListBuilder fragListBuilder,\n      final FieldQuery fieldQuery, IndexReader reader, int docId,\n      Set< String > matchedFields, int fragCharSize ) throws IOException {\n    Iterator< String > matchedFieldsItr = matchedFields.iterator();\n    if ( !matchedFieldsItr.hasNext() ) {\n      throw new IllegalArgumentException( "matchedFields must contain at least on field name." );\n    }\n    FieldPhraseList[] toMerge = new FieldPhraseList[ matchedFields.size() ];\n    int i = 0;\n    while ( matchedFieldsItr.hasNext() ) {\n      FieldTermStack stack = new FieldTermStack( reader, docId, matchedFieldsItr.next(), fieldQuery );\n      toMerge[ i++ ] = new FieldPhraseList( stack, fieldQuery, phraseLimit );\n    } \n    return fragListBuilder.createFieldFragList( new FieldPhraseList( toMerge ), fragCharSize );\n  }
181	private void setExternalDependencyXmlProperties() {\n    for (String module : internalCompileScopeDependencies.keySet()) {       StringBuilder compileScopeBuilder = new StringBuilder();\n      StringBuilder testScopeBuilder = new StringBuilder();\n      SortedSet<ExternalDependency> extDeps = allExternalDependencies.get(module);\n      if (null != extDeps) {\n        for (ExternalDependency dep : extDeps) {\n          StringBuilder builder = dep.isTestDependency ? testScopeBuilder : compileScopeBuilder;\n          appendDependencyXml(builder, dep.groupId, dep.artifactId, "    ", null, \n                              dep.isTestDependency, dep.isOptional, dep.classifier, null);\n                                        if ( ! dep.isTestDependency && modulesWithSeparateCompileAndTestPOMs.contains(module)) {\n            appendDependencyXml(testScopeBuilder, dep.groupId, dep.artifactId, "    ", null,\n                                true, dep.isOptional, dep.classifier, null);\n          }\n        }\n      }\n      if (compileScopeBuilder.length() > 0) {\n        compileScopeBuilder.setLength(compileScopeBuilder.length() - 1);       }\n      if (testScopeBuilder.length() > 0) {\n        testScopeBuilder.setLength(testScopeBuilder.length() - 1);       }\n      allProperties.setProperty(module + ".external.dependencies", compileScopeBuilder.toString());\n      allProperties.setProperty(module + ".external.test.dependencies", testScopeBuilder.toString());\n    }\n  }
182	public static Plane constructNormalizedYPlane(final Vector... planePoints) {\n        double bestDistance = 0.0;\n    Vector bestPoint = null;\n    for (final Vector point : planePoints) {\n      final double pointDist = point.x * point.x + point.z * point.z;\n      if (pointDist > bestDistance) {\n        bestDistance = pointDist;\n        bestPoint = point;\n      }\n    }\n    return constructNormalizedYPlane(bestPoint.x, bestPoint.z, 0.0);\n  }
183	public void balance() {\n        \n    int i = 0, n = length;\n    String[] k = new String[n];\n    char[] v = new char[n];\n    Iterator iter = new Iterator();\n    while (iter.hasMoreElements()) {\n      v[i] = iter.getValue();\n      k[i++] = iter.nextElement();\n    }\n    init();\n    insertBalanced(k, v, 0, n);\n\n              }
184	private int nextIterationMarkSpanSize() throws IOException {\n    int spanSize = 0;\n    for (int i = bufferPosition; buffer.get(i) != -1 && isIterationMark((char) (buffer.get(i))); i++) {\n      spanSize++;\n    }\n        if (bufferPosition - spanSize < iterationMarkSpanEndPosition) {\n      spanSize = bufferPosition - iterationMarkSpanEndPosition;\n    }\n    return spanSize;\n  }
185	public static Options parseOptions(String[] args) {\n    Options opts = new Options();\n\n    int i = 0;\n    while(i < args.length) {\n      String arg = args[i];\n      if ("-fast".equals(arg)) {\n        opts.doChecksumsOnly = true;\n      } else if ("-exorcise".equals(arg)) {\n        opts.doExorcise = true;\n      } else if ("-crossCheckTermVectors".equals(arg)) {\n        opts.doCrossCheckTermVectors = true;\n      } else if (arg.equals("-verbose")) {\n        opts.verbose = true;\n      } else if (arg.equals("-segment")) {\n        if (i == args.length-1) {\n          throw new IllegalArgumentException("ERROR: missing name for -segment option");\n        }\n        i++;\n        opts.onlySegments.add(args[i]);\n      } else if ("-dir-impl".equals(arg)) {\n        if (i == args.length - 1) {\n          throw new IllegalArgumentException("ERROR: missing value for -dir-impl option");\n        }\n        i++;\n        opts.dirImpl = args[i];\n      } else {\n        if (opts.indexPath != null) {\n          throw new IllegalArgumentException("ERROR: unexpected extra argument '" + args[i] + "'");\n        }\n        opts.indexPath = args[i];\n      }\n      i++;\n    }\n\n    if (opts.indexPath == null) {\n      throw new IllegalArgumentException("\nERROR: index path not specified" +\n                         "\nUsage: java org.apache.lucene.index.CheckIndex pathToIndex [-exorcise] [-crossCheckTermVectors] [-segment X] [-segment Y] [-dir-impl X]\n" +\n                         "\n" +\n                         "  -exorcise: actually write a new segments_N file, removing any problematic segments\n" +\n                         "  -fast: just verify file checksums, omitting logical integrity checks\n" + \n                         "  -crossCheckTermVectors: verifies that term vectors match postings; THIS IS VERY SLOW!\n" +\n                         "  -codec X: when exorcising, codec to write the new segments_N file with\n" +\n                         "  -verbose: print additional details\n" +\n                         "  -segment X: only check the specified segments.  This can be specified multiple\n" + \n                         "              times, to check more than one segment, eg '-segment _2 -segment _a'.\n" +\n                         "              You can't use this with the -exorcise option\n" +\n                         "  -dir-impl X: use a specific " + FSDirectory.class.getSimpleName() + " implementation. " +\n                         "If no package is specified the " + FSDirectory.class.getPackage().getName() + " package will be used.\n" +\n                         "\n" +\n                         "**WARNING**: -exorcise *LOSES DATA*. This should only be used on an emergency basis as it will cause\n" +\n                         "documents (perhaps many) to be permanently removed from the index.  Always make\n" +\n                         "a backup copy of your index before running this!  Do not run this tool on an index\n" +\n                         "that is actively being written to.  You have been warned!\n" +\n                         "\n" +\n                         "Run without -exorcise, this tool will open the index, report version information\n" +\n                         "and report any exceptions it hits and what action it would take if -exorcise were\n" +\n                         "specified.  With -exorcise, this tool will remove any segments that have issues and\n" + \n                         "write a new segments_N file.  This means all documents contained in the affected\n" +\n                         "segments will be removed.\n" +\n                         "\n" +\n                         "This tool exits with exit code 1 if the index cannot be opened or has any\n" +\n                         "corruption, else 0.\n");\n    }\n\n    if (opts.onlySegments.size() == 0) {\n      opts.onlySegments = null;\n    } else if (opts.doExorcise) {\n      throw new IllegalArgumentException("ERROR: cannot specify both -exorcise and -segment");\n    }\n    \n    if (opts.doChecksumsOnly && opts.doCrossCheckTermVectors) {\n      throw new IllegalArgumentException("ERROR: cannot specify both -fast and -crossCheckTermVectors");\n    }\n\n    return opts;\n  }
186	public static CompressingCodec randomInstance(Random random, int chunkSize, int maxDocsPerChunk, boolean withSegmentSuffix, int blockSize) {\n    switch (random.nextInt(4)) {\n    case 0:\n      return new FastCompressingCodec(chunkSize, maxDocsPerChunk, withSegmentSuffix, blockSize);\n    case 1:\n      return new FastDecompressionCompressingCodec(chunkSize, maxDocsPerChunk, withSegmentSuffix, blockSize);\n    case 2:\n      return new HighCompressionCompressingCodec(chunkSize, maxDocsPerChunk, withSegmentSuffix, blockSize);\n    case 3:\n      return new DummyCompressingCodec(chunkSize, maxDocsPerChunk, withSegmentSuffix, blockSize);\n    default:\n      throw new AssertionError();\n    }\n  }
187	public V put(char[] text, V value) {\n    if (ignoreCase) {\n      CharacterUtils.toLowerCase(text, 0, text.length);\n    }\n    int slot = getSlot(text, 0, text.length);\n    if (keys[slot] != null) {\n      final V oldValue = values[slot];\n      values[slot] = value;\n      return oldValue;\n    }\n    keys[slot] = text;\n    values[slot] = value;\n    count++;\n\n    if (count + (count>>2) > keys.length) {\n      rehash();\n    }\n\n    return null;\n  }
188	public static FSDirectory newFSDirectory(String clazzName, Path path, LockFactory lf) {\n    try {\n      final Class<? extends FSDirectory> clazz = loadFSDirectoryClass(clazzName);\n      return newFSDirectory(clazz, path, lf);\n    } catch (ClassNotFoundException e) {\n      throw new IllegalArgumentException(FSDirectory.class.getSimpleName()\n          + " implementation not found: " + clazzName, e);\n    } catch (ClassCastException e) {\n      throw new IllegalArgumentException(clazzName + " is not a " + FSDirectory.class.getSimpleName()\n          + " implementation", e);\n    } catch (NoSuchMethodException e) {\n      throw new IllegalArgumentException(clazzName + " constructor with "\n          + Path.class.getSimpleName() + " as parameter not found", e);\n    } catch (Exception e) {\n      throw new IllegalArgumentException("Error creating " + clazzName + " instance", e);\n    }\n  }
189	public static TokenStream getTermVectorTokenStreamOrNull(String field, Fields tvFields, int maxStartOffset)\n      throws IOException {\n    if (tvFields == null) {\n      return null;\n    }\n    final Terms tvTerms = tvFields.terms(field);\n    if (tvTerms == null || !tvTerms.hasOffsets()) {\n      return null;\n    }\n    return new TokenStreamFromTermVector(tvTerms, maxStartOffset);\n  }
190	private boolean collectConflicts(IvyNodeElement root, IvyNodeElement parent, String moduleName) {\n    boolean conflicts = false;\n    for (IvyNodeElement child : parent.getDependencies()) {\n      String coordinate = "/" + child.getOrganization() + "/" + child.getName();\n      Dependency dependency = directDependencies.get(coordinate);\n      if (null != dependency) {         String indirectVersion = child.getRevision();\n        if (isConflict(coordinate, dependency.directVersion, indirectVersion)) {\n          conflicts = true;\n          Set<String> moduleNames = dependency.conflictLocations.get(root);\n          if (null == moduleNames) {\n            moduleNames = new HashSet<>();\n            dependency.conflictLocations.put(root, moduleNames);\n          }\n          moduleNames.add(moduleName);\n        }\n        conflicts |= collectConflicts(root, child, moduleName);\n      }\n    }\n    return conflicts;\n  }
191	public static void writeIndexHeader(DataOutput out, String codec, int version, byte[] id, String suffix) throws IOException {\n    if (id.length != StringHelper.ID_LENGTH) {\n      throw new IllegalArgumentException("Invalid id: " + StringHelper.idToString(id));\n    }\n    writeHeader(out, codec, version);\n    out.writeBytes(id, 0, id.length);\n    BytesRef suffixBytes = new BytesRef(suffix);\n    if (suffixBytes.length != suffix.length() || suffixBytes.length >= 256) {\n      throw new IllegalArgumentException("suffix must be simple ASCII, less than 256 characters in length [got " + suffix + "]");\n    }\n    out.writeByte((byte) suffixBytes.length);\n    out.writeBytes(suffixBytes.bytes, suffixBytes.offset, suffixBytes.length);\n  }
192	public boolean flushAndRefresh() throws IOException {\n    message("top: now flushAndRefresh");\n    Set<String> completedMergeFiles;\n    synchronized(finishedMergedFiles) {\n      completedMergeFiles = Collections.unmodifiableSet(new HashSet<>(finishedMergedFiles));\n    }\n    mgr.maybeRefreshBlocking();\n    boolean result = setCurrentInfos(completedMergeFiles);\n    if (result) {\n      message("top: opened NRT reader version=" + curInfos.getVersion());\n      finishedMergedFiles.removeAll(completedMergeFiles);\n      message("flushAndRefresh: version=" + curInfos.getVersion() + " completedMergeFiles=" + completedMergeFiles + " finishedMergedFiles=" + finishedMergedFiles);\n    } else {\n      message("top: no changes in flushAndRefresh; still version=" + curInfos.getVersion());\n    }\n    return result;\n  }
193	public static void checkNoMatchExplanations(Query q, String defaultFieldName,\n                                              IndexSearcher searcher, int[] results)\n    throws IOException {\n\n    String d = q.toString(defaultFieldName);\n    Set<Integer> ignore = new TreeSet<>();\n    for (int i = 0; i < results.length; i++) {\n      ignore.add(Integer.valueOf(results[i]));\n    }\n    \n    int maxDoc = searcher.getIndexReader().maxDoc();\n    for (int doc = 0; doc < maxDoc; doc++) {\n      if (ignore.contains(Integer.valueOf(doc))) continue;\n\n      Explanation exp = searcher.explain(q, doc);\n      Assert.assertNotNull("Explanation of [["+d+"]] for #"+doc+" is null",\n                             exp);\n      Assert.assertFalse("Explanation of [["+d+"]] for #"+doc+\n                         " doesn't indicate non-match: " + exp.toString(),\n                         exp.isMatch());\n    }\n    \n  }
194	private void bottomChanged(BytesRef lastTerm) throws IOException {\n    int oldMaxEdits = maxEdits;\n    \n        boolean termAfter = bottomTerm == null || (lastTerm != null && lastTerm.compareTo(bottomTerm) >= 0);\n\n            while (maxEdits > 0) {\n      float maxBoost = 1.0f - ((float) maxEdits / (float) termLength);\n      if (bottom < maxBoost || (bottom == maxBoost && termAfter == false)) {\n        break;\n      }\n      maxEdits--;\n    }\n\n    if (oldMaxEdits != maxEdits || lastTerm == null) {\n                        actualEnum = getAutomatonEnum(maxEdits, lastTerm);\n    }\n  }
195	public SpatialArgs parse(String v, SpatialContext ctx) throws ParseException, InvalidShapeException {\n    int idx = v.indexOf('(');\n    int edx = v.lastIndexOf(')');\n\n    if (idx < 0 || idx > edx) {\n      throw new ParseException("missing parens: " + v, -1);\n    }\n\n    SpatialOperation op = SpatialOperation.get(v.substring(0, idx).trim());\n\n    String body = v.substring(idx + 1, edx).trim();\n    if (body.length() < 1) {\n      throw new ParseException("missing body : " + v, idx + 1);\n    }\n\n    Shape shape = parseShape(body, ctx);\n    SpatialArgs args = newSpatialArgs(op, shape);\n\n    if (v.length() > (edx + 1)) {\n      body = v.substring(edx + 1).trim();\n      if (body.length() > 0) {\n        Map<String, String> aa = parseMap(body);\n        readNameValuePairs(args, aa);\n        if (!aa.isEmpty()) {\n          throw new IllegalArgumentException("unused parameters: " + aa);\n        }\n      }\n    }\n    args.validate();\n    return args;\n  }
196	final ByteBuffer[] map(String resourceDescription, FileChannel fc, long offset, long length) throws IOException {\n    if ((length >>> chunkSizePower) >= Integer.MAX_VALUE)\n      throw new IllegalArgumentException("RandomAccessFile too big for chunk size: " + resourceDescription);\n    \n    final long chunkSize = 1L << chunkSizePower;\n    \n        final int nrBuffers = (int) (length >>> chunkSizePower) + 1;\n    \n    ByteBuffer buffers[] = new ByteBuffer[nrBuffers];\n    \n    long bufferStart = 0L;\n    for (int bufNr = 0; bufNr < nrBuffers; bufNr++) { \n      int bufSize = (int) ( (length > (bufferStart + chunkSize))\n          ? chunkSize\n              : (length - bufferStart)\n          );\n      MappedByteBuffer buffer;\n      try {\n        buffer = fc.map(MapMode.READ_ONLY, offset + bufferStart, bufSize);\n      } catch (IOException ioe) {\n        throw convertMapFailedIOException(ioe, resourceDescription, bufSize);\n      }\n      if (preload) {\n        buffer.load();\n      }\n      buffers[bufNr] = buffer;\n      bufferStart += bufSize;\n    }\n    \n    return buffers;\n  }
197	private FST<Object> buildAutomaton(BytesRefSorter sorter) throws IOException {\n        final Outputs<Object> outputs = NoOutputs.getSingleton();\n    final Object empty = outputs.getNoOutput();\n    final Builder<Object> builder = new Builder<>(\n        FST.INPUT_TYPE.BYTE1, 0, 0, true, true, \n        shareMaxTailLength, outputs, true, 15);\n    \n    BytesRefBuilder scratch = new BytesRefBuilder();\n    BytesRef entry;\n    final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n    int count = 0;\n    BytesRefIterator iter = sorter.iterator();\n    while((entry = iter.next()) != null) {\n      count++;\n      if (scratch.get().compareTo(entry) != 0) {\n        builder.add(Util.toIntsRef(entry, scratchIntsRef), empty);\n        scratch.copyBytes(entry);\n      }\n    }\n    \n    return count == 0 ? null : builder.finish();\n  }
198	CharSequence processPattern(CharSequence input) {\n    final Matcher m = pattern.matcher(input);\n\n    final StringBuffer cumulativeOutput = new StringBuffer();\n    int cumulative = 0;\n    int lastMatchEnd = 0;\n    while (m.find()) {\n      final int groupSize = m.end() - m.start();\n      final int skippedSize = m.start() - lastMatchEnd;\n      lastMatchEnd = m.end();\n\n      final int lengthBeforeReplacement = cumulativeOutput.length() + skippedSize;\n      m.appendReplacement(cumulativeOutput, replacement);\n                  final int replacementSize = cumulativeOutput.length() - lengthBeforeReplacement;\n\n      if (groupSize != replacementSize) {\n        if (replacementSize < groupSize) {\n                                                  cumulative += groupSize - replacementSize;\n          int atIndex = lengthBeforeReplacement + replacementSize;\n                    addOffCorrectMap(atIndex, cumulative);\n        } else {\n                              for (int i = groupSize; i < replacementSize; i++) {\n            addOffCorrectMap(lengthBeforeReplacement + i, --cumulative);\n                      }\n        }\n      }\n    }\n\n        m.appendTail(cumulativeOutput);\n    return cumulativeOutput;    \n  }
199	@SuppressWarnings({"unchecked","rawtypes"})\n  private static Arc<Object>[] cacheRootArcs(FST<Object> automaton) {\n    try {\n      List<Arc<Object>> rootArcs = new ArrayList<>();\n      Arc<Object> arc = automaton.getFirstArc(new Arc<>());\n      FST.BytesReader fstReader = automaton.getBytesReader();\n      automaton.readFirstTargetArc(arc, arc, fstReader);\n      while (true) {\n        rootArcs.add(new Arc<>().copyFrom(arc));\n        if (arc.isLast()) break;\n        automaton.readNextArc(arc, fstReader);\n      }\n      \n      Collections.reverse(rootArcs);       return rootArcs.toArray(new Arc[rootArcs.size()]);\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }
200	protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n                  words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }
201	protected int hstrcmp(char[] s, int si, char[] t, int ti) {\n    for (; s[si] == t[ti]; si++, ti++) {\n      if (s[si] == 0) {\n        return 0;\n      }\n    }\n    if (t[ti] == 0) {\n      return 0;\n    }\n    return s[si] - t[ti];\n  }
202	public void insert(String key, char val) {\n        int len = key.length() + 1;     if (freenode + len > eq.length) {\n      redimNodeArrays(eq.length + BLOCK_SIZE);\n    }\n    char strkey[] = new char[len--];\n    key.getChars(0, len, strkey, 0);\n    strkey[len] = 0;\n    root = insert(root, strkey, 0, val);\n  }
203	public Calendar parseCalendar(String str) throws ParseException {\n        if (str == null || str.isEmpty())\n      throw new IllegalArgumentException("str is null or blank");\n    Calendar cal = newCal();\n    if (str.equals("*"))\n      return cal;\n    int offset = 0;    try {\n            int lastOffset = str.charAt(str.length()-1) == 'Z' ? str.length() - 1 : str.length();\n      int hyphenIdx = str.indexOf('-', 1);      if (hyphenIdx < 0)\n        hyphenIdx = lastOffset;\n      int year = Integer.parseInt(str.substring(offset, hyphenIdx));\n      cal.set(Calendar.ERA, year <= 0 ? 0 : 1);\n      cal.set(Calendar.YEAR, year <= 0 ? -1*year + 1 : year);\n      offset = hyphenIdx + 1;\n      if (lastOffset < offset)\n        return cal;\n\n            \n            cal.set(Calendar.MONTH, Integer.parseInt(str.substring(offset, offset+2)) - 1);      offset += 3;\n      if (lastOffset < offset)\n        return cal;\n            cal.set(Calendar.DAY_OF_MONTH, Integer.parseInt(str.substring(offset, offset+2)));\n      offset += 3;\n      if (lastOffset < offset)\n        return cal;\n            cal.set(Calendar.HOUR_OF_DAY, Integer.parseInt(str.substring(offset, offset+2)));\n      offset += 3;\n      if (lastOffset < offset)\n        return cal;\n            cal.set(Calendar.MINUTE, Integer.parseInt(str.substring(offset, offset+2)));\n      offset += 3;\n      if (lastOffset < offset)\n        return cal;\n            cal.set(Calendar.SECOND, Integer.parseInt(str.substring(offset, offset+2)));\n      offset += 3;\n      if (lastOffset < offset)\n        return cal;\n            cal.set(Calendar.MILLISECOND, Integer.parseInt(str.substring(offset, offset+3)));\n      offset += 3;      if (lastOffset == offset)\n        return cal;\n    } catch (Exception e) {\n      ParseException pe = new ParseException("Improperly formatted date: "+str, offset);\n      pe.initCause(e);\n      throw pe;\n    }\n    throw new ParseException("Improperly formatted date: "+str, offset);\n  }
204	public Query createMinShouldMatchQuery(String field, String queryText, float fraction) {\n    if (Float.isNaN(fraction) || fraction < 0 || fraction > 1) {\n      throw new IllegalArgumentException("fraction should be >= 0 and <= 1");\n    }\n    \n        if (fraction == 1) {\n      return createBooleanQuery(field, queryText, BooleanClause.Occur.MUST);\n    }\n    \n    Query query = createFieldQuery(analyzer, BooleanClause.Occur.SHOULD, field, queryText, false, 0);\n    if (query instanceof BooleanQuery) {\n      query = addMinShouldMatchToBoolean((BooleanQuery) query, fraction);\n    }\n    return query;\n  }
205	public static IntsRef toUTF16(CharSequence s, IntsRefBuilder scratch) {\n    final int charLimit = s.length();\n    scratch.setLength(charLimit);\n    scratch.grow(charLimit);\n    for (int idx = 0; idx < charLimit; idx++) {\n      scratch.setIntAt(idx, (int) s.charAt(idx));\n    }\n    return scratch.get();\n  }
206	private boolean advanceRepeatGroups() throws IOException {\n    for (PhrasePositions[] rg: rptGroups) { \n      if (hasMultiTermRpts) {\n                int incr;\n        for (int i=0; i<rg.length; i+=incr) {\n          incr = 1;\n          PhrasePositions pp = rg[i];\n          int k;\n          while((k=collide(pp)) >= 0) {\n            PhrasePositions pp2 = lesser(pp, rg[k]);\n            if (!advancePP(pp2)) {                return false;             }\n            if (pp2.rptInd < i) {               incr = 0;\n              break;\n            }\n          }\n        }\n      } else {\n                for (int j=1; j<rg.length; j++) {\n          for (int k=0; k<j; k++) {\n            if (!rg[j].nextPosition()) {\n              return false;             }\n          }\n        }\n      }\n    }\n    return true;   }
207	public static void main(String[] args) {\n    String usage = "java org.apache.lucene.demo.IndexFiles"\n                 + " [-index INDEX_PATH] [-docs DOCS_PATH] [-update]\n\n"\n                 + "This indexes the documents in DOCS_PATH, creating a Lucene index"\n                 + "in INDEX_PATH that can be searched with SearchFiles";\n    String indexPath = "index";\n    String docsPath = null;\n    boolean create = true;\n    for(int i=0;i<args.length;i++) {\n      if ("-index".equals(args[i])) {\n        indexPath = args[i+1];\n        i++;\n      } else if ("-docs".equals(args[i])) {\n        docsPath = args[i+1];\n        i++;\n      } else if ("-update".equals(args[i])) {\n        create = false;\n      }\n    }\n\n    if (docsPath == null) {\n      System.err.println("Usage: " + usage);\n      System.exit(1);\n    }\n\n    final Path docDir = Paths.get(docsPath);\n    if (!Files.isReadable(docDir)) {\n      System.out.println("Document directory '" +docDir.toAbsolutePath()+ "' does not exist or is not readable, please check the path");\n      System.exit(1);\n    }\n    \n    Date start = new Date();\n    try {\n      System.out.println("Indexing to directory '" + indexPath + "'...");\n\n      Directory dir = FSDirectory.open(Paths.get(indexPath));\n      Analyzer analyzer = new StandardAnalyzer();\n      IndexWriterConfig iwc = new IndexWriterConfig(analyzer);\n\n      if (create) {\n                        iwc.setOpenMode(OpenMode.CREATE);\n      } else {\n                iwc.setOpenMode(OpenMode.CREATE_OR_APPEND);\n      }\n\n                                    \n      IndexWriter writer = new IndexWriter(dir, iwc);\n      indexDocs(writer, docDir);\n\n                                          \n      writer.close();\n\n      Date end = new Date();\n      System.out.println(end.getTime() - start.getTime() + " total milliseconds");\n\n    } catch (IOException e) {\n      System.out.println(" caught a " + e.getClass() +\n       "\n with message: " + e.getMessage());\n    }\n  }
208	public boolean bytesEquals(BytesRef other) {\n    assert other != null;\n    if (length == other.length) {\n      int otherUpto = other.offset;\n      final byte[] otherBytes = other.bytes;\n      final int end = offset + length;\n      for(int upto=offset;upto<end;upto++,otherUpto++) {\n        if (bytes[upto] != otherBytes[otherUpto]) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n      return false;\n    }\n  }
209	public static int getNearestSetSize(int maxNumberOfBits)\n  {\n    int result=usableBitSetSizes[0];\n    for (int i = 0; i < usableBitSetSizes.length; i++) {\n      if(usableBitSetSizes[i]<=maxNumberOfBits)\n      {\n        result=usableBitSetSizes[i];\n      }\n    }\n    return result;\n  }
210	protected void extractFile(Path sgmFile) {\n    try (BufferedReader reader = Files.newBufferedReader(sgmFile, StandardCharsets.ISO_8859_1)) {\n      StringBuilder buffer = new StringBuilder(1024);\n      StringBuilder outBuffer = new StringBuilder(1024);\n\n      String line = null;\n      int docNumber = 0;\n      while ((line = reader.readLine()) != null) {\n        \n        if (line.indexOf("</REUTERS") == -1) {\n          \n          buffer.append(line).append(' ');                                                                                            } else {\n                    Matcher matcher = EXTRACTION_PATTERN.matcher(buffer);\n          while (matcher.find()) {\n            for (int i = 1; i <= matcher.groupCount(); i++) {\n              if (matcher.group(i) != null) {\n                outBuffer.append(matcher.group(i));\n              }\n            }\n            outBuffer.append(System.lineSeparator()).append(System.lineSeparator());\n          }\n          String out = outBuffer.toString();\n          for (int i = 0; i < META_CHARS_SERIALIZATIONS.length; i++) {\n            out = out.replaceAll(META_CHARS_SERIALIZATIONS[i], META_CHARS[i]);\n          }\n          Path outFile = outputDir.resolve(sgmFile.getFileName() + "-" + (docNumber++) + ".txt");\n                    try (BufferedWriter writer = Files.newBufferedWriter(outFile, StandardCharsets.UTF_8)) {\n            writer.write(out);\n          }\n          outBuffer.setLength(0);\n          buffer.setLength(0);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }
211	static Automaton reverse(Automaton a, Set<Integer> initialStates) {\n\n    if (Operations.isEmpty(a)) {\n      return new Automaton();\n    }\n\n    int numStates = a.getNumStates();\n\n        Automaton.Builder builder = new Automaton.Builder();\n\n        builder.createState();\n\n    for(int s=0;s<numStates;s++) {\n      builder.createState();\n    }\n\n        builder.setAccept(1, true);\n\n    Transition t = new Transition();\n    for (int s=0;s<numStates;s++) {\n      int numTransitions = a.getNumTransitions(s);\n      a.initTransition(s, t);\n      for(int i=0;i<numTransitions;i++) {\n        a.getNextTransition(t);\n        builder.addTransition(t.dest+1, s+1, t.min, t.max);\n      }\n    }\n\n    Automaton result = builder.finish();\n\n    int s = 0;\n    BitSet acceptStates = a.getAcceptStates();\n    while (s < numStates && (s = acceptStates.nextSetBit(s)) != -1) {\n      result.addEpsilon(0, s+1);\n      if (initialStates != null) {\n        initialStates.add(s+1);\n      }\n      s++;\n    }\n\n    result.finishState();\n\n    return result;\n  }
212	public final T pop() {\n    if (size > 0) {\n      T result = heap[1];             heap[1] = heap[size];           heap[size] = null;              size--;\n      downHeap(1);                    return result;\n    } else {\n      return null;\n    }\n  }
213	public void clear(long startIndex, long endIndex) {\n    assert startIndex >= 0 && startIndex < numBits : "startIndex=" + startIndex + ", numBits=" + numBits;\n    assert endIndex >= 0 && endIndex <= numBits : "endIndex=" + endIndex + ", numBits=" + numBits;\n    if (endIndex <= startIndex) {\n      return;\n    }\n\n    int startWord = (int) (startIndex >> 6);\n    int endWord = (int) ((endIndex-1) >> 6);\n\n    long startmask = -1L << startIndex;\n    long endmask = -1L >>> -endIndex;  \n        startmask = ~startmask;\n    endmask = ~endmask;\n\n    if (startWord == endWord) {\n      bits[startWord] &= (startmask | endmask);\n      return;\n    }\n\n    bits[startWord] &= startmask;\n    Arrays.fill(bits, startWord+1, endWord, 0L);\n    bits[endWord] &= endmask;\n  }
214	public synchronized void stopUpdateThread() {\n    if (updateThread != null) {\n                        updateThread.stop.countDown();\n      try {\n        updateThread.join();\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ThreadInterruptedException(e);\n      }\n      updateThread = null;\n    }\n  }
215	private List<FacetResult> drillSideways() throws IOException {\n    DirectoryReader indexReader = DirectoryReader.open(indexDir);\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);\n\n            DrillDownQuery q = new DrillDownQuery(config);\n\n        q.add("Publish Date", "2010");\n\n    DrillSideways ds = new DrillSideways(searcher, config, taxoReader);\n    DrillSidewaysResult result = ds.search(q, 10);\n\n        List<FacetResult> facets = result.facets.getAllDims(10);\n\n    indexReader.close();\n    taxoReader.close();\n    \n    return facets;\n  }
216	public void reverse(long srcPos, long destPos) {\n    assert srcPos < destPos;\n    assert destPos < getPosition();\n    \n    int srcBlockIndex = (int) (srcPos >> blockBits);\n    int src = (int) (srcPos & blockMask);\n    byte[] srcBlock = blocks.get(srcBlockIndex);\n\n    int destBlockIndex = (int) (destPos >> blockBits);\n    int dest = (int) (destPos & blockMask);\n    byte[] destBlock = blocks.get(destBlockIndex);\n    \n    int limit = (int) (destPos - srcPos + 1)/2;\n    for(int i=0;i<limit;i++) {\n            byte b = srcBlock[src];\n      srcBlock[src] = destBlock[dest];\n      destBlock[dest] = b;\n      src++;\n      if (src == blockSize) {\n        srcBlockIndex++;\n        srcBlock = blocks.get(srcBlockIndex);\n                src = 0;\n      }\n\n      dest--;\n      if (dest == -1) {\n        destBlockIndex--;\n        destBlock = blocks.get(destBlockIndex);\n                dest = blockSize-1;\n      }\n    }\n  }
217	protected LeafSlice[] slices(List<LeafReaderContext> leaves) {\n    LeafSlice[] slices = new LeafSlice[leaves.size()];\n    for (int i = 0; i < slices.length; i++) {\n      slices[i] = new LeafSlice(leaves.get(i));\n    }\n    return slices;\n  }
218	static Class<?> readClass(final InputStream inputStream) throws IOException, ClassNotFoundException {\n    boolean standard = readBoolean(inputStream);\n    if (standard) {\n      int index = inputStream.read();\n      return StandardObjects.codeRegsitry.get(index);\n    }\n    else {\n      String className = readString(inputStream);\n      return  Class.forName(className);\n    }\n  }
219	protected Query analyzeMultiBoolean(String field, TokenStream stream, BooleanClause.Occur operator) throws IOException {\n    BooleanQuery.Builder q = newBooleanQuery();\n    List<Term> currentQuery = new ArrayList<>();\n    \n    TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class);\n    \n    stream.reset();\n    while (stream.incrementToken()) {\n      if (posIncrAtt.getPositionIncrement() != 0) {\n        add(q, currentQuery, operator);\n        currentQuery.clear();\n      }\n      currentQuery.add(new Term(field, termAtt.getBytesRef()));\n    }\n    add(q, currentQuery, operator);\n    \n    return q.build();\n  }
220	private void collectExternalDependenciesFromIvyXmlFile(File ivyXmlFile)\n      throws XPathExpressionException, IOException, SAXException {\n    String module = getModuleName(ivyXmlFile);\n    log("Collecting external dependencies from: " + ivyXmlFile.getPath(), verboseLevel);\n    Document document = documentBuilder.parse(ivyXmlFile);\n        String dependencyPath = "/ivy-module/dependencies/dependency[not(starts-with(@conf,'start'))]";\n    NodeList dependencies = (NodeList)xpath.evaluate(dependencyPath, document, XPathConstants.NODESET);\n    for (int depNum = 0 ; depNum < dependencies.getLength() ; ++depNum) {\n      Element dependency = (Element)dependencies.item(depNum);\n      String groupId = dependency.getAttribute("org");\n      String artifactId = dependency.getAttribute("name");\n      String dependencyCoordinate = groupId + ':' + artifactId;\n      Set<String> classifiers = dependencyClassifiers.get(dependencyCoordinate);\n      if (null == classifiers) {\n        classifiers = new HashSet<>();\n        dependencyClassifiers.put(dependencyCoordinate, classifiers);\n      }\n      String conf = dependency.getAttribute("conf");\n      boolean confContainsTest = conf.contains("test");\n      boolean isOptional = globalOptionalExternalDependencies.contains(dependencyCoordinate)\n          || ( perModuleOptionalExternalDependencies.containsKey(module)\n              && perModuleOptionalExternalDependencies.get(module).contains(dependencyCoordinate));\n      SortedSet<ExternalDependency> deps = allExternalDependencies.get(module);\n      if (null == deps) {\n        deps = new TreeSet<>();\n        allExternalDependencies.put(module, deps);\n      }\n      NodeList artifacts = null;\n      if (dependency.hasChildNodes()) {\n        artifacts = (NodeList)xpath.evaluate("artifact", dependency, XPathConstants.NODESET);\n      }\n      if (null != artifacts && artifacts.getLength() > 0) {\n        for (int artifactNum = 0 ; artifactNum < artifacts.getLength() ; ++artifactNum) {\n          Element artifact = (Element)artifacts.item(artifactNum);\n          String type = artifact.getAttribute("type");\n          String ext = artifact.getAttribute("ext");\n                    boolean isTestDependency = confContainsTest && (type.equals("test") || ! conf.contains("compile"));\n          if ((type.isEmpty() && ext.isEmpty()) || type.equals("jar") || ext.equals("jar")) {\n            String classifier = artifact.getAttribute("maven:classifier");\n            if (classifier.isEmpty()) {\n              classifier = null;\n            }\n            classifiers.add(classifier);\n            deps.add(new ExternalDependency(groupId, artifactId, classifier, isTestDependency, isOptional));\n          } else {             nonJarDependencies.add(dependencyCoordinate);\n          }\n        }\n      } else {\n        classifiers.add(null);\n        deps.add(new ExternalDependency(groupId, artifactId, null, confContainsTest, isOptional));\n      }\n    }\n  }
221	public void balancedTree(Object[] tokens, Object[] vals, int lo, int hi,\n          TernaryTreeNode root) {\n    if (lo > hi) return;\n    int mid = (lo + hi) / 2;\n    root = insert(root, (String) tokens[mid], vals[mid], 0);\n    balancedTree(tokens, vals, lo, mid - 1, root);\n    balancedTree(tokens, vals, mid + 1, hi, root);\n  }
222	private void pushCurrentDoc() {\n    for(int i=0;i<numSubsOnDoc;i++) {\n      docIDQueue.add(subsOnDoc[i]);\n    }\n    numSubsOnDoc = 0;\n  }
223	protected synchronized MergeThread getMergeThread(IndexWriter writer, OneMerge merge) throws IOException {\n    final MergeThread thread = new MergeThread(writer, merge);\n    thread.setDaemon(true);\n    thread.setName("Lucene Merge Thread #" + mergeThreadCount++);\n    return thread;\n  }
224	private void doQueryFirstScoring(Bits acceptDocs, LeafCollector collector, DocsAndCost[] dims) throws IOException {\n                int docID = baseScorer.docID();\n\n    nextDoc: while (docID != PostingsEnum.NO_MORE_DOCS) {\n      if (acceptDocs != null && acceptDocs.get(docID) == false) {\n        docID = baseIterator.nextDoc();\n        continue;\n      }\n      LeafCollector failedCollector = null;\n      for (DocsAndCost dim : dims) {\n                        if (dim.approximation.docID() < docID) {\n          dim.approximation.advance(docID);\n        }\n\n        boolean matches = false;\n        if (dim.approximation.docID() == docID) {\n          if (dim.twoPhase == null) {\n            matches = true;\n          } else {\n            matches = dim.twoPhase.matches();\n          }\n        }\n\n        if (matches == false) {\n          if (failedCollector != null) {\n                                                docID = baseIterator.nextDoc();\n            continue nextDoc;\n          } else {\n            failedCollector = dim.sidewaysLeafCollector;\n          }\n        }\n      }\n\n      collectDocID = docID;\n\n                  collectScore = baseScorer.score();\n\n      if (failedCollector == null) {\n                collectHit(collector, dims);\n      } else {\n                collectNearMiss(failedCollector);\n      }\n\n      docID = baseIterator.nextDoc();\n    }\n  }
225	private void finishCurrentState() {\n    int numTransitions = states[2*curState+1];\n    assert numTransitions > 0;\n\n    int offset = states[2*curState];\n    int start = offset/3;\n    destMinMaxSorter.sort(start, start+numTransitions);\n\n        int upto = 0;\n    int min = -1;\n    int max = -1;\n    int dest = -1;\n\n    for(int i=0;i<numTransitions;i++) {\n      int tDest = transitions[offset+3*i];\n      int tMin = transitions[offset+3*i+1];\n      int tMax = transitions[offset+3*i+2];\n\n      if (dest == tDest) {\n        if (tMin <= max+1) {\n          if (tMax > max) {\n            max = tMax;\n          }\n        } else {\n          if (dest != -1) {\n            transitions[offset+3*upto] = dest;\n            transitions[offset+3*upto+1] = min;\n            transitions[offset+3*upto+2] = max;\n            upto++;\n          }\n          min = tMin;\n          max = tMax;\n        }\n      } else {\n        if (dest != -1) {\n          transitions[offset+3*upto] = dest;\n          transitions[offset+3*upto+1] = min;\n          transitions[offset+3*upto+2] = max;\n          upto++;\n        }\n        dest = tDest;\n        min = tMin;\n        max = tMax;\n      }\n    }\n\n    if (dest != -1) {\n            transitions[offset+3*upto] = dest;\n      transitions[offset+3*upto+1] = min;\n      transitions[offset+3*upto+2] = max;\n      upto++;\n    }\n\n    nextTransition -= (numTransitions-upto)*3;\n    states[2*curState+1] = upto;\n\n        minMaxDestSorter.sort(start, start+upto);\n\n    if (deterministic && upto > 1) {\n      int lastMax = transitions[offset+2];\n      for(int i=1;i<upto;i++) {\n        min = transitions[offset + 3*i + 1];\n        if (min <= lastMax) {\n          deterministic = false;\n          break;\n        }\n        lastMax = transitions[offset + 3*i + 2];\n      }\n    }\n  }
226	public void split(IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException("Invalid number of outputs.");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException("Not enough documents for splitting");\n    }\n    int numParts = outputs.length;\n                FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) {         int lo = partLen * i;\n        int hi = lo + partLen;\n                for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n                        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n                for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println("Writing part " + (i + 1) + " ...");\n            final List<? extends FakeDeleteLeafIndexReader> sr = input.getSequentialSubReaders();\n      w.addIndexes(sr.toArray(new CodecReader[sr.size()]));       w.close();\n    }\n    System.err.println("Done.");\n  }
227	public static GeoBBox makeGeoBBox(final PlanetModel planetModel, double topLat, double bottomLat, double leftLon, double rightLon) {\n        if (topLat > Math.PI * 0.5)\n      topLat = Math.PI * 0.5;\n    if (bottomLat < -Math.PI * 0.5)\n      bottomLat = -Math.PI * 0.5;\n    if (leftLon < -Math.PI)\n      leftLon = -Math.PI;\n    if (rightLon > Math.PI)\n      rightLon = Math.PI;\n    if ((Math.abs(leftLon + Math.PI) < Vector.MINIMUM_ANGULAR_RESOLUTION && Math.abs(rightLon - Math.PI) < Vector.MINIMUM_ANGULAR_RESOLUTION) ||\n        (Math.abs(rightLon + Math.PI) < Vector.MINIMUM_ANGULAR_RESOLUTION && Math.abs(leftLon - Math.PI) < Vector.MINIMUM_ANGULAR_RESOLUTION)) {\n      if (Math.abs(topLat - Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION && Math.abs(bottomLat + Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION)\n        return new GeoWorld(planetModel);\n      if (Math.abs(topLat - bottomLat) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n        if (Math.abs(topLat - Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION || Math.abs(topLat + Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION)\n          return new GeoDegeneratePoint(planetModel, topLat, 0.0);\n        return new GeoDegenerateLatitudeZone(planetModel, topLat);\n      }\n      if (Math.abs(topLat - Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION)\n        return new GeoNorthLatitudeZone(planetModel, bottomLat);\n      else if (Math.abs(bottomLat + Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION)\n        return new GeoSouthLatitudeZone(planetModel, topLat);\n      return new GeoLatitudeZone(planetModel, topLat, bottomLat);\n    }\n        double extent = rightLon - leftLon;\n    if (extent < 0.0)\n      extent += Math.PI * 2.0;\n    if (topLat == Math.PI * 0.5 && bottomLat == -Math.PI * 0.5) {\n      if (Math.abs(leftLon - rightLon) < Vector.MINIMUM_ANGULAR_RESOLUTION)\n        return new GeoDegenerateLongitudeSlice(planetModel, leftLon);\n\n      if (extent >= Math.PI)\n        return new GeoWideLongitudeSlice(planetModel, leftLon, rightLon);\n\n      return new GeoLongitudeSlice(planetModel, leftLon, rightLon);\n    }\n        if (Math.abs(leftLon - rightLon) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n      if (Math.abs(topLat - bottomLat) < Vector.MINIMUM_ANGULAR_RESOLUTION)\n        return new GeoDegeneratePoint(planetModel, topLat, leftLon);\n      return new GeoDegenerateVerticalLine(planetModel, topLat, bottomLat, leftLon);\n    }\n        if (extent >= Math.PI) {\n      if (Math.abs(topLat - bottomLat) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n        if (Math.abs(topLat - Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n          return new GeoDegeneratePoint(planetModel, topLat, 0.0);\n        } else if (Math.abs(bottomLat + Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n          return new GeoDegeneratePoint(planetModel, bottomLat, 0.0);\n        }\n                return new GeoWideDegenerateHorizontalLine(planetModel, topLat, leftLon, rightLon);\n      }\n      if (Math.abs(topLat - Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n        return new GeoWideNorthRectangle(planetModel, bottomLat, leftLon, rightLon);\n      } else if (Math.abs(bottomLat + Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n        return new GeoWideSouthRectangle(planetModel, topLat, leftLon, rightLon);\n      }\n            return new GeoWideRectangle(planetModel, topLat, bottomLat, leftLon, rightLon);\n    }\n    if (Math.abs(topLat - bottomLat) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n      if (Math.abs(topLat - Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n        return new GeoDegeneratePoint(planetModel, topLat, 0.0);\n      } else if (Math.abs(bottomLat + Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n        return new GeoDegeneratePoint(planetModel, bottomLat, 0.0);\n      }\n            return new GeoDegenerateHorizontalLine(planetModel, topLat, leftLon, rightLon);\n    }\n    if (Math.abs(topLat - Math.PI * 0.5) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n      return new GeoNorthRectangle(planetModel, bottomLat, leftLon, rightLon);\n    } else if (Math.abs(bottomLat + Math.PI * 0.5) <  Vector.MINIMUM_ANGULAR_RESOLUTION) {\n      return new GeoSouthRectangle(planetModel, topLat, leftLon, rightLon);\n    }\n        return new GeoRectangle(planetModel, topLat, bottomLat, leftLon, rightLon);\n  }
228	protected Encoder getEncoder() {\n            try {\n      Encoder encoder = clazz.newInstance();\n            if(maxCodeLength != null && setMaxCodeLenMethod != null) {\n        setMaxCodeLenMethod.invoke(encoder, maxCodeLength);\n      }\n      return encoder;\n    } catch (Exception e) {\n      final Throwable t = (e instanceof InvocationTargetException) ? e.getCause() : e;\n      throw new IllegalArgumentException("Error initializing encoder: " + name + " / " + clazz, t);\n    }\n  }
229	public synchronized IndexCommit snapshot() throws IOException {\n    if (!initCalled) {\n      throw new IllegalStateException("this instance is not being used by IndexWriter; be sure to use the instance returned from writer.getConfig().getIndexDeletionPolicy()");\n    }\n    if (lastCommit == null) {\n            throw new IllegalStateException("No index commit to snapshot");\n    }\n\n    incRef(lastCommit);\n\n    return lastCommit;\n  }
230	int next() {\n    int next = rbbi.next();\n    while (next == BreakIterator.DONE && scriptIterator.next()) {\n      rbbi = getBreakIterator(scriptIterator.getScriptCode());\n      rbbi.setText(text, scriptIterator.getScriptStart(), \n          scriptIterator.getScriptLimit() - scriptIterator.getScriptStart());\n      next = rbbi.next();\n    }\n    return (next == BreakIterator.DONE) ? BreakIterator.DONE : next\n        + scriptIterator.getScriptStart();\n  }
231	protected Passage[] getSummaryPassagesNoHighlight(int maxPassages) {\n    assert breakIterator.current() == breakIterator.first();\n\n    List<Passage> passages = new ArrayList<>(Math.min(maxPassages, 10));\n    int pos = breakIterator.current();\n    assert pos == 0;\n    while (passages.size() < maxPassages) {\n      int next = breakIterator.next();\n      if (next == BreakIterator.DONE) {\n        break;\n      }\n      Passage passage = new Passage();\n      passage.setScore(Float.NaN);\n      passage.setStartOffset(pos);\n      passage.setEndOffset(next);\n      passages.add(passage);\n      pos = next;\n    }\n\n    return passages.toArray(new Passage[passages.size()]);\n  }
232	protected void releaseGen(long gen) throws IOException {\n    if (!initCalled) {\n      throw new IllegalStateException("this instance is not being used by IndexWriter; be sure to use the instance returned from writer.getConfig().getIndexDeletionPolicy()");\n    }\n    Integer refCount = refCounts.get(gen);\n    if (refCount == null) {\n      throw new IllegalArgumentException("commit gen=" + gen + " is not currently snapshotted");\n    }\n    int refCountInt = refCount.intValue();\n    assert refCountInt > 0;\n    refCountInt--;\n    if (refCountInt == 0) {\n      refCounts.remove(gen);\n      indexCommits.remove(gen);\n    } else {\n      refCounts.put(gen, refCountInt);\n    }\n  }
233	private int mergeMiddle(MergePolicy.OneMerge merge, MergePolicy mergePolicy) throws IOException {\n    merge.checkAborted();\n\n    Directory mergeDirectory = config.getMergeScheduler().wrapForMerge(merge, directory);\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getStoreMergeInfo());\n\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(mergeDirectory);\n\n    if (infoStream.isEnabled("IW")) {\n      infoStream.message("IW", "merging " + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>(sourceSegments.size());\n\n            boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n                        final ReadersAndUpdates rld = readerPool.get(info, true);\n        rld.setIsMerging();\n\n        SegmentReader reader = rld.getReaderForMerge(context);\n        int delCount = reader.numDeletedDocs();\n\n        if (infoStream.isEnabled("IW")) {\n          infoStream.message("IW", "seg=" + segString(info) + " reader=" + reader);\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.maxDoc(): "delCount=" + delCount + " info.maxDoc=" + info.info.maxDoc() + " rld.pendingDeleteCount=" + rld.getPendingDeleteCount() + " info.getDelCount()=" + info.getDelCount();\n        segUpto++;\n      }\n\n            List<CodecReader> mergeReaders = new ArrayList<>();\n      for (SegmentReader reader : merge.readers) {\n        CodecReader wrappedReader = merge.wrapForMerge(reader);\n        validateMergeReader(wrappedReader);\n        mergeReaders.add(wrappedReader);\n      }\n      final SegmentMerger merger = new SegmentMerger(mergeReaders,\n                                                     merge.info.info, infoStream, dirWrapper,\n                                                     globalFieldNumberMap, \n                                                     context);\n\n      merge.checkAborted();\n\n      merge.mergeStartNS = System.nanoTime();\n\n            if (merger.shouldMerge()) {\n        merger.merge();\n      }\n\n      MergeState mergeState = merger.mergeState;\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      if (infoStream.isEnabled("IW")) {\n        if (merger.shouldMerge()) {\n          String pauseInfo = merge.getMergeProgress().getPauseTimes().entrySet()\n            .stream()\n            .filter((e) -> e.getValue() > 0)\n            .map((e) -> String.format(Locale.ROOT, "%.1f sec %s", \n                e.getValue() / 1000000000., \n                e.getKey().name().toLowerCase(Locale.ROOT)))\n            .collect(Collectors.joining(", "));\n          if (!pauseInfo.isEmpty()) {\n            pauseInfo = " (" + pauseInfo + ")";\n          }\n\n          long t1 = System.nanoTime();\n          double sec = (t1-merge.mergeStartNS)/1000000000.;\n          double segmentMB = (merge.info.sizeInBytes()/1024./1024.);\n          infoStream.message("IW", "merge codec=" + codec + " maxDoc=" + merge.info.info.maxDoc() + "; merged segment has " +\n                             (mergeState.mergeFieldInfos.hasVectors() ? "vectors" : "no vectors") + "; " +\n                             (mergeState.mergeFieldInfos.hasNorms() ? "norms" : "no norms") + "; " + \n                             (mergeState.mergeFieldInfos.hasDocValues() ? "docValues" : "no docValues") + "; " + \n                             (mergeState.mergeFieldInfos.hasProx() ? "prox" : "no prox") + "; " + \n                             (mergeState.mergeFieldInfos.hasProx() ? "freqs" : "no freqs") + "; " +\n                             (mergeState.mergeFieldInfos.hasPointValues() ? "points" : "no points") + "; " +\n                             String.format(Locale.ROOT,\n                                           "%.1f sec%s to merge segment [%.2f MB, %.2f MB/sec]",\n                                           sec,\n                                           pauseInfo,\n                                           segmentMB,\n                                           segmentMB / sec));\n        } else {\n          infoStream.message("IW", "skip merging fully deleted segments");\n        }\n      }\n\n      if (merger.shouldMerge() == false) {\n                assert merge.info.info.maxDoc() == 0;\n        commitMerge(merge, mergeState);\n        return 0;\n      }\n\n      assert merge.info.info.maxDoc() > 0;\n\n                        boolean useCompoundFile;\n      synchronized (this) {         useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info, this);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n        TrackingDirectoryWrapper trackingCFSDir = new TrackingDirectoryWrapper(mergeDirectory);\n        try {\n          createCompoundFile(infoStream, trackingCFSDir, merge.info.info, context);\n          success = true;\n        } catch (Throwable t) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n                                                        if (infoStream.isEnabled("IW")) {\n                infoStream.message("IW", "hit merge abort exception creating compound file during merge");\n              }\n              return 0;\n            } else {\n              handleMergeException(t, merge);\n            }\n          }\n        } finally {\n          if (success == false) {\n            if (infoStream.isEnabled("IW")) {\n              infoStream.message("IW", "hit exception creating compound file during merge");\n            }\n                        deleteNewFiles(merge.info.files());\n          }\n        }\n\n                                success = false;\n\n        synchronized(this) {\n\n                              deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled("IW")) {\n              infoStream.message("IW", "abort merge after building CFS");\n            }\n                        deleteNewFiles(merge.info.files());\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n                                success = false;\n      }\n\n                              boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().write(directory, merge.info.info, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n                    deleteNewFiles(merge.info.files());\n        }\n      }\n\n                  \n      if (infoStream.isEnabled("IW")) {\n        infoStream.message("IW", String.format(Locale.ROOT, "merged segment size=%.3f MB vs estimate=%.3f MB", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      if (!commitMerge(merge, mergeState)) {\n                        return 0;\n      }\n\n      success = true;\n\n    } finally {\n                  if (success == false) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.maxDoc();\n  }
234	public final String getBestFragments(\n    TokenStream tokenStream,\n    String text,\n    int maxNumFragments,\n    String separator)\n    throws IOException, InvalidTokenOffsetsException\n  {\n    String sections[] =  getBestFragments(tokenStream,text, maxNumFragments);\n    StringBuilder result = new StringBuilder();\n    for (int i = 0; i < sections.length; i++)\n    {\n      if (i > 0)\n      {\n        result.append(separator);\n      }\n      result.append(sections[i]);\n    }\n    return result.toString();\n  }
235	public Bounds addZValue(final double z) {\n    final double small = z - FUDGE_FACTOR;\n    if (minZ == null || minZ > small) {\n      minZ = new Double(small);\n    }\n    final double large = z + FUDGE_FACTOR;\n    if (maxZ == null || maxZ < large) {\n      maxZ = new Double(large);\n    }\n    return this;\n  }
236	private void setDocAndFreq() {\n    assert head.size() > 0;\n\n            lead = head.pop();\n    lead.next = null;\n    freq = 1;\n    doc = lead.doc;\n    while (head.size() > 0 && head.top().doc == doc) {\n      addLead(head.pop());\n    }\n  }
237	public int stem(char text[], int length, boolean stemDerivational) {\n    flags = 0;\n    numSyllables = 0;\n    for (int i = 0; i < length; i++)\n      if (isVowel(text[i]))\n          numSyllables++;\n    \n    if (numSyllables > 2) length = removeParticle(text, length);\n    if (numSyllables > 2) length = removePossessivePronoun(text, length);\n    \n    if (stemDerivational)\n      length = stemDerivational(text, length);\n    return length;\n  }
238	public synchronized long updateDocument(String id, Document doc) throws IOException {\n    assert buffer.getFilePointer() == 0;\n    buffer.writeByte(OP_UPDATE_DOCUMENT);\n    encode(id, doc);\n    return flushBuffer();\n  }
239	public static XYZSolid makeXYZSolid(final PlanetModel planetModel, final double minX, final double maxX, final double minY, final double maxY, final double minZ, final double maxZ) {\n    if (Math.abs(maxX - minX) < Vector.MINIMUM_RESOLUTION) {\n      if (Math.abs(maxY - minY) < Vector.MINIMUM_RESOLUTION) {\n        if (Math.abs(maxZ - minZ) < Vector.MINIMUM_RESOLUTION) {\n          return new dXdYdZSolid(planetModel, (minX+maxX) * 0.5, (minY+maxY) * 0.5, minZ);\n        } else {\n          return new dXdYZSolid(planetModel, (minX+maxX) * 0.5, (minY+maxY) * 0.5, minZ, maxZ);\n        }\n      } else {\n        if (Math.abs(maxZ - minZ) < Vector.MINIMUM_RESOLUTION) {\n          return new dXYdZSolid(planetModel, (minX+maxX) * 0.5, minY, maxY, (minZ+maxZ) * 0.5);\n        } else {\n          return new dXYZSolid(planetModel, (minX+maxX) * 0.5, minY, maxY, minZ, maxZ);\n        }\n      }\n    }\n    if (Math.abs(maxY - minY) < Vector.MINIMUM_RESOLUTION) {\n      if (Math.abs(maxZ - minZ) < Vector.MINIMUM_RESOLUTION) {\n        return new XdYdZSolid(planetModel, minX, maxX, (minY+maxY) * 0.5, (minZ+maxZ) * 0.5);\n      } else {\n        return new XdYZSolid(planetModel, minX, maxX, (minY+maxY) * 0.5, minZ, maxZ);\n      }\n    }\n    if (Math.abs(maxZ - minZ) < Vector.MINIMUM_RESOLUTION) {\n      return new XYdZSolid(planetModel, minX, maxX, minY, maxY, (minZ+maxZ) * 0.5);\n    }\n    return new StandardXYZSolid(planetModel, minX, maxX, minY, maxY, minZ, maxZ);\n  }
240	public synchronized long tryDeleteDocument(IndexReader readerIn, int docID) throws IOException {\n\n    final LeafReader reader;\n    if (readerIn instanceof LeafReader) {\n            reader = (LeafReader) readerIn;\n    } else {\n            List<LeafReaderContext> leaves = readerIn.leaves();\n      int subIndex = ReaderUtil.subIndex(docID, leaves);\n      reader = leaves.get(subIndex).reader();\n      docID -= leaves.get(subIndex).docBase;\n      assert docID >= 0;\n      assert docID < reader.maxDoc();\n    }\n\n    if (!(reader instanceof SegmentReader)) {\n      throw new IllegalArgumentException("the reader must be a SegmentReader or composite reader containing only SegmentReaders");\n    }\n      \n    final SegmentCommitInfo info = ((SegmentReader) reader).getSegmentInfo();\n\n                \n    if (segmentInfos.indexOf(info) != -1) {\n      ReadersAndUpdates rld = readerPool.get(info, false);\n      if (rld != null) {\n        synchronized(bufferedUpdatesStream) {\n          if (rld.delete(docID)) {\n            final int fullDelCount = rld.info.getDelCount() + rld.getPendingDeleteCount();\n            if (fullDelCount == rld.info.info.maxDoc()) {\n              dropDeletedSegment(rld.info);\n              checkpoint();\n            }\n\n                                    changed();\n          }\n          return docWriter.deleteQueue.getNextSequenceNumber();\n        }\n      }\n    }\n\n    return -1;\n  }
241	private void caseFoldTitle(char word[], int length) {\n    titleBuffer = ArrayUtil.grow(titleBuffer, length);\n    System.arraycopy(word, 0, titleBuffer, 0, length);\n    for (int i = 1; i < length; i++) {\n      titleBuffer[i] = dictionary.caseFold(titleBuffer[i]);\n    }\n  }
242	private static CharSequence replaceIgnoreCase(CharSequence string,\n      CharSequence sequence1, CharSequence escapeChar, Locale locale) {\n    if (escapeChar == null || sequence1 == null || string == null)\n      throw new NullPointerException();\n\n        int count = string.length();\n    int sequence1Length = sequence1.length();\n    if (sequence1Length == 0) {\n      StringBuilder result = new StringBuilder((count + 1)\n          * escapeChar.length());\n      result.append(escapeChar);\n      for (int i = 0; i < count; i++) {\n        result.append(string.charAt(i));\n        result.append(escapeChar);\n      }\n      return result.toString();\n    }\n\n        StringBuilder result = new StringBuilder();\n    char first = sequence1.charAt(0);\n    int start = 0, copyStart = 0, firstIndex;\n    while (start < count) {\n      if ((firstIndex = string.toString().toLowerCase(locale).indexOf(first,\n          start)) == -1)\n        break;\n      boolean found = true;\n      if (sequence1.length() > 1) {\n        if (firstIndex + sequence1Length > count)\n          break;\n        for (int i = 1; i < sequence1Length; i++) {\n          if (string.toString().toLowerCase(locale).charAt(firstIndex + i) != sequence1\n              .charAt(i)) {\n            found = false;\n            break;\n          }\n        }\n      }\n      if (found) {\n        result.append(string.toString().substring(copyStart, firstIndex));\n        result.append(escapeChar);\n        result.append(string.toString().substring(firstIndex,\n            firstIndex + sequence1Length));\n        copyStart = start = firstIndex + sequence1Length;\n      } else {\n        start = firstIndex + 1;\n      }\n    }\n    if (result.length() == 0 && copyStart == 0)\n      return string;\n    result.append(string.toString().substring(copyStart));\n    return result.toString();\n  }
243	public float hyperbolicTf(float freq) {\n    if (0.0f == freq) return 0.0f;\n\n    final float min = tf_hyper_min;\n    final float max = tf_hyper_max;\n    final double base = tf_hyper_base;\n    final float xoffset = tf_hyper_xoffset;\n    final double x = (double)(freq - xoffset);\n  \n    final float result = min +\n      (float)(\n              (max-min) / 2.0f\n              *\n              (\n               ( ( Math.pow(base,x) - Math.pow(base,-x) )\n                 / ( Math.pow(base,x) + Math.pow(base,-x) )\n                 )\n               + 1.0d\n               )\n              );\n\n    return Float.isNaN(result) ? max : result;\n    \n  }
244	public synchronized long flush(int atLeastMarkerCount) throws IOException {\n    assert isPrimary;\n    try (Connection c = new Connection(tcpPort)) {\n      c.out.writeByte(SimplePrimaryNode.CMD_FLUSH);\n      c.out.writeVInt(atLeastMarkerCount);\n      c.flush();\n      c.s.shutdownOutput();\n      return c.in.readLong();\n    }\n  }
245	private boolean applyAllDeletes(DocumentsWriterDeleteQueue deleteQueue) throws IOException {\n    if (flushControl.getAndResetApplyAllDeletes()) {\n      if (deleteQueue != null) {\n        ticketQueue.addDeletes(deleteQueue);\n      }\n      putEvent(ApplyDeletesEvent.INSTANCE);       return true;\n    }\n    return false;\n  }
246	public int stemPrefix(char s[], int len) {\n    for (int i = 0; i < prefixes.length; i++) \n      if (startsWithCheckLength(s, len, prefixes[i]))\n        return deleteN(s, 0, len, prefixes[i].length);\n    return len;\n  }
247	public Explanation customExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpls[]) throws IOException {\n    if (valSrcExpls.length == 1) {\n      return customExplain(doc, subQueryExpl, valSrcExpls[0]);\n    }\n    if (valSrcExpls.length == 0) {\n      return subQueryExpl;\n    }\n    float valSrcScore = 1;\n    for (Explanation valSrcExpl : valSrcExpls) {\n      valSrcScore *= valSrcExpl.getValue();\n    }\n    \n    List<Explanation> subs = new ArrayList<>();\n    subs.add(subQueryExpl);\n    for (Explanation valSrcExpl : valSrcExpls) {\n      subs.add(valSrcExpl);\n    }\n    return Explanation.match(valSrcScore * subQueryExpl.getValue(), "custom score: product of:", subs);\n  }
248	public long deleteDocuments(Term... terms) throws IOException {\n    ensureOpen();\n    try {\n      long seqNo = docWriter.deleteTerms(terms);\n      if (seqNo < 0) {\n        seqNo = -seqNo;\n        processEvents(true, false);\n      }\n      return seqNo;\n    } catch (VirtualMachineError tragedy) {\n      tragicEvent(tragedy, "deleteDocuments(Term..)");\n\n            return -1;\n    }\n  }
249	Query makeIntersects(Rectangle bbox) {\n\n        \n        \n        Query qHasEnv;\n    if (ctx.isGeo()) {\n      Query qIsNonXDL = this.makeXDL(false);\n      Query qIsXDL = ctx.isGeo() ? this.makeXDL(true) : null;\n      qHasEnv = this.makeQuery(BooleanClause.Occur.SHOULD, qIsNonXDL, qIsXDL);\n    } else {\n      qHasEnv = this.makeXDL(false);\n    }\n\n    BooleanQuery.Builder qNotDisjoint = new BooleanQuery.Builder();\n    qNotDisjoint.add(qHasEnv, BooleanClause.Occur.MUST);\n    Query qDisjoint = makeDisjoint(bbox);\n    qNotDisjoint.add(qDisjoint, BooleanClause.Occur.MUST_NOT);\n\n                    return qNotDisjoint.build();\n  }
250	private char normalizeIterationMark(char c) throws IOException {\n\n        if (bufferPosition < iterationMarkSpanEndPosition) {\n      return normalize(sourceCharacter(bufferPosition, iterationMarksSpanSize), c);\n    }\n\n        if (bufferPosition == iterationMarkSpanEndPosition) {\n                  iterationMarkSpanEndPosition++;\n      return c;\n    }\n\n        iterationMarksSpanSize = nextIterationMarkSpanSize();\n    iterationMarkSpanEndPosition = bufferPosition + iterationMarksSpanSize;\n    return normalize(sourceCharacter(bufferPosition, iterationMarksSpanSize), c);\n  }
251	public double normalDistance(final double x, final double y, final double z, final Membership... bounds) {\n\n    final double dist = evaluate(x,y,z);\n    final double perpX = x - dist * this.x;\n    final double perpY = y - dist * this.y;\n    final double perpZ = z - dist * this.z;\n\n    if (!meetsAllBounds(perpX, perpY, perpZ, bounds)) {\n      return Double.POSITIVE_INFINITY;\n    }\n    \n    return Math.abs(dist);\n  }
252	private FacetResult drillDown() throws IOException {\n    DirectoryReader indexReader = DirectoryReader.open(indexDir);\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    SortedSetDocValuesReaderState state = new DefaultSortedSetDocValuesReaderState(indexReader);\n\n        DrillDownQuery q = new DrillDownQuery(config);\n    q.add("Publish Year", "2010");\n    FacetsCollector fc = new FacetsCollector();\n    FacetsCollector.search(searcher, q, 10, fc);\n\n        Facets facets = new SortedSetDocValuesFacetCounts(state, fc);\n    FacetResult result = facets.getTopChildren(10, "Author");\n    indexReader.close();\n    \n    return result;\n  }
253	public static CharArrayMap<String> getStemDict(Reader reader, CharArrayMap<String> result) throws IOException {\n    BufferedReader br = null;\n    try {\n      br = getBufferedReader(reader);\n      String line;\n      while ((line = br.readLine()) != null) {\n        String[] wordstem = line.split("\t", 2);\n        result.put(wordstem[0], wordstem[1]);\n      }\n    } finally {\n      IOUtils.close(br);\n    }\n    return result;\n  }
254	protected <T> T doAction(HttpResponse response, boolean consume, Callable<T> call) throws IOException {\n    Throwable th = null;\n    try {\n      return call.call();\n    } catch (Throwable t) {\n      th = t;\n    } finally {\n      try {\n        verifyStatus(response);\n      } finally {\n        if (consume) {\n          EntityUtils.consumeQuietly(response.getEntity());\n        }\n      }\n    }\n    throw IOUtils.rethrowAlways(th); \n  }
255	protected final void rewindPrefix() throws IOException {\n    if (upto == 0) {\n            upto = 1;\n      fst.readFirstTargetArc(getArc(0), getArc(1), fstReader);\n      return;\n    }\n    \n    final int currentLimit = upto;\n    upto = 1;\n    while (upto < currentLimit && upto <= targetLength+1) {\n      final int cmp = getCurrentLabel() - getTargetLabel();\n      if (cmp < 0) {\n                        break;\n      } else if (cmp > 0) {\n                final FST.Arc<T> arc = getArc(upto);\n        fst.readFirstTargetArc(getArc(upto-1), arc, fstReader);\n                break;\n      }\n      upto++;\n    }\n      }
256	public int newRound() {\n    roundNumber++;\n\n    StringBuilder sb = new StringBuilder("--> Round ").append(roundNumber - 1).append("-->").append(roundNumber);\n\n        if (valByRound.size() > 0) {\n      sb.append(": ");\n      for (final String name : valByRound.keySet()) {\n        Object a = valByRound.get(name);\n        if (a instanceof int[]) {\n          int ai[] = (int[]) a;\n          int n1 = (roundNumber - 1) % ai.length;\n          int n2 = roundNumber % ai.length;\n          sb.append("  ").append(name).append(":").append(ai[n1]).append("-->").append(ai[n2]);\n        } else if (a instanceof double[]) {\n          double ad[] = (double[]) a;\n          int n1 = (roundNumber - 1) % ad.length;\n          int n2 = roundNumber % ad.length;\n          sb.append("  ").append(name).append(":").append(ad[n1]).append("-->").append(ad[n2]);\n        } else if (a instanceof String[]) {\n          String ad[] = (String[]) a;\n          int n1 = (roundNumber - 1) % ad.length;\n          int n2 = roundNumber % ad.length;\n          sb.append("  ").append(name).append(":").append(ad[n1]).append("-->").append(ad[n2]);\n        } else {\n          boolean ab[] = (boolean[]) a;\n          int n1 = (roundNumber - 1) % ab.length;\n          int n2 = roundNumber % ab.length;\n          sb.append("  ").append(name).append(":").append(ab[n1]).append("-->").append(ab[n2]);\n        }\n      }\n    }\n\n    System.out.println();\n    System.out.println(sb.toString());\n    System.out.println();\n\n    return roundNumber;\n  }
257	public static Query newBoxQuery(String field, double minLatitude, double maxLatitude, double minLongitude, double maxLongitude) {\n            if (minLatitude == 90.0) {\n            return new MatchNoDocsQuery("LatLonPoint.newBoxQuery with minLatitude=90.0");\n    }\n    if (minLongitude == 180.0) {\n      if (maxLongitude == 180.0) {\n                return new MatchNoDocsQuery("LatLonPoint.newBoxQuery with minLongitude=maxLongitude=180.0");\n      } else if (maxLongitude < minLongitude) {\n                minLongitude = -180.0;\n      }\n    }\n    byte[] lower = encodeCeil(minLatitude, minLongitude);\n    byte[] upper = encode(maxLatitude, maxLongitude);\n        if (maxLongitude < minLongitude) {\n            BooleanQuery.Builder q = new BooleanQuery.Builder();\n\n            byte[] leftOpen = lower.clone();\n            NumericUtils.intToSortableBytes(Integer.MIN_VALUE, leftOpen, Integer.BYTES);\n      Query left = newBoxInternal(field, leftOpen, upper);\n      q.add(new BooleanClause(left, BooleanClause.Occur.SHOULD));\n\n      byte[] rightOpen = upper.clone();\n            NumericUtils.intToSortableBytes(Integer.MAX_VALUE, rightOpen, Integer.BYTES);\n      Query right = newBoxInternal(field, lower, rightOpen);\n      q.add(new BooleanClause(right, BooleanClause.Occur.SHOULD));\n      return new ConstantScoreQuery(q.build());\n    } else {\n      return newBoxInternal(field, lower, upper);\n    }\n  }
258	boolean requiresEviction() {\n    assert lock.isHeldByCurrentThread();\n    final int size = mostRecentlyUsedQueries.size();\n    if (size == 0) {\n      return false;\n    } else {\n      return size > maxSize || ramBytesUsed() > maxRamBytesUsed;\n    }\n  }
259	private synchronized long flushBuffer() throws IOException {\n    long pos = channel.position();\n    int len = (int) buffer.getFilePointer();\n    byte[] bytes = new byte[len];\n    buffer.writeTo(bytes, 0);\n    buffer.reset();\n\n    intBuffer[0] = (byte) (len >> 24);\n    intBuffer[1] = (byte) (len >> 16);\n    intBuffer[2] = (byte) (len >> 8);\n    intBuffer[3] = (byte) len;\n    intByteBuffer.limit(4);\n    intByteBuffer.position(0);\n\n    writeBytesToChannel(intByteBuffer);\n    writeBytesToChannel(ByteBuffer.wrap(bytes));\n\n    return pos;\n  }
260	private void strip( StringBuilder buffer )\n    {\n      boolean doMore = true;\n      while ( doMore && buffer.length() > 3 ) {\n        if ( ( buffer.length() + substCount > 5 ) &&\n          buffer.substring( buffer.length() - 2, buffer.length() ).equals( "nd" ) )\n        {\n          buffer.delete( buffer.length() - 2, buffer.length() );\n        }\n        else if ( ( buffer.length() + substCount > 4 ) &&\n          buffer.substring( buffer.length() - 2, buffer.length() ).equals( "em" ) ) {\n            buffer.delete( buffer.length() - 2, buffer.length() );\n        }\n        else if ( ( buffer.length() + substCount > 4 ) &&\n          buffer.substring( buffer.length() - 2, buffer.length() ).equals( "er" ) ) {\n            buffer.delete( buffer.length() - 2, buffer.length() );\n        }\n        else if ( buffer.charAt( buffer.length() - 1 ) == 'e' ) {\n          buffer.deleteCharAt( buffer.length() - 1 );\n        }\n        else if ( buffer.charAt( buffer.length() - 1 ) == 's' ) {\n          buffer.deleteCharAt( buffer.length() - 1 );\n        }\n        else if ( buffer.charAt( buffer.length() - 1 ) == 'n' ) {\n          buffer.deleteCharAt( buffer.length() - 1 );\n        }\n                else if ( buffer.charAt( buffer.length() - 1 ) == 't' ) {\n          buffer.deleteCharAt( buffer.length() - 1 );\n        }\n        else {\n          doMore = false;\n        }\n      }\n    }
261	public void clearCoreCacheKey(Object coreKey) {\n    lock.lock();\n    try {\n      final LeafCache leafCache = cache.remove(coreKey);\n      if (leafCache != null) {\n        ramBytesUsed -= HASHTABLE_RAM_BYTES_PER_ENTRY;\n        final int numEntries = leafCache.cache.size();\n        if (numEntries > 0) {\n          onDocIdSetEviction(coreKey, numEntries, leafCache.ramBytesUsed);\n        } else {\n          assert numEntries == 0;\n          assert leafCache.ramBytesUsed == 0;\n        }\n      }\n    } finally {\n      lock.unlock();\n    }\n  }
262	public Weight createWeight(Query query, boolean needsScores, float boost) throws IOException {\n    final QueryCache queryCache = this.queryCache;\n    Weight weight = query.createWeight(this, needsScores, boost);\n    if (needsScores == false && queryCache != null) {\n      weight = queryCache.doCache(weight, queryCachingPolicy);\n    }\n    return weight;\n  }
263	synchronized void removeMergeThread() {\n    Thread currentThread = Thread.currentThread();\n        for(int i=0;i<mergeThreads.size();i++) {\n      if (mergeThreads.get(i) == currentThread) {\n        mergeThreads.remove(i);\n        return;\n      }\n    }\n      \n    assert false: "merge thread " + currentThread + " was not found";\n  }
264	private void popCurrentDoc() {\n    assert numSubsOnDoc == 0;\n    assert docIDQueue.size() > 0;\n    subsOnDoc[numSubsOnDoc++] = docIDQueue.pop();\n    docID = subsOnDoc[0].posEnum.docID();\n    while (docIDQueue.size() > 0 && docIDQueue.top().posEnum.docID() == docID) {\n      subsOnDoc[numSubsOnDoc++] = docIDQueue.pop();\n    }\n  }
265	private void substitute( StringBuilder buffer )\n    {\n      substCount = 0;\n      for ( int c = 0; c < buffer.length(); c++ ) {\n                if ( c > 0 && buffer.charAt( c ) == buffer.charAt ( c - 1 )  ) {\n          buffer.setCharAt( c, '*' );\n        }\n                else if ( buffer.charAt( c ) == 'ä' ) {\n          buffer.setCharAt( c, 'a' );\n        }\n        else if ( buffer.charAt( c ) == 'ö' ) {\n          buffer.setCharAt( c, 'o' );\n        }\n        else if ( buffer.charAt( c ) == 'ü' ) {\n          buffer.setCharAt( c, 'u' );\n        }\n                else if ( buffer.charAt( c ) == 'ß' ) {\n            buffer.setCharAt( c, 's' );\n            buffer.insert( c + 1, 's' );\n            substCount++;\n        }\n                if ( c < buffer.length() - 1 ) {\n                    if ( ( c < buffer.length() - 2 ) && buffer.charAt( c ) == 's' &&\n            buffer.charAt( c + 1 ) == 'c' && buffer.charAt( c + 2 ) == 'h' )\n          {\n            buffer.setCharAt( c, '$' );\n            buffer.delete( c + 1, c + 3 );\n            substCount += 2;\n          }\n          else if ( buffer.charAt( c ) == 'c' && buffer.charAt( c + 1 ) == 'h' ) {\n            buffer.setCharAt( c, '§' );\n            buffer.deleteCharAt( c + 1 );\n            substCount++;\n          }\n          else if ( buffer.charAt( c ) == 'e' && buffer.charAt( c + 1 ) == 'i' ) {\n            buffer.setCharAt( c, '%' );\n            buffer.deleteCharAt( c + 1 );\n            substCount++;\n          }\n          else if ( buffer.charAt( c ) == 'i' && buffer.charAt( c + 1 ) == 'e' ) {\n            buffer.setCharAt( c, '&' );\n            buffer.deleteCharAt( c + 1 );\n            substCount++;\n          }\n          else if ( buffer.charAt( c ) == 'i' && buffer.charAt( c + 1 ) == 'g' ) {\n            buffer.setCharAt( c, '#' );\n            buffer.deleteCharAt( c + 1 );\n            substCount++;\n          }\n          else if ( buffer.charAt( c ) == 's' && buffer.charAt( c + 1 ) == 't' ) {\n            buffer.setCharAt( c, '!' );\n            buffer.deleteCharAt( c + 1 );\n            substCount++;\n          }\n        }\n      }\n    }
266	public static ParsePathType pathType(Path f) {\n    int pathLength = 0;\n    while (f != null && f.getFileName() != null && ++pathLength < MAX_PATH_LENGTH) {\n      ParsePathType ppt = pathName2Type.get(f.getFileName().toString().toUpperCase(Locale.ROOT));\n      if (ppt!=null) {\n        return ppt;\n      }\n      f = f.getParent();\n    }\n    return DEFAULT_PATH_TYPE;\n  }
267	public void build(InputIterator iterator, double ramBufferSizeMB) throws IOException {\n    if (iterator.hasPayloads()) {\n      throw new IllegalArgumentException("this suggester doesn't support payloads");\n    }\n    if (iterator.hasContexts()) {\n      throw new IllegalArgumentException("this suggester doesn't support contexts");\n    }\n\n    String prefix = getClass().getSimpleName();\n    Path tempIndexPath = Files.createTempDirectory(prefix + ".index.");\n\n    Directory dir = FSDirectory.open(tempIndexPath);\n\n    IndexWriterConfig iwc = new IndexWriterConfig(indexAnalyzer);\n    iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n    iwc.setRAMBufferSizeMB(ramBufferSizeMB);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n    ft.setOmitNorms(true);\n    ft.freeze();\n\n    Document doc = new Document();\n    Field field = new Field("body", "", ft);\n    doc.add(field);\n\n    totTokens = 0;\n    IndexReader reader = null;\n\n    boolean success = false;\n    count = 0;\n    try {\n      while (true) {\n        BytesRef surfaceForm = iterator.next();\n        if (surfaceForm == null) {\n          break;\n        }\n        field.setStringValue(surfaceForm.utf8ToString());\n        writer.addDocument(doc);\n        count++;\n      }\n      reader = DirectoryReader.open(writer);\n\n      Terms terms = MultiFields.getTerms(reader, "body");\n      if (terms == null) {\n        throw new IllegalArgumentException("need at least one suggestion");\n      }\n\n            TermsEnum termsEnum = terms.iterator();\n\n      Outputs<Long> outputs = PositiveIntOutputs.getSingleton();\n      Builder<Long> builder = new Builder<>(FST.INPUT_TYPE.BYTE1, outputs);\n\n      IntsRefBuilder scratchInts = new IntsRefBuilder();\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        int ngramCount = countGrams(term);\n        if (ngramCount > grams) {\n          throw new IllegalArgumentException("tokens must not contain separator byte; got token=" + term + " but gramCount=" + ngramCount + ", which is greater than expected max ngram size=" + grams);\n        }\n        if (ngramCount == 1) {\n          totTokens += termsEnum.totalTermFreq();\n        }\n\n        builder.add(Util.toIntsRef(term, scratchInts), encodeWeight(termsEnum.totalTermFreq()));\n      }\n\n      fst = builder.finish();\n      if (fst == null) {\n        throw new IllegalArgumentException("need at least one suggestion");\n      }\n      \n      "/x/tmp/out.dot"\n\n                        writer.rollback();\n      success = true;\n    } finally {\n      try {\n        if (success) {\n          IOUtils.close(reader, dir);\n        } else {\n          IOUtils.closeWhileHandlingException(reader, writer, dir);\n        }\n      } finally {\n        IOUtils.rm(tempIndexPath);\n      }\n    }\n  }
268	public int normalize(char s[], int len) {\n\n    for (int i = 0; i < len; i++) {\n      switch (s[i]) {\n      case FARSI_YEH:\n      case YEH_BARREE:\n        s[i] = YEH;\n        break;\n      case KEHEH:\n        s[i] = KAF;\n        break;\n      case HEH_YEH:\n      case HEH_GOAL:\n        s[i] = HEH;\n        break;\n      case HAMZA_ABOVE:         len = delete(s, i, len);\n        i--;\n        break;\n      default:\n        break;\n      }\n    }\n\n    return len;\n  }
269	public static Query newSlowBoxQuery(String field, double minLatitude, double maxLatitude, double minLongitude, double maxLongitude) {\n            if (minLatitude == 90.0) {\n            return new MatchNoDocsQuery("LatLonDocValuesField.newBoxQuery with minLatitude=90.0");\n    }\n    if (minLongitude == 180.0) {\n      if (maxLongitude == 180.0) {\n                return new MatchNoDocsQuery("LatLonDocValuesField.newBoxQuery with minLongitude=maxLongitude=180.0");\n      } else if (maxLongitude < minLongitude) {\n                minLongitude = -180.0;\n      }\n    }\n    return new LatLonDocValuesBoxQuery(field, minLatitude, maxLatitude, minLongitude, maxLongitude);\n  }
270	public static Query newPrefixQuery(String field, InetAddress value, int prefixLength) {\n    if (value == null) {\n      throw new IllegalArgumentException("InetAddress must not be null");\n    }\n    if (prefixLength < 0 || prefixLength > 8 * value.getAddress().length) {\n      throw new IllegalArgumentException("illegal prefixLength '" + prefixLength + "'. Must be 0-32 for IPv4 ranges, 0-128 for IPv6 ranges");\n    }\n        byte lower[] = value.getAddress();\n    byte upper[] = value.getAddress();\n    for (int i = prefixLength; i < 8 * lower.length; i++) {\n      int m = 1 << (7 - (i & 7));\n      lower[i >> 3] &= ~m;\n      upper[i >> 3] |= m;\n    }\n    try {\n      return newRangeQuery(field, InetAddress.getByAddress(lower), InetAddress.getByAddress(upper));\n    } catch (UnknownHostException e) {\n      throw new AssertionError(e);     }\n  }
271	private static GeoPoint pickPole(final Random generator, final PlanetModel planetModel, final List<GeoPoint> points) {\n    final int pointIndex = generator.nextInt(points.size());\n    final GeoPoint closePoint = points.get(pointIndex);\n        final double angle = generator.nextDouble() * Math.PI * 2.0 - Math.PI;\n    double maxArcDistance = points.get(0).arcDistance(points.get(1));\n    double trialArcDistance = points.get(0).arcDistance(points.get(2));\n    if (trialArcDistance > maxArcDistance) {\n      maxArcDistance = trialArcDistance;\n    }\n    final double arcDistance = maxArcDistance - generator.nextDouble() * maxArcDistance;\n        final double x = Math.cos(arcDistance);\n    final double sinArcDistance = Math.sin(arcDistance);\n    final double y = Math.cos(angle) * sinArcDistance;\n    final double z = Math.sin(angle) * sinArcDistance;\n        final double sinLatitude = Math.sin(closePoint.getLatitude());\n    final double cosLatitude = Math.cos(closePoint.getLatitude());\n    final double sinLongitude = Math.sin(closePoint.getLongitude());\n    final double cosLongitude = Math.cos(closePoint.getLongitude());\n                                                                                    final double x1 = x * cosLatitude - z * sinLatitude;\n    final double y1 = y;\n    final double z1 = x * sinLatitude + z * cosLatitude;\n    final double x2 = x1 * cosLongitude - y1 * sinLongitude;\n    final double y2 = x1 * sinLongitude + y1 * cosLongitude;\n    final double z2 = z1;\n        return planetModel.createSurfacePoint(x2, y2, z2);\n  }
272	protected GeoPoint[] findCrossings(final PlanetModel planetModel, final Plane q, final Membership[] bounds, final Membership[] moreBounds) {\n                final double lineVectorX = y * q.z - z * q.y;\n    final double lineVectorY = z * q.x - x * q.z;\n    final double lineVectorZ = x * q.y - y * q.x;\n    if (Math.abs(lineVectorX) < MINIMUM_RESOLUTION && Math.abs(lineVectorY) < MINIMUM_RESOLUTION && Math.abs(lineVectorZ) < MINIMUM_RESOLUTION) {\n            return NO_POINTS;\n    }\n\n                                                                                double x0;\n    double y0;\n    double z0;\n        final double denomYZ = this.y * q.z - this.z * q.y;\n    final double denomXZ = this.x * q.z - this.z * q.x;\n    final double denomXY = this.x * q.y - this.y * q.x;\n    if (Math.abs(denomYZ) >= Math.abs(denomXZ) && Math.abs(denomYZ) >= Math.abs(denomXY)) {\n            if (Math.abs(denomYZ) < MINIMUM_RESOLUTION_SQUARED) {\n        return NO_POINTS;\n      }\n      final double denom = 1.0 / denomYZ;\n      x0 = 0.0;\n      y0 = (-this.D * q.z - this.z * -q.D) * denom;\n      z0 = (this.y * -q.D + this.D * q.y) * denom;\n    } else if (Math.abs(denomXZ) >= Math.abs(denomXY) && Math.abs(denomXZ) >= Math.abs(denomYZ)) {\n            if (Math.abs(denomXZ) < MINIMUM_RESOLUTION_SQUARED) {\n        return NO_POINTS;\n      }\n      final double denom = 1.0 / denomXZ;\n      x0 = (-this.D * q.z - this.z * -q.D) * denom;\n      y0 = 0.0;\n      z0 = (this.x * -q.D + this.D * q.x) * denom;\n    } else {\n            if (Math.abs(denomXY) < MINIMUM_RESOLUTION_SQUARED) {\n        return NO_POINTS;\n      }\n      final double denom = 1.0 / denomXY;\n      x0 = (-this.D * q.y - this.y * -q.D) * denom;\n      y0 = (this.x * -q.D + this.D * q.x) * denom;\n      z0 = 0.0;\n    }\n\n                                final double A = lineVectorX * lineVectorX * planetModel.inverseAbSquared +\n      lineVectorY * lineVectorY * planetModel.inverseAbSquared +\n      lineVectorZ * lineVectorZ * planetModel.inverseCSquared;\n    final double B = 2.0 * (lineVectorX * x0 * planetModel.inverseAbSquared + lineVectorY * y0 * planetModel.inverseAbSquared + lineVectorZ * z0 * planetModel.inverseCSquared);\n    final double C = x0 * x0 * planetModel.inverseAbSquared + y0 * y0 * planetModel.inverseAbSquared + z0 * z0 * planetModel.inverseCSquared - 1.0;\n\n    final double BsquaredMinus = B * B - 4.0 * A * C;\n    if (Math.abs(BsquaredMinus) < MINIMUM_RESOLUTION_SQUARED) {\n            return NO_POINTS;\n    } else if (BsquaredMinus > 0.0) {\n      final double inverse2A = 1.0 / (2.0 * A);\n            final double sqrtTerm = Math.sqrt(BsquaredMinus);\n      final double t1 = (-B + sqrtTerm) * inverse2A;\n      final double t2 = (-B - sqrtTerm) * inverse2A;\n            final double point1X = lineVectorX * t1 + x0;\n      final double point1Y = lineVectorY * t1 + y0;\n      final double point1Z = lineVectorZ * t1 + z0;\n      final double point2X = lineVectorX * t2 + x0;\n      final double point2Y = lineVectorY * t2 + y0;\n      final double point2Z = lineVectorZ * t2 + z0;\n      boolean point1Valid = true;\n      boolean point2Valid = true;\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(point1X, point1Y, point1Z)) {\n          point1Valid = false;\n          break;\n        }\n      }\n      if (point1Valid) {\n        for (final Membership bound : moreBounds) {\n          if (!bound.isWithin(point1X, point1Y, point1Z)) {\n            point1Valid = false;\n            break;\n          }\n        }\n      }\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(point2X, point2Y, point2Z)) {\n          point2Valid = false;\n          break;\n        }\n      }\n      if (point2Valid) {\n        for (final Membership bound : moreBounds) {\n          if (!bound.isWithin(point2X, point2Y, point2Z)) {\n            point2Valid = false;\n            break;\n          }\n        }\n      }\n\n      if (point1Valid && point2Valid) {\n        return new GeoPoint[]{new GeoPoint(point1X, point1Y, point1Z), new GeoPoint(point2X, point2Y, point2Z)};\n      }\n      if (point1Valid) {\n        return new GeoPoint[]{new GeoPoint(point1X, point1Y, point1Z)};\n      }\n      if (point2Valid) {\n        return new GeoPoint[]{new GeoPoint(point2X, point2Y, point2Z)};\n      }\n      return NO_POINTS;\n    } else {\n            return NO_POINTS;\n    }\n  }
273	protected Report reportAll(List<TaskStats> taskStats) {\n    String longestOp = longestOp(taskStats);\n    boolean first = true;\n    StringBuilder sb = new StringBuilder();\n    sb.append(tableTitle(longestOp));\n    sb.append(newline);\n    int reported = 0;\n    for (final TaskStats stat : taskStats) {\n      if (stat.getElapsed()>=0) {         if (!first) {\n          sb.append(newline);\n        }\n        first = false;\n        String line = taskReportLine(longestOp, stat);\n        reported++;\n        if (taskStats.size()>2 && reported%2==0) {\n          line = line.replaceAll("   "," - ");\n        }\n        sb.append(line);\n      }\n    }\n    String reptxt = (reported==0 ? "No Matching Entries Were Found!" : sb.toString());\n    return new Report(reptxt,reported,reported,taskStats.size());\n  }
274	public static void transformCriteria(Properties formProperties, InputStream xslIs, Result result)\n      throws SAXException, IOException, ParserConfigurationException, TransformerException {\n    dbf.setNamespaceAware(true);\n    DocumentBuilder builder = dbf.newDocumentBuilder();\n    org.w3c.dom.Document xslDoc = builder.parse(xslIs);\n    DOMSource ds = new DOMSource(xslDoc);\n\n    Transformer transformer = null;\n    synchronized (tFactory) {\n      transformer = tFactory.newTransformer(ds);\n    }\n    transformCriteria(formProperties, transformer, result);\n  }
275	public Trie optimize(Trie orig) {\n    List<CharSequence> cmds = orig.cmds;\n    List<Row> rows = new ArrayList<>();\n    List<Row> orows = orig.rows;\n    int remap[] = new int[orows.size()];\n    \n    Arrays.fill(remap, -1);\n    rows = removeGaps(orig.root, rows, new ArrayList<Row>(), remap);\n    \n    return new Trie(orig.forward, remap[orig.root], cmds, rows);\n  }
276	public int normalize(char text[], int len) {\n    for (int i = 0; i < len; i++) {\n      final Character.UnicodeBlock block = Character.UnicodeBlock.of(text[i]);\n      final ScriptData sd = scripts.get(block);\n      if (sd != null) {\n        final int ch = text[i] - sd.base;\n        if (sd.decompMask.get(ch))\n          len = compose(ch, block, sd, text, i, len);\n      }\n    }\n    return len;\n  }
277	public void copy(Automaton other) {\n\n        int stateOffset = getNumStates();\n    states = ArrayUtil.grow(states, nextState + other.nextState);\n    System.arraycopy(other.states, 0, states, nextState, other.nextState);\n    for(int i=0;i<other.nextState;i += 2) {\n      if (states[nextState+i] != -1) {\n        states[nextState+i] += nextTransition;\n      }\n    }\n    nextState += other.nextState;\n    int otherNumStates = other.getNumStates();\n    BitSet otherAcceptStates = other.getAcceptStates();\n    int state = 0;\n    while (state < otherNumStates && (state = otherAcceptStates.nextSetBit(state)) != -1) {\n      setAccept(stateOffset + state, true);\n      state++;\n    }\n\n        transitions = ArrayUtil.grow(transitions, nextTransition + other.nextTransition);\n    System.arraycopy(other.transitions, 0, transitions, nextTransition, other.nextTransition);\n    for(int i=0;i<other.nextTransition;i += 3) {\n      transitions[nextTransition+i] += stateOffset;\n    }\n    nextTransition += other.nextTransition;\n\n    if (other.deterministic == false) {\n      deterministic = false;\n    }\n  }
278	private int removeArticle(final char s[], final int len) {\n    if (len > 6 && endsWith(s, len, "ият"))\n      return len - 3;\n    \n    if (len > 5) {\n      if (endsWith(s, len, "ът") ||\n          endsWith(s, len, "то") ||\n          endsWith(s, len, "те") ||\n          endsWith(s, len, "та") ||\n          endsWith(s, len, "ия"))\n        return len - 2;\n    }\n    \n    if (len > 4 && endsWith(s, len, "ят"))\n      return len - 2;\n\n    return len;\n  }
279	public void forceMergeDeletes(boolean doWait)\n    throws IOException {\n    ensureOpen();\n\n    flush(true, true);\n\n    if (infoStream.isEnabled("IW")) {\n      infoStream.message("IW", "forceMergeDeletes: index now " + segString());\n    }\n\n    final MergePolicy mergePolicy = config.getMergePolicy();\n    MergePolicy.MergeSpecification spec;\n    boolean newMergesFound = false;\n    synchronized(this) {\n      spec = mergePolicy.findForcedDeletesMerges(segmentInfos, this);\n      newMergesFound = spec != null;\n      if (newMergesFound) {\n        final int numMerges = spec.merges.size();\n        for(int i=0;i<numMerges;i++)\n          registerMerge(spec.merges.get(i));\n      }\n    }\n\n    mergeScheduler.merge(this, MergeTrigger.EXPLICIT, newMergesFound);\n\n    if (spec != null && doWait) {\n      final int numMerges = spec.merges.size();\n      synchronized(this) {\n        boolean running = true;\n        while(running) {\n\n          if (tragedy != null) {\n            throw new IllegalStateException("this writer hit an unrecoverable error; cannot complete forceMergeDeletes", tragedy);\n          }\n\n                                        running = false;\n          for(int i=0;i<numMerges;i++) {\n            final MergePolicy.OneMerge merge = spec.merges.get(i);\n            if (pendingMerges.contains(merge) || runningMerges.contains(merge)) {\n              running = true;\n            }\n            Throwable t = merge.getException();\n            if (t != null) {\n              throw new IOException("background merge hit exception: " + merge.segString(), t);\n            }\n          }\n\n                    if (running)\n            doWait();\n        }\n      }\n    }\n\n              }
280	public NRShape toRangeShape(UnitNRShape startUnit, UnitNRShape endUnit) {\n            startUnit = startUnit.getShapeAtLevel(truncateStartVals(startUnit, 0));     endUnit = endUnit.getShapeAtLevel(truncateEndVals(endUnit, 0));         int cmp = comparePrefix(startUnit, endUnit);\n    if (cmp > 0) {\n      throw new IllegalArgumentException("Wrong order: "+ startUnit +" TO "+ endUnit);\n    }\n    if (cmp == 0) {      if (startUnit.getLevel() == endUnit.getLevel()) {\n                return startUnit;\n      } else if (endUnit.getLevel() > startUnit.getLevel()) {\n                if (truncateStartVals(endUnit, startUnit.getLevel()) == startUnit.getLevel()) {\n          return endUnit;\n        }\n      } else {                if (truncateEndVals(startUnit, endUnit.getLevel()) == endUnit.getLevel()) {\n          return startUnit;\n        }\n      }\n    }\n    return new SpanUnitsNRShape(startUnit, endUnit);\n  }
281	private DisiWrapper insertTailWithOverFlow(DisiWrapper s) {\n    if (tailSize < tail.length) {\n      addTail(s);\n      return null;\n    } else if (tail.length >= 1) {\n      final DisiWrapper top = tail[0];\n      if (top.cost < s.cost) {\n        tail[0] = s;\n        downHeapCost(tail, tailSize);\n        return top;\n      }\n    }\n    return s;\n  }
282	public int putAll(K key, Collection<? extends V> vals) {\n    final Set<V> theSet;\n    if (theMap.containsKey(key)) {\n      theSet = theMap.get(key);\n    } else {\n      theSet = new HashSet<>(23);\n      theMap.put(key, theSet);\n    }\n    theSet.addAll(vals);\n    return theSet.size();\n  }
283	protected static Map<String,Step> parse(Class<? extends RSLPStemmerBase> clazz, String resource) {\n        try {\n      InputStream is = clazz.getResourceAsStream(resource);\n      LineNumberReader r = new LineNumberReader(new InputStreamReader(is, StandardCharsets.UTF_8));\n      Map<String,Step> steps = new HashMap<>();\n      String step;\n      while ((step = readLine(r)) != null) {\n        Step s = parseStep(r, step);\n        steps.put(s.name, s);\n      }\n      r.close();\n      return steps;\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }
284	private int recursiveNodeCalculator(TSTNode currentNode, boolean checkData,\n          int numNodes2) {\n    if (currentNode == null) {\n      return numNodes2;\n    }\n    int numNodes = recursiveNodeCalculator(\n            currentNode.relatives[TSTNode.LOKID], checkData, numNodes2);\n    numNodes = recursiveNodeCalculator(currentNode.relatives[TSTNode.EQKID],\n            checkData, numNodes);\n    numNodes = recursiveNodeCalculator(currentNode.relatives[TSTNode.HIKID],\n            checkData, numNodes);\n    if (checkData) {\n      if (currentNode.data != null) {\n        numNodes++;\n      }\n    } else {\n      numNodes++;\n    }\n    return numNodes;\n  }
285	public String buildExtensionField(String extensionKey, String field) {\n    StringBuilder builder = new StringBuilder(field);\n    builder.append(this.extensionFieldDelimiter);\n    builder.append(extensionKey);\n    return escapeExtensionField(builder.toString());\n  }
286	private boolean endsWith(char s[], int len, String suffix) {\n    final int suffixLen = suffix.length();\n    if (suffixLen > len)\n      return false;\n    for (int i = suffixLen - 1; i >= 0; i--)\n      if (s[len -(suffixLen - i)] != suffix.charAt(i))\n        return false;\n    \n    return true;\n  }
287	@SuppressWarnings("fallthrough")\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n                            break;\n            } else {\n                            break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  ("Line #" + lineno(stok) + ": Unexpected opening parenthesis.");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  ("Line #" + lineno(stok) + ": Unexpected closing parenthesis.");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException("Line #" + lineno(stok) + ": Unexpected token '" + stok.sval + "'");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  ("Line #" + lineno(stok) + ": Missing ':' after '" + argName + "' param to " + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                                    argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst("");\n                                }\n              case '"':\n              case '\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException("Unexpected EOF: " + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    ("Line #" + lineno(stok) + ": Unexpected token: " + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey("luceneMatchVersion")) {\n        argMap.put("luceneMatchVersion", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException("Line #" + lineno(stok) + ": ", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        Path baseDir = Paths.get(getRunData().getConfig().get("work.dir", "work"));\n        if (!Files.isDirectory(baseDir)) {\n          baseDir = Paths.get(".");\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith("Line #")) {\n        throw (e);\n      } else {\n        throw new RuntimeException("Line #" + lineno(stok) + ": ", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException("Line #" + lineno(stok) + ": ", t);\n    }\n  }
288	private int[][] toIndexArray(Map<Integer, int[]> input) {\n    ArrayList<int[]> result = new ArrayList<>();\n    for (int i : input.keySet()) {\n      int[] wordIdAndLength = input.get(i);\n      int wordId = wordIdAndLength[0];\n            int current = i;\n      for (int j = 1; j < wordIdAndLength.length; j++) {         int[] token = { wordId + j - 1, current, wordIdAndLength[j] };\n        result.add(token);\n        current += wordIdAndLength[j];\n      }\n    }\n    return result.toArray(new int[result.size()][]);\n  }
289	Query makeEquals(Rectangle bbox) {\n\n        Query qMinX = makeNumberTermQuery(field_minX, bbox.getMinX());\n    Query qMinY = makeNumberTermQuery(field_minY, bbox.getMinY());\n    Query qMaxX = makeNumberTermQuery(field_maxX, bbox.getMaxX());\n    Query qMaxY = makeNumberTermQuery(field_maxY, bbox.getMaxY());\n    return makeQuery(BooleanClause.Occur.MUST, qMinX, qMinY, qMaxX, qMaxY);\n  }
290	public static QualityStats average(QualityStats[] stats) {\n    QualityStats avg = new QualityStats(0,0);\n    if (stats.length==0) {\n            return avg;\n    }\n    int m = 0;         for (int i=0; i<stats.length; i++) {\n      avg.searchTime += stats[i].searchTime;\n      avg.docNamesExtractTime += stats[i].docNamesExtractTime;\n      if (stats[i].maxGoodPoints>0) {\n        m++;\n        avg.numGoodPoints += stats[i].numGoodPoints;\n        avg.numPoints += stats[i].numPoints;\n        avg.pReleventSum += stats[i].getAvp();\n        avg.recall += stats[i].recall;\n        avg.mrr += stats[i].getMRR();\n        avg.maxGoodPoints += stats[i].maxGoodPoints;\n        for (int j=1; j<avg.pAt.length; j++) {\n          avg.pAt[j] += stats[i].getPrecisionAt(j);\n        }\n      }\n    }\n    assert m>0 : "Fishy: no \"good\" queries!";\n        avg.searchTime /= stats.length;\n    avg.docNamesExtractTime /= stats.length;\n    avg.numGoodPoints /= m;\n    avg.numPoints /= m;\n    avg.recall /= m;\n    avg.mrr /= m;\n    avg.maxGoodPoints /= m;\n    for (int j=1; j<avg.pAt.length; j++) {\n      avg.pAt[j] /= m;\n    }\n    avg.pReleventSum /= m;                     avg.pReleventSum *= avg.maxGoodPoints;     \n    return avg;\n  }
291	DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {\n    ensureOpen();\n\n    if (writeAllDeletes && applyAllDeletes == false) {\n      throw new IllegalArgumentException("applyAllDeletes must be true when writeAllDeletes=true");\n    }\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled("IW")) {\n      infoStream.message("IW", "flush at getReader");\n    }\n                poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    \n    boolean success2 = false;\n    try {\n      boolean success = false;\n      synchronized (fullFlushLock) {\n        try {\n                    long seqNo = docWriter.flushAllThreads();\n          if (seqNo < 0) {\n            anyChanges = true;\n            seqNo = -seqNo;\n          } else {\n            anyChanges = false;\n          }\n          if (anyChanges == false) {\n                                    flushCount.incrementAndGet();\n          }\n\n          processEvents(false, true);\n\n          if (applyAllDeletes) {\n            applyAllDeletesAndUpdates();\n          }\n\n          synchronized(this) {\n\n                        \n                                    readerPool.writeAllDocValuesUpdates();\n\n            if (writeAllDeletes) {\n                            readerPool.commit(segmentInfos);\n            }\n\n                                                \n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes, writeAllDeletes);\n            if (infoStream.isEnabled("IW")) {\n              infoStream.message("IW", "return reader version=" + r.getVersion() + " reader=" + r);\n            }\n          }\n          success = true;\n        } finally {\n                    docWriter.finishFullFlush(this, success);\n          if (success) {\n            processEvents(false, true);\n            doAfterFlush();\n          } else {\n            if (infoStream.isEnabled("IW")) {\n              infoStream.message("IW", "hit exception during NRT reader");\n            }\n          }\n        }\n      }\n      anyChanges |= maybeMerge.getAndSet(false);\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled("IW")) {\n        infoStream.message("IW", "getReader took " + (System.currentTimeMillis() - tStart) + " msec");\n      }\n      success2 = true;\n    } catch (AbortingException | VirtualMachineError tragedy) {\n      tragicEvent(tragedy, "getReader");\n            return null;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }
292	public Set<String> readSetOfStrings() throws IOException {\n    int count = readVInt();\n    if (count == 0) {\n      return Collections.emptySet();\n    } else if (count == 1) {\n      return Collections.singleton(readString());\n    } else {\n      Set<String> set = count > 10 ? new HashSet<>() : new TreeSet<>();\n      for (int i = 0; i < count; i++) {\n        set.add(readString());\n      }\n      return Collections.unmodifiableSet(set);\n    }\n  }
293	FieldDoc fillFields(final Entry entry) {\n    final int n = comparators.length;\n    final Object[] fields = new Object[n];\n    for (int i = 0; i < n; ++i) {\n      fields[i] = comparators[i].value(entry.slot);\n    }\n        return new FieldDoc(entry.doc, entry.score, fields);\n  }
294	public static void check(IndexReader reader, BitSetProducer parentsFilter) throws IOException {\n    for (LeafReaderContext context : reader.leaves()) {\n      if (context.reader().maxDoc() == 0) {\n        continue;\n      }\n      final BitSet parents = parentsFilter.getBitSet(context);\n      if (parents == null || parents.cardinality() == 0) {\n        throw new IllegalStateException("Every segment should have at least one parent, but " + context.reader() + " does not have any");\n      }\n      if (parents.get(context.reader().maxDoc() - 1) == false) {\n        throw new IllegalStateException("The last document of a segment must always be a parent, but " + context.reader() + " has a child as a last doc");\n      }\n      final Bits liveDocs = context.reader().getLiveDocs();\n      if (liveDocs != null) {\n        int prevParentDoc = -1;\n        DocIdSetIterator it = new BitSetIterator(parents, 0L);\n        for (int parentDoc = it.nextDoc(); parentDoc != DocIdSetIterator.NO_MORE_DOCS; parentDoc = it.nextDoc()) {\n          final boolean parentIsLive = liveDocs.get(parentDoc);\n          for (int child = prevParentDoc + 1; child != parentDoc; child++) {\n            final boolean childIsLive = liveDocs.get(child);\n            if (parentIsLive != childIsLive) {\n              if (childIsLive) {\n                throw new IllegalStateException("Parent doc " + parentDoc + " of segment " + context.reader() + " is live but has a deleted child document " + child);\n              } else {\n                throw new IllegalStateException("Parent doc " + parentDoc + " of segment " + context.reader() + " is deleted but has a live child document " + child);\n              }\n            }\n          }\n          prevParentDoc = parentDoc;\n        }\n      }\n    }\n  }
295	private static boolean isFinite(Transition scratch, Automaton a, int state, BitSet path, BitSet visited, int level) {\n    if (level > MAX_RECURSION_LEVEL) {\n      throw new IllegalArgumentException("input automaton is too large: " +  level);\n    }\n    path.set(state);\n    int numTransitions = a.initTransition(state, scratch);\n    for(int t=0;t<numTransitions;t++) {\n      a.getTransition(state, t, scratch);\n      if (path.get(scratch.dest) || (!visited.get(scratch.dest) && !isFinite(scratch, a, scratch.dest, path, visited, level+1))) {\n        return false;\n      }\n    }\n    path.clear(state);\n    visited.set(state);\n    return true;\n  }
296	public void addLonLine(double minLat, double maxLat, double lon) {\n    String name = "lonline" + nextShape;\n    nextShape++;\n\n    b.append("        var " + name + " = WE.polygon([\n");\n    double lat;\n    int steps = getStepCount(minLat, lon, maxLat, lon);\n    for(lat = minLat;lat<=maxLat;lat += (maxLat-minLat)/steps) {\n      b.append("          [" + lat + ", " + lon + "],\n");\n    }\n    b.append("          [" + maxLat + ", " + lon + "],\n");\n    lat -= (maxLat-minLat)/36;\n    for(;lat>=minLat;lat -= (maxLat-minLat)/steps) {\n      b.append("          [" + lat + ", " + lon + "],\n");\n    }\n    b.append("        ], {color: \"#ff0000\", fillColor: \"#ffffff\", opacity: 1, fillOpacity: 0.0001});\n");\n    b.append("        " + name + ".addTo(earth);\n");\n  }
297	protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n            numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: "lastFieldName=" + lastFieldName + " fieldName=" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n                continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n                numTerms = 0;\n        termsEnum = terms.iterator();\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator();\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }
298	public void copyBytes(DataInput input, long numBytes) throws IOException {\n    assert numBytes >= 0: "numBytes=" + numBytes;\n    long left = numBytes;\n    if (copyBuffer == null)\n      copyBuffer = new byte[COPY_BUFFER_SIZE];\n    while(left > 0) {\n      final int toCopy;\n      if (left > COPY_BUFFER_SIZE)\n        toCopy = COPY_BUFFER_SIZE;\n      else\n        toCopy = (int) left;\n      input.readBytes(copyBuffer, 0, toCopy);\n      writeBytes(copyBuffer, 0, toCopy);\n      left -= toCopy;\n    }\n  }
299	public int stem(final char s[], int len) {\n    if (len < 4)       return len;\n    \n    if (len > 5 && endsWith(s, len, "ища"))\n      return len - 3;\n    \n    len = removeArticle(s, len);\n    len = removePlural(s, len);\n    \n    if (len > 3) {\n      if (endsWith(s, len, "я"))\n        len--;\n      if (endsWith(s, len, "а") ||\n          endsWith(s, len, "о") ||\n          endsWith(s, len, "е"))\n        len--;\n    }\n    \n                if (len > 4 && endsWith(s, len, "ен")) {\n      s[len - 2] = 'н';       len--;\n    }\n    \n    if (len > 5 && s[len - 2] == 'ъ') {\n      s[len - 2] = s[len - 1];       len--;\n    }\n\n    return len;\n  }
300	private void unionTermGroups(ArrayList<FixedBitSet> bb) {\n    int incr;\n    for (int i=0; i<bb.size()-1; i+=incr) {\n      incr = 1;\n      int j = i+1;\n      while (j<bb.size()) {\n        if (bb.get(i).intersects(bb.get(j))) {\n          bb.get(i).or(bb.get(j));\n          bb.remove(j);\n          incr = 0;\n        } else {\n          ++j;\n        }\n      }\n    }\n  }
301	private HashMap<Term,Integer> termGroups(LinkedHashMap<Term,Integer> tord, ArrayList<FixedBitSet> bb) throws IOException {\n    HashMap<Term,Integer> tg = new HashMap<>();\n    Term[] t = tord.keySet().toArray(new Term[0]);\n    for (int i=0; i<bb.size(); i++) {       FixedBitSet bits = bb.get(i);\n      for (int ord = bits.nextSetBit(0); ord != DocIdSetIterator.NO_MORE_DOCS; ord = ord + 1 >= bits.length() ? DocIdSetIterator.NO_MORE_DOCS : bits.nextSetBit(ord + 1)) {\n        tg.put(t[ord],i);\n      }\n    }\n    return tg;\n  }
302	public int stem(char s[], int len) {\n        if (len > 5 && endsWith(s, len, "دا")) {\n      len -= 2;\n    } else if (len > 4 && endsWith(s, len, "نا")) {\n      len--;\n    } else if (len > 6 && endsWith(s, len, "ەوە")) {\n      len -= 3;\n    }\n    \n        if (len > 6 && (endsWith(s, len, "مان") || endsWith(s, len, "یان") || endsWith(s, len, "تان"))) {\n      len -= 3;\n    }\n    \n        if (len > 6 && endsWith(s, len, "ێکی")) {\n      return len-3;\n    } else if (len > 7 && endsWith(s, len, "یەکی")) {\n      return len-4;\n    }\n        if (len > 5 && endsWith(s, len, "ێک")) {\n      return len-2;\n    } else if (len > 6 && endsWith(s, len, "یەک")) {\n      return len-3;\n    }\n        else if (len > 6 && endsWith(s, len, "ەکە")) {\n      return len-3;\n    } else if (len > 5 && endsWith(s, len, "کە")) {\n      return len-2;\n    }\n        else if (len > 7 && endsWith(s, len, "ەکان")) {\n      return len-4;\n    } else if (len > 6 && endsWith(s, len, "کان")) {\n      return len-3;\n    }\n        else if (len > 7 && endsWith(s, len, "یانی")) {\n      return len-4;\n    } else if (len > 6 && endsWith(s, len, "انی")) {\n      return len-3;\n    }\n        else if (len > 6 && endsWith(s, len, "یان")) {\n      return len-3;\n    } else if (len > 5 && endsWith(s, len, "ان")) {\n      return len-2;\n    } \n        else if (len > 7 && endsWith(s, len, "یانە")) {\n      return len-4;\n    } else if (len > 6 && endsWith(s, len, "انە")) {\n      return len-3;\n    }\n        else if (len > 5 && (endsWith(s, len, "ایە") || endsWith(s, len, "ەیە"))) {\n      return len-2;\n    } else if (len > 4 && endsWith(s, len, "ە")) {\n      return len-1;\n    }\n        else if (len > 4 && endsWith(s, len, "ی")) {\n      return len-1;\n    }\n    return len;\n  }
303	public int[][] lookup(char[] chars, int off, int len) throws IOException {\n        TreeMap<Integer, int[]> result = new TreeMap<>();     boolean found = false; \n    final FST.BytesReader fstReader = fst.getBytesReader();\n\n    FST.Arc<Long> arc = new FST.Arc<>();\n    int end = off + len;\n    for (int startOffset = off; startOffset < end; startOffset++) {\n      arc = fst.getFirstArc(arc);\n      int output = 0;\n      int remaining = end - startOffset;\n      for (int i = 0; i < remaining; i++) {\n        int ch = chars[startOffset+i];\n        if (fst.findTargetArc(ch, arc, arc, i == 0, fstReader) == null) {\n          break;         }\n        output += arc.output.intValue();\n        if (arc.isFinal()) {\n          final int finalOutput = output + arc.nextFinalOutput.intValue();\n          result.put(startOffset-off, segmentations[finalOutput]);\n          found = true;\n        }\n      }\n    }\n    \n    return found ? toIndexArray(result) : EMPTY_RESULT;\n  }
304	public void addValue(BytesRef value) throws IOException {    \n      int hash = hashFunction.hash(value);\n      if (hash < 0) {\n        hash = hash * -1;\n      }\n            int bloomPos = hash & bloomSize;\n      filter.set(bloomPos);\n  }
305	public static PolygonPredicate createPolygonPredicate(Polygon[] polygons, Polygon2D tree) {\n    final Rectangle boundingBox = Rectangle.fromPolygon(polygons);\n    final Function<Rectangle, Relation> boxToRelation = box -> tree.relate(\n        box.minLat, box.maxLat, box.minLon, box.maxLon);\n    final Grid subBoxes = createSubBoxes(boundingBox, boxToRelation);\n\n    return new PolygonPredicate(\n        subBoxes.latShift, subBoxes.lonShift,\n        subBoxes.latBase, subBoxes.lonBase,\n        subBoxes.maxLatDelta, subBoxes.maxLonDelta,\n        subBoxes.relations,\n        tree);\n  }
306	private void refill() {\n            if (bufferLen > 64) {\n      int last = bufferLen - 1;\n      buffer[0] = buffer[last];\n      startOffset[0] = startOffset[last];\n      endOffset[0] = endOffset[last];\n      bufferLen = 1;\n      index -= last;\n    }\n\n    char termBuffer[] = termAtt.buffer();\n    int len = termAtt.length();\n    int start = offsetAtt.startOffset();\n    int end = offsetAtt.endOffset();\n    \n    int newSize = bufferLen + len;\n    buffer = ArrayUtil.grow(buffer, newSize);\n    startOffset = ArrayUtil.grow(startOffset, newSize);\n    endOffset = ArrayUtil.grow(endOffset, newSize);\n    lastEndOffset = end;\n\n    if (end - start != len) {\n            for (int i = 0, cp = 0; i < len; i += Character.charCount(cp)) {\n        cp = buffer[bufferLen] = Character.codePointAt(termBuffer, i, len);\n        startOffset[bufferLen] = start;\n        endOffset[bufferLen] = end;\n        bufferLen++;\n      }\n    } else {\n            for (int i = 0, cp = 0, cpLen = 0; i < len; i += cpLen) {\n        cp = buffer[bufferLen] = Character.codePointAt(termBuffer, i, len);\n        cpLen = Character.charCount(cp);\n        startOffset[bufferLen] = start;\n        start = endOffset[bufferLen] = start + cpLen;\n        bufferLen++;\n      }\n    }\n  }
307	public int normalize(char s[], int len) {\n\n    for (int i = 0; i < len; i++) {\n      switch (s[i]) {\n                case '\u0981':\n          len = delete(s, i, len);\n          i--;\n          break;\n\n                case '\u09C0':\n          s[i] = '\u09BF';\n          break;\n\n                case '\u09C2':\n          s[i] = '\u09C1';\n          break;\n\n                case '\u0995':\n          if(i + 2 < len && s[i+1] == '\u09CD' && s[i+2] == '\u09BF') {\n            if (i == 0) {\n              s[i] = '\u0996';\n              len = delete(s, i + 2, len);\n              len = delete(s, i + 1, len);\n            } else {\n              s[i+1] = '\u0996';\n              len = delete(s, i + 2, len);\n            }\n          }\n          break;\n\n                case '\u0999':\n          s[i] = '\u0982';\n          break;\n\n                case '\u09AF':\n          if(i - 2 == 0 && s[i-1] == '\u09CD') {\n            s[i - 1] = '\u09C7';\n\n            if(i + 1 < len && s[i+1] == '\u09BE') {\n              len = delete(s, i+1, len);\n            }\n            len = delete(s, i, len);\n            i --;\n          } else if(i - 1 >= 0 && s[i-1] == '\u09CD' ){\n            len = delete(s, i, len);\n            len = delete(s, i-1, len);\n            i -=2;\n          }\n          break;\n\n                case '\u09AC':\n          if((i >= 1 && s[i-1] != '\u09CD') || i == 0)\n            break;\n          if(i - 2 == 0) {\n            len = delete(s, i, len);\n            len = delete(s, i - 1, len);\n            i -= 2;\n          } else if(i - 5 >= 0 && s[i - 3] == '\u09CD') {\n            len = delete(s, i, len);\n            len = delete(s, i-1, len);\n            i -=2;\n          } else if(i - 2 >= 0){\n            s[i - 1] = s[i - 2];\n            len = delete(s, i, len);\n            i --;\n          }\n          break;\n\n                case '\u0983':\n          if(i == len -1) {\n            if(len <= 3) {\n              s[i] = '\u09B9';\n            } else {\n              len = delete(s, i, len);\n            }\n          } else {\n            s[i] = s[i+1];\n          }\n          break;\n\n                case '\u09B6':\n        case '\u09B7':\n          s[i] = '\u09B8';\n          break;\n\n                case '\u09A3':\n          s[i] = '\u09A8';\n          break;\n\n                case '\u09DC':\n        case '\u09DD':\n          s[i] = '\u09B0';\n          break;\n\n        case '\u09CE':\n          s[i] = '\u09A4';\n          break;\n\n        default:\n          break;\n      }\n    }\n\n    return len;\n  }
308	private static void writeCopyState(CopyState state, DataOutput out) throws IOException {\n        out.writeVInt(state.infosBytes.length);\n    out.writeBytes(state.infosBytes, 0, state.infosBytes.length);\n    out.writeVLong(state.gen);\n    out.writeVLong(state.version);\n    SimpleServer.writeFilesMetaData(out, state.files);\n\n    out.writeVInt(state.completedMergeFiles.size());\n    for(String fileName : state.completedMergeFiles) {\n      out.writeString(fileName);\n    }\n    out.writeVLong(state.primaryGen);\n  }
309	public static void exec(String[] args) {\n        if (args.length < 1) {\n      System.err.println("Usage: java Benchmark <algorithm file>");\n      System.exit(1);\n    }\n    \n        Path algFile = Paths.get(args[0]);\n    if (!Files.isReadable(algFile)) {\n      System.err.println("cannot find/read algorithm file: "+algFile.toAbsolutePath()); \n      System.exit(1);\n    }\n    \n    System.out.println("Running algorithm from: "+algFile.toAbsolutePath());\n    \n    Benchmark benchmark = null;\n    try {\n      benchmark = new Benchmark(Files.newBufferedReader(algFile, StandardCharsets.UTF_8));\n    } catch (Exception e) {\n      e.printStackTrace();\n      System.exit(1);\n    }\n\n    System.out.println("------------> algorithm:");\n    System.out.println(benchmark.getAlgorithm().toString());\n\n        try {\n      benchmark.execute();\n    } catch (Exception e) {\n      System.err.println("Error: cannot execute the algorithm! "+e.getMessage());\n      e.printStackTrace();\n    }\n\n    System.out.println("####################");\n    System.out.println("###  D O N E !!! ###");\n    System.out.println("####################");\n  }
310	private void parseObject(String path) throws ParseException {\n    scan('{');\n    boolean first = true;\n    while (true) {\n      char ch = peek();\n      if (ch == '}') {\n        break;\n      } else if (first == false) {\n        if (ch == ',') {\n                    upto++;\n          ch = peek();\n          if (ch == '}') {\n            break;\n          }\n        } else {\n          throw newParseException("expected , but got " + ch);\n        }\n      }\n\n      first = false;\n\n      int uptoStart = upto;\n      String key = parseString();\n\n      if (path.equals("crs.properties") && key.equals("href")) {\n        upto = uptoStart;\n        throw newParseException("cannot handle linked crs");\n      }\n\n      scan(':');\n\n      Object o;\n\n      ch = peek();\n\n      uptoStart = upto;\n\n      if (ch == '[') {\n        String newPath;\n        if (path.length() == 0) {\n          newPath = key;\n        } else {\n          newPath = path + "." + key;\n        }\n        o = parseArray(newPath);\n      } else if (ch == '{') {\n        String newPath;\n        if (path.length() == 0) {\n          newPath = key;\n        } else {\n          newPath = path + "." + key;\n        }\n        parseObject(newPath);\n        o = null;\n      } else if (ch == '"') {\n        o = parseString();\n      } else if (ch == 't') {\n        scan("true");\n        o = Boolean.TRUE;\n      } else if (ch == 'f') {\n        scan("false");\n        o = Boolean.FALSE;\n      } else if (ch == 'n') {\n        scan("null");\n        o = null;\n      } else if (ch == '-' || ch == '.' || (ch >= '0' && ch <= '9')) {\n        o = parseNumber();\n      } else if (ch == '}') {\n        break;\n      } else {\n        throw newParseException("expected array, object, string or literal value, but got: " + ch);\n      }\n\n      if (path.equals("crs.properties") && key.equals("name")) {\n        if (o instanceof String == false) {\n          upto = uptoStart;\n          throw newParseException("crs.properties.name should be a string, but saw: " + o);\n        }\n        String crs = (String) o;\n        if (crs.startsWith("urn:ogc:def:crs:OGC") == false || crs.endsWith(":CRS84") == false) {\n          upto = uptoStart;\n          throw newParseException("crs must be CRS84 from OGC, but saw: " + o);\n        }\n      }\n\n      if (key.equals("type") && path.startsWith("crs") == false) {\n        if (o instanceof String == false) {\n          upto = uptoStart;\n          throw newParseException("type should be a string, but got: " + o);\n        }\n        String type = (String) o;\n        if (type.equals("Polygon") && isValidGeometryPath(path)) {\n          polyType = "Polygon";\n        } else if (type.equals("MultiPolygon") && isValidGeometryPath(path)) {\n          polyType = "MultiPolygon";\n        } else if ((type.equals("FeatureCollection") || type.equals("Feature")) && (path.equals("features.[]") || path.equals(""))) {\n          // OK, we recurse\n        } else {\n          upto = uptoStart;\n          throw newParseException("can only handle type FeatureCollection (if it has a single polygon geometry), Feature, Polygon or MutiPolygon, but got " + type);\n        }\n      } else if (key.equals("coordinates") && isValidGeometryPath(path)) {\n        if (o instanceof List == false) {\n          upto = uptoStart;\n          throw newParseException("coordinates should be an array, but got: " + o.getClass());\n        }\n        if (coordinates != null) {\n          upto = uptoStart;\n          throw newParseException("only one Polygon or MultiPolygon is supported");\n        }\n        coordinates = (List<Object>) o;\n      }\n    }\n\n    scan('}');\n  }
311	private Collection<String> getTransitiveDependenciesFromIvyCache\n  (String groupId, String artifactId, String version) {\n    SortedSet<String> transitiveDependencies = new TreeSet<>();\n        File ivyXmlFile = new File(new File(new File(ivyCacheDir, groupId), artifactId), "ivy-" + version + ".xml");\n    if ( ! ivyXmlFile.exists()) {\n      throw new BuildException("File not found: " + ivyXmlFile.getPath());\n    }\n    try {\n      Document document = documentBuilder.parse(ivyXmlFile);\n      String dependencyPath = "/ivy-module/dependencies/dependency"\n                            + "[   not(starts-with(@conf,'test->'))"\n                            + "and not(starts-with(@conf,'provided->'))"\n                            + "and not(starts-with(@conf,'optional->'))]";\n      NodeList dependencies = (NodeList)xpath.evaluate(dependencyPath, document, XPathConstants.NODESET);\n      for (int i = 0 ; i < dependencies.getLength() ; ++i) {\n        Element dependency = (Element)dependencies.item(i);\n        transitiveDependencies.add(dependency.getAttribute("org") + ':' + dependency.getAttribute("name"));\n      }\n    } catch (Exception e) {\n      throw new BuildException( "Exception collecting transitive dependencies for " \n                              + groupId + ':' + artifactId + ':' + version + " from "\n                              + ivyXmlFile.getAbsolutePath(), e);\n    }\n    return transitiveDependencies;\n  }
312	public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, StandardCharsets.UTF_8));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, StandardCharsets.UTF_8));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTerm(a, inputWord, expectedWord);\n    }\n  }
313	public int normalize(char s[], int len) {\n    for (int i = 0; i < len; i++) {\n      switch (s[i]) {\n        case YEH:\n        case DOTLESS_YEH:\n          s[i] = FARSI_YEH;\n          break;\n        case KAF:\n          s[i] = KEHEH;\n          break;\n        case ZWNJ:\n          if (i > 0 && s[i-1] == HEH) {\n            s[i-1] = AE;\n          }\n          len = delete(s, i, len);\n          i--;\n          break;\n        case HEH:\n          if (i == len-1) {\n            s[i] = AE;\n          }\n          break;\n        case TEH_MARBUTA:\n          s[i] = AE;\n          break;\n        case HEH_DOACHASHMEE:\n          s[i] = HEH;\n          break;\n        case REH:\n          if (i == 0) {\n            s[i] = RREH;\n          }\n          break;\n        case RREH_ABOVE:\n          s[i] = RREH;\n          break;\n        case TATWEEL:\n        case KASRATAN:\n        case DAMMATAN:\n        case FATHATAN:\n        case FATHA:\n        case DAMMA:\n        case KASRA:\n        case SHADDA:\n        case SUKUN:\n          len = delete(s, i, len);\n          i--;\n          break;\n        default:\n          if (Character.getType(s[i]) == Character.FORMAT) {\n            len = delete(s, i, len);\n            i--;\n          }\n      }\n    }\n    return len;\n  }
314	private CharSequence toLowercase(CharSequence chs) {\n    final int length = chs.length();\n    scratch.setLength(length);\n    scratch.grow(length);\n\n    char buffer[] = scratch.chars();\n    for (int i = 0; i < length;) {\n      i += Character.toChars(\n          Character.toLowerCase(Character.codePointAt(chs, i)), buffer, i);      \n    }\n\n    return scratch.get();\n  }
315	void add() throws IOException {\n                int termID = bytesHash.add(termAtt.getBytesRef());\n      \n    \n    if (termID >= 0) {      bytesHash.byteStart(termID);\n            if (numPostingInt + intPool.intUpto > IntBlockPool.INT_BLOCK_SIZE) {\n        intPool.nextBuffer();\n      }\n\n      if (ByteBlockPool.BYTE_BLOCK_SIZE - bytePool.byteUpto < numPostingInt*ByteBlockPool.FIRST_LEVEL_SIZE) {\n        bytePool.nextBuffer();\n      }\n\n      intUptos = intPool.buffer;\n      intUptoStart = intPool.intUpto;\n      intPool.intUpto += streamCount;\n\n      postingsArray.intStarts[termID] = intUptoStart + intPool.intOffset;\n\n      for(int i=0;i<streamCount;i++) {\n        final int upto = bytePool.newSlice(ByteBlockPool.FIRST_LEVEL_SIZE);\n        intUptos[intUptoStart+i] = upto + bytePool.byteOffset;\n      }\n      postingsArray.byteStarts[termID] = intUptos[intUptoStart];\n\n      newTerm(termID);\n\n    } else {\n      termID = (-termID)-1;\n      int intStart = postingsArray.intStarts[termID];\n      intUptos = intPool.buffers[intStart >> IntBlockPool.INT_BLOCK_SHIFT];\n      intUptoStart = intStart & IntBlockPool.INT_BLOCK_MASK;\n      addTerm(termID);\n    }\n\n    if (doNextCall) {\n      nextPerField.add(postingsArray.textStarts[termID]);\n    }\n  }
316	protected FieldInfo getFieldInfo(String field) {\n    if (searcher == null) {\n      return null;\n    }\n        FieldInfos fieldInfos = this.fieldInfos;     if (fieldInfos == null) {\n      synchronized (this) {\n        fieldInfos = this.fieldInfos;\n        if (fieldInfos == null) {\n          fieldInfos = MultiFields.getMergedFieldInfos(searcher.getIndexReader());\n          this.fieldInfos = fieldInfos;\n        }\n\n      }\n\n    }\n    return fieldInfos.fieldInfo(field);\n  }
317	public static int bytesDifference(BytesRef left, BytesRef right) {\n    int len = left.length < right.length ? left.length : right.length;\n    final byte[] bytesLeft = left.bytes;\n    final int offLeft = left.offset;\n    byte[] bytesRight = right.bytes;\n    final int offRight = right.offset;\n    for (int i = 0; i < len; i++)\n      if (bytesLeft[i+offLeft] != bytesRight[i+offRight])\n        return i;\n    return len;\n  }
318	public void getNextTransition(Transition t) {\n        assert (t.transitionUpto+3 - states[2*t.source]) <= 3*states[2*t.source+1];\n\n        assert transitionSorted(t);\n\n    t.dest = transitions[t.transitionUpto++];\n    t.min = transitions[t.transitionUpto++];\n    t.max = transitions[t.transitionUpto++];\n  }
319	public Query parse(String queryText) {\n    if ("*".equals(queryText.trim())) {\n      return new MatchAllDocsQuery();\n    }\n\n    char data[] = queryText.toCharArray();\n    char buffer[] = new char[data.length];\n\n    State state = new State(data, buffer, 0, data.length);\n    parseSubQuery(state);\n    if (state.top == null) {\n      return new MatchNoDocsQuery("empty string passed to query parser");\n    } else {\n      return state.top;\n    }\n  }
320	public final boolean remove(T element) {\n    for (int i = 1; i <= size; i++) {\n      if (heap[i] == element) {\n        heap[i] = heap[size];\n        heap[size] = null;         size--;\n        if (i <= size) {\n          if (!upHeap(i)) {\n            downHeap(i);\n          }\n        }\n        return true;\n      }\n    }\n    return false;\n  }
321	public void finishTerm() throws IOException {\n    int numArcs = 0;\n    int numDedupBytes = 1;\n    analyzed.grow(analyzed.length() + 1);\n    analyzed.setLength(analyzed.length() + 1);\n    for (Entry entry : entries) {\n      if (numArcs == maxNumArcsForDedupByte(numDedupBytes)) {\n        analyzed.setByteAt(analyzed.length() - 1, (byte) (numArcs));\n        analyzed.grow(analyzed.length() + 1);\n        analyzed.setLength(analyzed.length() + 1);\n        numArcs = 0;\n        numDedupBytes++;\n      }\n      analyzed.setByteAt(analyzed.length() - 1, (byte) numArcs++);\n      Util.toIntsRef(analyzed.get(), scratchInts);\n      builder.add(scratchInts.get(), outputs.newPair(entry.weight, entry.payload));\n    }\n    maxAnalyzedPathsPerOutput = Math.max(maxAnalyzedPathsPerOutput, entries.size());\n    entries.clear();\n  }
322	public static final int hexToInt(String hex)\n    {\n        int len = hex.length();\n        if (len > 16)\n            throw new NumberFormatException();\n\n        int l = 0;\n        for (int i = 0; i < len; i++)\n        {\n            l <<= 4;\n            int c = Character.digit(hex.charAt(i), 16);\n            if (c < 0)\n                throw new NumberFormatException();\n            l |= c;\n        }\n        return l;\n    }
323	public static void checkHits(\n        Random random,\n        Query query,\n        String defaultFieldName,\n        IndexSearcher searcher,\n        int[] results)\n          throws IOException {\n\n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n\n    Set<Integer> correct = new TreeSet<>();\n    for (int i = 0; i < results.length; i++) {\n      correct.add(Integer.valueOf(results[i]));\n    }\n\n    Set<Integer> actual = new TreeSet<>();\n    for (int i = 0; i < hits.length; i++) {\n      actual.add(Integer.valueOf(hits[i].doc));\n    }\n\n    Assert.assertEquals(query.toString(defaultFieldName), correct, actual);\n\n    QueryUtils.check(random, query,searcher, LuceneTestCase.rarely(random));\n  }
324	private boolean isStemmable( String term )\n    {\n      for ( int c = 0; c < term.length(); c++ ) {\n        if ( !Character.isLetter( term.charAt( c ) ) )\n          return false;\n      }\n      return true;\n    }
325	private static Boolean isInsidePolygon(final GeoPoint point, final List<GeoPoint> polyPoints) {\n        final double latitude = point.getLatitude();\n    final double longitude = point.getLongitude();\n    final double sinLatitude = Math.sin(latitude);\n    final double cosLatitude = Math.cos(latitude);\n    final double sinLongitude = Math.sin(longitude);\n    final double cosLongitude = Math.cos(longitude);\n    \n        double arcDistance = 0.0;\n    Double prevAngle = null;\n        for (final GeoPoint polyPoint : polyPoints) {\n      final Double angle = computeAngle(polyPoint, sinLatitude, cosLatitude, sinLongitude, cosLongitude);\n      if (angle == null) {\n        return null;\n      }\n            if (prevAngle != null) {\n                double angleDelta = angle - prevAngle;\n        if (angleDelta < -Math.PI) {\n          angleDelta += Math.PI * 2.0;\n        }\n        if (angleDelta > Math.PI) {\n          angleDelta -= Math.PI * 2.0;\n        }\n        if (Math.abs(angleDelta - Math.PI) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n          return null;\n        }\n                arcDistance += angleDelta;\n              }\n      prevAngle = angle;\n    }\n    if (prevAngle != null) {\n      final Double lastAngle = computeAngle(polyPoints.get(0), sinLatitude, cosLatitude, sinLongitude, cosLongitude);\n      if (lastAngle == null) {\n        return null;\n      }\n                  double angleDelta = lastAngle - prevAngle;\n      if (angleDelta < -Math.PI) {\n        angleDelta += Math.PI * 2.0;\n      }\n      if (angleDelta > Math.PI) {\n        angleDelta -= Math.PI * 2.0;\n      }\n      if (Math.abs(angleDelta - Math.PI) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n        return null;\n      }\n            arcDistance += angleDelta;\n          }\n\n            if (Math.abs(arcDistance) < Vector.MINIMUM_ANGULAR_RESOLUTION) {\n            return null;\n    }\n    return arcDistance > 0.0;\n  }
326	public final AttributeSource cloneAttributes() {\n    final AttributeSource clone = new AttributeSource(this.factory);\n    \n    if (hasAttributes()) {\n            for (State state = getCurrentState(); state != null; state = state.next) {\n        clone.attributeImpls.put(state.attribute.getClass(), state.attribute.clone());\n      }\n      \n            for (Entry<Class<? extends Attribute>, AttributeImpl> entry : this.attributes.entrySet()) {\n        clone.attributes.put(entry.getKey(), clone.attributeImpls.get(entry.getValue().getClass()));\n      }\n    }\n    \n    return clone;\n  }
327	private static void encode(final InetAddress min, final InetAddress max, final byte[] bytes) {\n        final byte[] minEncoded = InetAddressPoint.encode(min);\n    final byte[] maxEncoded = InetAddressPoint.encode(max);\n        if (StringHelper.compare(BYTES, minEncoded, 0, maxEncoded, 0) > 0) {\n      throw new IllegalArgumentException("min value cannot be greater than max value for InetAddressRange field");\n    }\n    System.arraycopy(minEncoded, 0, bytes, 0, BYTES);\n    System.arraycopy(maxEncoded, 0, bytes, BYTES, BYTES);\n  }
328	private double createCoefficient(IndexSearcher searcher, int doc, Set<String> matchedTokens, String prefixToken) throws IOException {\n\n    Terms tv = searcher.getIndexReader().getTermVector(doc, TEXT_FIELD_NAME);\n    TermsEnum it = tv.iterator();\n\n    Integer position = Integer.MAX_VALUE;\n    BytesRef term;\n        while ((term = it.next()) != null) {\n\n      String docTerm = term.utf8ToString();\n\n      if (matchedTokens.contains(docTerm) || (prefixToken != null && docTerm.startsWith(prefixToken))) {\n \n        PostingsEnum docPosEnum = it.postings(null, PostingsEnum.OFFSETS);\n        docPosEnum.nextDoc();\n\n                int p = docPosEnum.nextPosition();\n        if (p < position) {\n          position = p;\n        }\n      }\n    }\n\n        return calculateCoefficient(position);\n  }
329	public static Rectangle fromPointDistance(final double centerLat, final double centerLon, final double radiusMeters) {\n    checkLatitude(centerLat);\n    checkLongitude(centerLon);\n    final double radLat = toRadians(centerLat);\n    final double radLon = toRadians(centerLon);\n        double radDistance = (radiusMeters + 7E-2) / EARTH_MEAN_RADIUS_METERS;\n    double minLat = radLat - radDistance;\n    double maxLat = radLat + radDistance;\n    double minLon;\n    double maxLon;\n\n    if (minLat > MIN_LAT_RADIANS && maxLat < MAX_LAT_RADIANS) {\n      double deltaLon = asin(sloppySin(radDistance) / cos(radLat));\n      minLon = radLon - deltaLon;\n      if (minLon < MIN_LON_RADIANS) {\n        minLon += 2d * PI;\n      }\n      maxLon = radLon + deltaLon;\n      if (maxLon > MAX_LON_RADIANS) {\n        maxLon -= 2d * PI;\n      }\n    } else {\n            minLat = max(minLat, MIN_LAT_RADIANS);\n      maxLat = min(maxLat, MAX_LAT_RADIANS);\n      minLon = MIN_LON_RADIANS;\n      maxLon = MAX_LON_RADIANS;\n    }\n\n    return new Rectangle(toDegrees(minLat), toDegrees(maxLat), toDegrees(minLon), toDegrees(maxLon));\n  }
330	protected void writeHeader(PrintWriter out) {\n    StringBuilder sb = threadBuffer.get();\n    if (sb == null) {\n      sb = new StringBuilder();\n      threadBuffer.set(sb);\n    }\n    sb.setLength(0);\n    sb.append(FIELDS_HEADER_INDICATOR);\n    for (String f : fieldsToWrite) {\n      sb.append(SEP).append(f);\n    }\n    out.println(sb.toString());\n  }
331	public static int parseInt(char[] chars, int offset, int len, int radix)\n          throws NumberFormatException {\n    if (chars == null || radix < Character.MIN_RADIX\n            || radix > Character.MAX_RADIX) {\n      throw new NumberFormatException();\n    }\n    int  i = 0;\n    if (len == 0) {\n      throw new NumberFormatException("chars length is 0");\n    }\n    boolean negative = chars[offset + i] == '-';\n    if (negative && ++i == len) {\n      throw new NumberFormatException("can't convert to an int");\n    }\n    if (negative == true){\n      offset++;\n      len--;\n    }\n    return parse(chars, offset, len, radix, negative);\n  }
332	public static PointValues.Relation relate(\n      double minLat, double maxLat, double minLon, double maxLon,\n      double lat, double lon, double distanceSortKey, double axisLat) {\n\n    if (minLon > maxLon) {\n      throw new IllegalArgumentException("Box crosses the dateline");\n    }\n\n    if ((lon < minLon || lon > maxLon) && (axisLat + Rectangle.AXISLAT_ERROR < minLat || axisLat - Rectangle.AXISLAT_ERROR > maxLat)) {\n            if (SloppyMath.haversinSortKey(lat, lon, minLat, minLon) > distanceSortKey &&\n          SloppyMath.haversinSortKey(lat, lon, minLat, maxLon) > distanceSortKey &&\n          SloppyMath.haversinSortKey(lat, lon, maxLat, minLon) > distanceSortKey &&\n          SloppyMath.haversinSortKey(lat, lon, maxLat, maxLon) > distanceSortKey) {\n                return Relation.CELL_OUTSIDE_QUERY;\n      }\n    }\n\n    if (within90LonDegrees(lon, minLon, maxLon) &&\n        SloppyMath.haversinSortKey(lat, lon, minLat, minLon) <= distanceSortKey &&\n        SloppyMath.haversinSortKey(lat, lon, minLat, maxLon) <= distanceSortKey &&\n        SloppyMath.haversinSortKey(lat, lon, maxLat, minLon) <= distanceSortKey &&\n        SloppyMath.haversinSortKey(lat, lon, maxLat, maxLon) <= distanceSortKey) {\n            return Relation.CELL_INSIDE_QUERY;\n    }\n\n    return Relation.CELL_CROSSES_QUERY;\n  }
333	public int doCheck(Options opts) throws IOException, InterruptedException {\n    setCrossCheckTermVectors(opts.doCrossCheckTermVectors);\n    setChecksumsOnly(opts.doChecksumsOnly);\n    setInfoStream(opts.out, opts.verbose);\n\n    Status result = checkIndex(opts.onlySegments);\n    if (result.missingSegments) {\n      return 1;\n    }\n\n    if (!result.clean) {\n      if (!opts.doExorcise) {\n        opts.out.println("WARNING: would write new segments file, and " + result.totLoseDocCount + " documents would be lost, if -exorcise were specified\n");\n      } else {\n        opts.out.println("WARNING: " + result.totLoseDocCount + " documents will be lost\n");\n        opts.out.println("NOTE: will write new segments file in 5 seconds; this will remove " + result.totLoseDocCount + " docs from the index. YOU WILL LOSE DATA. THIS IS YOUR LAST CHANCE TO CTRL+C!");\n        for(int s=0;s<5;s++) {\n          Thread.sleep(1000);\n          opts.out.println("  " + (5-s) + "...");\n        }\n        opts.out.println("Writing...");\n        exorciseIndex(result);\n        opts.out.println("OK");\n        opts.out.println("Wrote new segments file \"" + result.newSegments.getSegmentsFileName() + "\"");\n      }\n    }\n    opts.out.println("");\n\n    if (result.clean == true) {\n      return 0;\n    } else {\n      return 1;\n    }\n  }
334	private boolean advanceRpts(PhrasePositions pp) throws IOException {\n    if (pp.rptGroup < 0) {\n      return true;     }\n    PhrasePositions[] rg = rptGroups[pp.rptGroup];\n    FixedBitSet bits = new FixedBitSet(rg.length);     int k0 = pp.rptInd;\n    int k;\n    while((k=collide(pp)) >= 0) {\n      pp = lesser(pp, rg[k]);       if (!advancePP(pp)) {\n        return false;       }\n      if (k != k0) {         bits = FixedBitSet.ensureCapacity(bits, k);\n        bits.set(k);       }\n    }\n            int n = 0;\n        int numBits = bits.length();     while (bits.cardinality() > 0) {\n      PhrasePositions pp2 = pq.pop();\n      rptStack[n++] = pp2;\n      if (pp2.rptGroup >= 0 \n          && pp2.rptInd < numBits            && bits.get(pp2.rptInd)) {\n        bits.clear(pp2.rptInd);\n      }\n    }\n        for (int i=n-1; i>=0; i--) {\n      pq.add(rptStack[i]);\n    }\n    return true;\n  }
335	public UnitNRShape toShape(Calendar cal) {\n        final int calPrecField = getCalPrecisionField(cal);    try {\n      int[] valStack = new int[maxLevels];      int len = 0;\n      if (calPrecField >= Calendar.YEAR) {        int year = cal.get(Calendar.YEAR);\n        int yearAdj = cal.get(Calendar.ERA) == 0 ? AD_YEAR_BASE - (year - 1) : AD_YEAR_BASE + year;\n\n        valStack[len++] = yearAdj / 1000_000;\n        yearAdj -= valStack[len-1] * 1000_000;\n        valStack[len++] = yearAdj / 1000;\n        yearAdj -= valStack[len-1] * 1000;\n        valStack[len++] = yearAdj;\n        for (int level = YEAR_LEVEL +1; level < FIELD_BY_LEVEL.length; level++) {\n          int field = FIELD_BY_LEVEL[level];\n          if (field > calPrecField)\n            break;\n          valStack[len++] = cal.get(field) - cal.getActualMinimum(field);\n        }\n      }\n\n      return toShape(valStack, len);\n    } finally {\n      clearFieldsAfter(cal, calPrecField);    }\n  }
336	protected static CharArraySet loadStopwordSet(Path stopwords) throws IOException {\n    Reader reader = null;\n    try {\n      reader = Files.newBufferedReader(stopwords, StandardCharsets.UTF_8);\n      return WordlistLoader.getWordSet(reader);\n    } finally {\n      IOUtils.close(reader);\n    }\n  }
337	private void loadSkipLevels() throws IOException {\n    if (docCount <= skipInterval[0]) {\n      numberOfSkipLevels = 1;\n    } else {\n      numberOfSkipLevels = 1+MathUtil.log(docCount/skipInterval[0], skipMultiplier);\n    }\n\n    if (numberOfSkipLevels > maxNumberOfSkipLevels) {\n      numberOfSkipLevels = maxNumberOfSkipLevels;\n    }\n\n    skipStream[0].seek(skipPointer[0]);\n    \n    int toBuffer = numberOfLevelsToBuffer;\n    \n    for (int i = numberOfSkipLevels - 1; i > 0; i--) {\n            long length = skipStream[0].readVLong();\n      \n            skipPointer[i] = skipStream[0].getFilePointer();\n      if (toBuffer > 0) {\n                skipStream[i] = new SkipBuffer(skipStream[0], (int) length);\n        toBuffer--;\n      } else {\n                skipStream[i] = skipStream[0].clone();\n        if (inputIsBuffered && length < BufferedIndexInput.BUFFER_SIZE) {\n          ((BufferedIndexInput) skipStream[i]).setBufferSize(Math.max(BufferedIndexInput.MIN_BUFFER_SIZE, (int) length));\n        }\n        \n                skipStream[0].seek(skipStream[0].getFilePointer() + length);\n      }\n    }\n   \n        skipPointer[0] = skipStream[0].getFilePointer();\n  }
338	public synchronized void addDVUpdate(DocValuesFieldUpdates update) {\n    if (update.getFinished() == false) {\n      throw new IllegalArgumentException("call finish first");\n    }\n    List<DocValuesFieldUpdates> fieldUpdates = pendingDVUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new ArrayList<>();\n      pendingDVUpdates.put(update.field, fieldUpdates);\n    }\n\n    assert assertNoDupGen(fieldUpdates, update);\n\n    ramBytesUsed.addAndGet(update.ramBytesUsed());\n\n    fieldUpdates.add(update);\n\n    if (isMerging) {\n      fieldUpdates = mergingDVUpdates.get(update.field);\n      if (fieldUpdates == null) {\n        fieldUpdates = new ArrayList<>();\n        mergingDVUpdates.put(update.field, fieldUpdates);\n      }\n      fieldUpdates.add(update);\n    }\n  }
339	protected String taskReportLine(String longestOp, TaskStats stat) {\n    PerfTask task = stat.getTask();\n    StringBuilder sb = new StringBuilder();\n    sb.append(Format.format(task.getName(), longestOp));\n    String round = (stat.getRound()>=0 ? ""+stat.getRound() : "-");\n    sb.append(Format.formatPaddLeft(round, ROUND));\n    sb.append(getRunData().getConfig().getColsValuesForValsByRound(stat.getRound()));\n    sb.append(Format.format(stat.getNumRuns(), RUNCNT)); \n    sb.append(Format.format(stat.getCount() / stat.getNumRuns(), RECCNT));\n    long elapsed = (stat.getElapsed()>0 ? stat.getElapsed() : 1);     sb.append(Format.format(2, (float) (stat.getCount() * 1000.0 / elapsed), RECSEC));\n    sb.append(Format.format(2, (float) stat.getElapsed() / 1000, ELAPSED));\n    sb.append(Format.format(0, (float) stat.getMaxUsedMem() / stat.getNumRuns(), USEDMEM)); \n    sb.append(Format.format(0, (float) stat.getMaxTotMem() / stat.getNumRuns(), TOTMEM));\n    return sb.toString();\n  }
340	public final int runAndMaybeStats(boolean reportStats) throws Exception {\n    if (!reportStats || shouldNotRecordStats()) {\n      setup();\n      int count = doLogic();\n      count = disableCounting ? 0 : count;\n      tearDown();\n      return count;\n    }\n    if (reportStats && depth <= maxDepthLogStart && !shouldNeverLogAtStart()) {\n      System.out.println("------------> starting task: " + getName());\n    }\n    setup();\n    Points pnts = runData.getPoints();\n    TaskStats ts = pnts.markTaskStart(this, runData.getConfig().getRoundNumber());\n    int count = doLogic();\n    count = disableCounting ? 0 : count;\n    pnts.markTaskEnd(ts, count);\n    tearDown();\n    return count;\n  }
341	public static String pathToString(String dim, String[] path) {\n    String[] fullPath = new String[1+path.length];\n    fullPath[0] = dim;\n    System.arraycopy(path, 0, fullPath, 1, path.length);\n    return pathToString(fullPath, fullPath.length);\n  }
342	public static CharArraySet getSnowballWordSet(Reader reader, CharArraySet result)\n      throws IOException {\n    BufferedReader br = null;\n    try {\n      br = getBufferedReader(reader);\n      String line = null;\n      while ((line = br.readLine()) != null) {\n        int comment = line.indexOf('|');\n        if (comment >= 0) line = line.substring(0, comment);\n        String words[] = line.split("\\s+");\n        for (int i = 0; i < words.length; i++)\n          if (words[i].length() > 0) result.add(words[i]);\n      }\n    } finally {\n      IOUtils.close(br);\n    }\n    return result;\n  }
343	protected Query newPrefixQuery(String text) {\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    for (Map.Entry<String,Float> entry : weights.entrySet()) {\n      final String fieldName = entry.getKey();\n      final BytesRef term = getAnalyzer().normalize(fieldName, text);\n      Query q = new PrefixQuery(new Term(fieldName, term));\n      float boost = entry.getValue();\n      if (boost != 1f) {\n        q = new BoostQuery(q, boost);\n      }\n      bq.add(q, BooleanClause.Occur.SHOULD);\n    }\n    return simplify(bq.build());\n  }
344	private static byte[] encode(double latitude, double longitude) {\n    byte[] bytes = new byte[2 * Integer.BYTES];\n    NumericUtils.intToSortableBytes(encodeLatitude(latitude), bytes, 0);\n    NumericUtils.intToSortableBytes(encodeLongitude(longitude), bytes, Integer.BYTES);\n    return bytes;\n  }
345	public static String getQueryAsXmlString(Properties formProperties, InputStream xslIs)\n      throws SAXException, IOException, ParserConfigurationException, TransformerException {\n        StringWriter writer = new StringWriter();\n    StreamResult result = new StreamResult(writer);\n    transformCriteria(formProperties, xslIs, result);\n    return writer.toString();\n  }
346	protected Collection<ScoreTerm> suggestSimilar(Term term, int numSug, IndexReader ir, int docfreq, int editDistance,\n                                                 float accuracy, final CharsRefBuilder spare) throws IOException {\n    \n    AttributeSource atts = new AttributeSource();\n    MaxNonCompetitiveBoostAttribute maxBoostAtt =\n      atts.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n    Terms terms = MultiFields.getTerms(ir, term.field());\n    if (terms == null) {\n      return Collections.emptyList();\n    }\n    FuzzyTermsEnum e = new FuzzyTermsEnum(terms, atts, term, editDistance, Math.max(minPrefix, editDistance-1), true);\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    \n    BytesRef queryTerm = new BytesRef(term.text());\n    BytesRef candidateTerm;\n    ScoreTerm st = new ScoreTerm();\n    BoostAttribute boostAtt =\n      e.attributes().addAttribute(BoostAttribute.class);\n    while ((candidateTerm = e.next()) != null) {\n            float score = boostAtt.getBoost();\n            if (stQueue.size() >= numSug && score <= stQueue.peek().boost) {\n        continue;\n      }\n      \n            if (queryTerm.bytesEquals(candidateTerm)) {\n        continue;\n      }\n      \n      int df = e.docFreq();\n      \n            if (df <= docfreq) {\n        continue;\n      }\n      \n      final String termAsString;\n      if (distance == INTERNAL_LEVENSHTEIN) {\n                termAsString = null;\n      } else {\n        spare.copyUTF8Bytes(candidateTerm);\n        termAsString = spare.toString();\n        score = distance.getDistance(term.text(), termAsString);\n      }\n      \n      if (score < accuracy) {\n        continue;\n      }\n      \n            st.term = BytesRef.deepCopyOf(candidateTerm);\n      st.boost = score;\n      st.docfreq = df;\n      st.termAsString = termAsString;\n      st.score = score;\n      stQueue.offer(st);\n            st = (stQueue.size() > numSug) ? stQueue.poll() : new ScoreTerm();\n      maxBoostAtt.setMaxNonCompetitiveBoost((stQueue.size() >= numSug) ? stQueue.peek().boost : Float.NEGATIVE_INFINITY);\n    }\n      \n    return stQueue;\n  }
347	protected List<CharSequence[]> loadFieldValues(String[] fields,\n                                                 DocIdSetIterator docIter, int cacheCharsThreshold)\n      throws IOException {\n    List<CharSequence[]> docListOfFields =\n        new ArrayList<>(cacheCharsThreshold == 0 ? 1 : (int) Math.min(64, docIter.cost()));\n\n    LimitedStoredFieldVisitor visitor = newLimitedStoredFieldsVisitor(fields);\n    int sumChars = 0;\n    do {\n      int docId = docIter.nextDoc();\n      if (docId == DocIdSetIterator.NO_MORE_DOCS) {\n        break;\n      }\n      visitor.init();\n      searcher.doc(docId, visitor);\n      CharSequence[] valuesByField = visitor.getValuesByField();\n      docListOfFields.add(valuesByField);\n      for (CharSequence val : valuesByField) {\n        sumChars += (val == null ? 0 : val.length());\n      }\n    } while (sumChars <= cacheCharsThreshold && cacheCharsThreshold != 0);\n    return docListOfFields;\n  }
348	public boolean stem(char[] wordBuffer, int offset, int wordLen) {\n    reset();\n    if (b.length < wordLen) {\n      b = new char[ArrayUtil.oversize(wordLen, Character.BYTES)];\n    }\n    System.arraycopy(wordBuffer, offset, b, 0, wordLen);\n    i = wordLen;\n    return stem(0);\n  }
349	protected void init() {\n    skipBuffer = new RAMOutputStream[numberOfSkipLevels];\n    for (int i = 0; i < numberOfSkipLevels; i++) {\n      skipBuffer[i] = new RAMOutputStream();\n    }\n  }
350	public List<Map.Entry<String,FileMetaData>> getFilesToCopy(Map<String,FileMetaData> files) throws IOException {\n\n    List<Map.Entry<String,FileMetaData>> toCopy = new ArrayList<>();\n    for (Map.Entry<String,FileMetaData> ent : files.entrySet()) {\n      String fileName = ent.getKey();\n      FileMetaData fileMetaData = ent.getValue();\n      if (fileIsIdentical(fileName, fileMetaData) == false) {\n        toCopy.add(ent);\n      }\n    }\n\n    return toCopy;\n  }
351	protected ByteBufferIndexInput buildSlice(String sliceDescription, long offset, long length) {\n    if (buffers == null) {\n      throw new AlreadyClosedException("Already closed: " + this);\n    }\n\n    final ByteBuffer newBuffers[] = buildSlice(buffers, offset, length);\n    final int ofs = (int) (offset & chunkSizeMask);\n    \n    final ByteBufferIndexInput clone = newCloneInstance(getFullSliceDescription(sliceDescription), newBuffers, ofs, length);\n    clone.isClone = true;\n    \n    return clone;\n  }
352	public final int computeIterations(int valueCount, int ramBudget) {\n    final int iterations = ramBudget / (byteBlockCount() + 8 * byteValueCount());\n    if (iterations == 0) {\n            return 1;\n    } else if ((iterations - 1) * byteValueCount() >= valueCount) {\n            return (int) Math.ceil((double) valueCount / byteValueCount());\n    } else {\n      return iterations;\n    }\n  }
353	public static IntsRef getByOutput(FST<Long> fst, long targetOutput) throws IOException {\n\n    final BytesReader in = fst.getBytesReader();\n\n        FST.Arc<Long> arc = fst.getFirstArc(new FST.Arc<Long>());\n    \n    FST.Arc<Long> scratchArc = new FST.Arc<>();\n\n    final IntsRefBuilder result = new IntsRefBuilder();\n    return getByOutput(fst, targetOutput, in, arc, scratchArc, result);\n  }
354	public synchronized void setMaxMergesAndThreads(int maxMergeCount, int maxThreadCount) {\n    if (maxMergeCount == AUTO_DETECT_MERGES_AND_THREADS && maxThreadCount == AUTO_DETECT_MERGES_AND_THREADS) {\n            this.maxMergeCount = AUTO_DETECT_MERGES_AND_THREADS;\n      this.maxThreadCount = AUTO_DETECT_MERGES_AND_THREADS;\n    } else if (maxMergeCount == AUTO_DETECT_MERGES_AND_THREADS) {\n      throw new IllegalArgumentException("both maxMergeCount and maxThreadCount must be AUTO_DETECT_MERGES_AND_THREADS");\n    } else if (maxThreadCount == AUTO_DETECT_MERGES_AND_THREADS) {\n      throw new IllegalArgumentException("both maxMergeCount and maxThreadCount must be AUTO_DETECT_MERGES_AND_THREADS");\n    } else {\n      if (maxThreadCount < 1) {\n        throw new IllegalArgumentException("maxThreadCount should be at least 1");\n      }\n      if (maxMergeCount < 1) {\n        throw new IllegalArgumentException("maxMergeCount should be at least 1");\n      }\n      if (maxThreadCount > maxMergeCount) {\n        throw new IllegalArgumentException("maxThreadCount should be <= maxMergeCount (= " + maxMergeCount + ")");\n      }\n      this.maxThreadCount = maxThreadCount;\n      this.maxMergeCount = maxMergeCount;\n    }\n  }
355	protected Query getWildcardQuery(String field, String termStr) throws ParseException\n  {\n    if ("*".equals(field)) {\n      if ("*".equals(termStr)) return newMatchAllDocsQuery();\n    }\n    if (!allowLeadingWildcard && (termStr.startsWith("*") || termStr.startsWith("?")))\n      throw new ParseException("'*' or '?' not allowed as first character in WildcardQuery");\n\n    Term t = new Term(field, analyzeWildcard(field, termStr));\n    return newWildcardQuery(t);\n  }
356	private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n        int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    long numValues = 0;\n    BytesRefBuilder previousValue = new BytesRefBuilder();\n    long prefixSum = 0;     for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n      if (minLength == maxLength) {\n        int termPosition = (int) (numValues & INTERVAL_MASK);\n        if (termPosition == 0) {\n                    previousValue.copyBytes(v);\n        } else if (termPosition == INTERVAL_COUNT - 1) {\n                    prefixSum += StringHelper.bytesDifference(previousValue.get(), v);\n        }\n      }\n      numValues++;\n    }\n                if (minLength == maxLength && prefixSum <= 3*(numValues >> INTERVAL_SHIFT)) {\n            addBinaryField(field, values);\n    } else if (numValues < REVERSE_INTERVAL_COUNT) {\n            addBinaryField(field, values);\n    } else {\n      assert numValues > 0;             meta.writeVInt(field.number);\n      meta.writeByte(Lucene54DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n            final long startFP = data.getFilePointer();\n                  RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, MONOTONIC_BLOCK_SIZE);\n            RAMOutputStream bytesBuffer = new RAMOutputStream();\n            RAMOutputStream headerBuffer = new RAMOutputStream();\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      lastTerm.grow(maxLength);\n      long count = 0;\n      int suffixDeltas[] = new int[INTERVAL_COUNT];\n      for (BytesRef v : values) {\n        int termPosition = (int) (count & INTERVAL_MASK);\n        if (termPosition == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n                    headerBuffer.writeVInt(v.length);\n          headerBuffer.writeBytes(v.bytes, v.offset, v.length);\n          lastTerm.copyBytes(v);\n        } else {\n                              int sharedPrefix = Math.min(255, StringHelper.bytesDifference(lastTerm.get(), v));\n          bytesBuffer.writeByte((byte) sharedPrefix);\n          bytesBuffer.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n                    suffixDeltas[termPosition] = v.length - sharedPrefix - 1;\n        }\n        \n        count++;\n                if ((count & INTERVAL_MASK) == 0) {\n          flushTermsDictBlock(headerBuffer, bytesBuffer, suffixDeltas);\n        }\n      }\n            int leftover = (int) (count & INTERVAL_MASK);\n      if (leftover > 0) {\n        Arrays.fill(suffixDeltas, leftover, suffixDeltas.length, 0);\n        flushTermsDictBlock(headerBuffer, bytesBuffer, suffixDeltas);\n      }\n      final long indexStartFP = data.getFilePointer();\n            termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(MONOTONIC_BLOCK_SIZE);\n      addReverseTermIndex(field, values, maxLength);\n    }\n  }
357	public synchronized long deleteDocuments(String id) throws IOException {\n    assert buffer.getFilePointer() == 0;\n    buffer.writeByte(OP_DELETE_DOCUMENTS);\n    buffer.writeString(id);\n    return flushBuffer();\n  }
358	public final static String htmlEncode(String plainText)\n  {\n    if (plainText == null || plainText.length() == 0)\n    {\n      return "";\n    }\n\n    StringBuilder result = new StringBuilder(plainText.length());\n\n    for (int index=0; index<plainText.length(); index++)\n    {\n      char ch = plainText.charAt(index);\n\n      switch (ch) {\n      case '"':\n        result.append("&quot;");\n        break;\n      case '&':\n        result.append("&amp;");\n        break;\n      case '<':\n        result.append("&lt;");\n        break;\n      case '>':\n        result.append("&gt;");\n        break;\n      case '\'':\n        result.append("&#x27;");\n        break;\n      case '/':\n        result.append("&#x2F;");\n        break;\n      default:\n        result.append(ch);\n      }\n    }\n\n    return result.toString();\n  }
359	public TernaryTreeNode insert(TernaryTreeNode currentNode, CharSequence s,\n          Object val, int x) {\n    if (s == null || s.length() <= x) {\n      return currentNode;\n    }\n    if (currentNode == null) {\n      TernaryTreeNode newNode = new TernaryTreeNode();\n      newNode.splitchar = s.charAt(x);\n      currentNode = newNode;\n      if (x < s.length() - 1) {\n        currentNode.eqKid = insert(currentNode.eqKid, s, val, x + 1);\n      } else {\n        currentNode.token = s.toString();\n        currentNode.val = val;\n        return currentNode;\n      }\n    } else if (currentNode.splitchar > s.charAt(x)) {\n      currentNode.loKid = insert(currentNode.loKid, s, val, x);\n    } else if (currentNode.splitchar == s.charAt(x)) {\n      if (x < s.length() - 1) {\n        currentNode.eqKid = insert(currentNode.eqKid, s, val, x + 1);\n      } else {\n        currentNode.token = s.toString();\n        currentNode.val = val;\n        return currentNode;\n      }\n    } else {\n      currentNode.hiKid = insert(currentNode.hiKid, s, val, x);\n    }\n    return currentNode;\n  }
360	public static SidedPlane constructNormalizedPerpendicularSidedPlane(final Vector insidePoint,\n    final Vector normalVector, final Vector point1, final Vector point2) {\n    final Vector pointsVector = new Vector(point1.x - point2.x, point1.y - point2.y, point1.z - point2.z);\n    final Vector newNormalVector = new Vector(normalVector, pointsVector);\n    try {\n            return new SidedPlane(insidePoint, newNormalVector, -newNormalVector.dotProduct(point1));\n    } catch (IllegalArgumentException e) {\n      return null;\n    }\n  }
361	protected Explanation explain(Weight weight, int doc) throws IOException {\n    int n = ReaderUtil.subIndex(doc, leafContexts);\n    final LeafReaderContext ctx = leafContexts.get(n);\n    int deBasedDoc = doc - ctx.docBase;\n    final Bits liveDocs = ctx.reader().getLiveDocs();\n    if (liveDocs != null && liveDocs.get(deBasedDoc) == false) {\n      return Explanation.noMatch("Document " + doc + " is deleted");\n    }\n    return weight.explain(ctx, deBasedDoc);\n  }
362	public int put(K key, V val) {\n    final Set<V> theSet;\n    if (theMap.containsKey(key)) {\n      theSet = theMap.get(key);\n    } else {\n      theSet = new HashSet<>(23);\n      theMap.put(key, theSet);\n    }\n    theSet.add(val);\n    return theSet.size();\n  }
363	public Object highlightWithoutSearcher(String field, Query query, String content, int maxPassages)\n      throws IOException {\n    if (this.searcher != null) {\n      throw new IllegalStateException("highlightWithoutSearcher should only be called on a " +\n          getClass().getSimpleName() + " without an IndexSearcher.");\n    }\n    Objects.requireNonNull(content, "content is required");\n    Set<Term> queryTerms = extractTerms(query);\n    return getFieldHighlighter(field, query, queryTerms, maxPassages)\n        .highlightFieldForDoc(null, -1, content);\n  }
364	private CharsetDecoder getJavaEncoding(String encoding) {\n    if ("ISO8859-14".equals(encoding)) {\n      return new ISO8859_14Decoder();\n    }\n    String canon = CHARSET_ALIASES.get(encoding);\n    if (canon != null) {\n      encoding = canon;\n    }\n    Charset charset = Charset.forName(encoding);\n    return charset.newDecoder().onMalformedInput(CodingErrorAction.REPLACE);\n  }
365	public static void fsync(Path fileToSync, boolean isDir) throws IOException {\n            try (final FileChannel file = FileChannel.open(fileToSync, isDir ? StandardOpenOption.READ : StandardOpenOption.WRITE)) {\n      file.force(true);\n    } catch (IOException ioe) {\n      if (isDir) {\n        assert (Constants.LINUX || Constants.MAC_OS_X) == false :\n            "On Linux and MacOSX fsyncing a directory should not throw IOException, "+\n                "we just don't want to rely on that in production (undocumented). Got: " + ioe;\n                return;\n      }\n            throw ioe;\n    }\n  }
366	public static IvyNodeElement adapt(ResolveReport report) {\n    Map<ModuleRevisionId,IvyNodeElement> resolvedNodes = new HashMap<>();\n\n    IvyNodeElement root = new IvyNodeElement();\n    root.setModuleRevisionId(report.getModuleDescriptor().getModuleRevisionId());\n    resolvedNodes.put(report.getModuleDescriptor().getModuleRevisionId(), root);\n\n    @SuppressWarnings("unchecked") List<IvyNode> dependencies = report.getDependencies();\n\n        for (Iterator<IvyNode> iter = dependencies.iterator(); iter.hasNext();) {\n      IvyNode node = iter.next();\n      if (node.getAllEvictingNodes() != null) {\n                                continue;\n      }\n      IvyNodeElement nodeElement = new IvyNodeElement();\n      nodeElement.setModuleRevisionId(node.getResolvedId());\n      resolvedNodes.put(node.getResolvedId(), nodeElement);\n    }\n\n        for (Iterator<IvyNode> iter = dependencies.iterator(); iter.hasNext();) {\n      IvyNode node = iter.next();\n      if (node.getAllEvictingNodes() != null) {\n        continue;       }\n\n      IvyNodeElement nodeElement = resolvedNodes.get(node.getResolvedId());\n      IvyNodeCallers.Caller[] callers = node.getAllRealCallers();\n      for (int i = 0; i < callers.length; i++) {\n        IvyNodeElement caller = resolvedNodes.get(callers[i].getModuleRevisionId());\n        if (caller != null) {\n          nodeElement.addCaller(caller);\n          nodeElement.setCallerConfigurations(caller, callers[i].getCallerConfigurations());\n        }\n      }\n    }\n\n    IvyNode[] evictions = report.getEvictedNodes();\n    for (int i = 0; i < evictions.length; i++) {\n      IvyNode eviction = evictions[i];\n      IvyNodeElement evictionElement = new IvyNodeElement();\n      evictionElement.setModuleRevisionId(eviction.getResolvedId());\n      evictionElement.setEvicted(true);\n\n      IvyNodeCallers.Caller[] callers = eviction.getAllCallers();\n      for (int j = 0; j < callers.length; j++) {\n        IvyNodeElement caller = resolvedNodes.get(callers[j].getModuleRevisionId());\n        if (caller != null) {\n          evictionElement.addCaller(caller);\n          evictionElement.setCallerConfigurations(caller, callers[j].getCallerConfigurations());\n        }\n      }\n    }\n\n        root.setDepth(0);\n    findConflictsBeneathNode(root);\n\n    return root;\n  }
367	private String getModuleName(File ivyXmlFile) {\n    String path = ivyXmlFile.getAbsolutePath();\n    Matcher matcher = PROPERTY_PREFIX_FROM_IVY_XML_FILE_PATTERN.matcher(path);\n    if ( ! matcher.find()) {\n      throw new BuildException("Can't get module name from ivy.xml path: " + path);\n    }\n    StringBuilder builder = new StringBuilder();\n    builder.append(matcher.group(1));\n    if (null != matcher.group(2)) {       builder.append("-analyzers");\n    } else if (null != matcher.group(3)) {       builder.append("-example");\n    } else if (null != matcher.group(4)) {       builder.append("-server");\n    }\n    builder.append('-');\n    builder.append(matcher.group(5));\n    return builder.toString().replace("solr-solr-", "solr-");\n  }
368	public final synchronized long getRecomputedActualSizeInBytes() throws IOException {\n    if (!(in instanceof RAMDirectory))\n      return sizeInBytes();\n    long size = 0;\n    for (final RAMFile file : ((RAMDirectory)in).fileMap.values())\n      size += file.length;\n    return size;\n  }
369	public synchronized void crash() throws IOException {\n    openFiles = new HashMap<>();\n    openFilesForWrite = new HashSet<>();\n    openFilesDeleted = new HashSet<>();\n            Map<Closeable,Exception> m = new IdentityHashMap<>(openFileHandles);\n    for (Closeable f : m.keySet()) {\n      try {\n        f.close();\n      } catch (Exception ignored) {}\n    }\n    corruptFiles(unSyncedFiles);\n    crashed = true;\n    unSyncedFiles = new HashSet<>();\n  }
370	public long deleteDocuments(Query... queries) throws IOException {\n    ensureOpen();\n\n        for(Query query : queries) {\n      if (query.getClass() == MatchAllDocsQuery.class) {\n        return deleteAll();\n      }\n    }\n\n    try {\n      long seqNo = docWriter.deleteQueries(queries);\n      if (seqNo < 0) {\n        seqNo = -seqNo;\n        processEvents(true, false);\n      }\n\n      return seqNo;\n    } catch (VirtualMachineError tragedy) {\n      tragicEvent(tragedy, "deleteDocuments(Query..)");\n\n            return -1;\n    }\n  }
371	void deleteNewFiles(Collection<String> files) throws IOException {\n    assert locked();\n    Set<String> toDelete = new HashSet<>();\n    for (final String fileName: files) {\n                                          if (!refCounts.containsKey(fileName) || refCounts.get(fileName).count == 0) {\n        if (infoStream.isEnabled("IFD")) {\n          infoStream.message("IFD", "will delete new file \"" + fileName + "\"");\n        }\n        toDelete.add(fileName);\n      }\n    }\n\n    deleteFiles(toDelete);\n  }
372	public int readNextArcLabel(Arc<T> arc, BytesReader in) throws IOException {\n    assert !arc.isLast();\n\n    if (arc.label == END_LABEL) {\n                  \n      long pos = arc.nextArc;\n      in.setPosition(pos);\n\n      final byte b = in.readByte();\n      if (b == ARCS_AS_FIXED_ARRAY) {\n                in.readVInt();\n\n                if (version >= VERSION_VINT_TARGET) {\n          in.readVInt();\n        } else {\n          in.readInt();\n        }\n      } else {\n        in.setPosition(pos);\n      }\n    } else {\n      if (arc.bytesPerArc != 0) {\n                        in.setPosition(arc.posArcsStart);\n        in.skipBytes((1+arc.arcIdx)*arc.bytesPerArc);\n      } else {\n                        in.setPosition(arc.nextArc);\n      }\n    }\n        in.readByte();\n    return readLabel(in);\n  }
373	public static void main(String[] args) throws Exception {\n    System.out.println("Sum associations example:");\n    System.out.println("-------------------------");\n    List<FacetResult> results = new AssociationsFacetsExample().runSumAssociations();\n    System.out.println("tags: " + results.get(0));\n    System.out.println("genre: " + results.get(1));\n  }
374	protected Query getBooleanQuery(List<BooleanClause> clauses) throws ParseException {\n    if (clauses.size()==0) {\n      return null;     }\n    BooleanQuery.Builder query = newBooleanQuery();\n    for(final BooleanClause clause: clauses) {\n      query.add(clause);\n    }\n    return query.build();\n  }
375	public static SortedDocValues wrap(SortedSetDocValues sortedSet, Type selector) {\n    if (sortedSet.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException("fields containing more than " + (Integer.MAX_VALUE-1) + " unique terms are unsupported");\n    }\n    \n    SortedDocValues singleton = DocValues.unwrapSingleton(sortedSet);\n    if (singleton != null) {\n                        return singleton;\n    } else {\n      switch(selector) {\n        case MIN: return new MinValue(sortedSet);\n        case MAX: return new MaxValue(sortedSet);\n        case MIDDLE_MIN: return new MiddleMinValue(sortedSet);\n        case MIDDLE_MAX: return new MiddleMaxValue(sortedSet);\n        default: \n          throw new AssertionError();\n      }\n    }\n  }
376	private void reorder(int from, int to, int[] startOffsets, int[] endOffsets, int k) {\n        for (int i = 0; i < HISTOGRAM_SIZE; ++i) {\n      final int limit = endOffsets[i];\n      for (int h1 = startOffsets[i]; h1 < limit; h1 = startOffsets[i]) {\n        final int b = getBucket(from + h1, k);\n        final int h2 = startOffsets[b]++;\n        swap(from + h1, from + h2);\n      }\n    }\n  }
377	private boolean fileIsIdentical(String fileName, FileMetaData srcMetaData) throws IOException {\n\n    FileMetaData destMetaData = readLocalFileMetaData(fileName);\n    if (destMetaData == null) {\n            return false;\n    }\n\n    if (Arrays.equals(destMetaData.header, srcMetaData.header) == false ||\n        Arrays.equals(destMetaData.footer, srcMetaData.footer) == false) {\n            if (Node.VERBOSE_FILES) {\n        message("file " + fileName + ": will copy [header/footer is different]");\n      }\n      return false;\n    } else {\n      return true;\n    }\n  }
378	protected int isGeoAreaShapeInsideShape(final GeoShape geoshape)  {\n    boolean foundOutside = false;\n    boolean foundInside = false;\n    for (GeoPoint p : getEdgePoints()) {\n      if (geoshape.isWithin(p)) {\n        foundInside = true;\n      } else {\n        foundOutside = true;\n      }\n      if (foundInside && foundOutside) {\n        return SOME_INSIDE;\n      }\n    }\n    if (!foundInside && !foundOutside)\n      return NONE_INSIDE;\n    if (foundInside && !foundOutside)\n      return ALL_INSIDE;\n    if (foundOutside && !foundInside)\n      return NONE_INSIDE;\n    return SOME_INSIDE;\n  }
379	void setText(char text[], int length) {\n    this.text = text;\n    this.length = this.endBounds = length;\n    current = startBounds = end = 0;\n    skipPossessive = hasFinalPossessive = false;\n    setBounds();\n  }
380	public synchronized final long getRecomputedSizeInBytes() throws IOException {\n    if (!(in instanceof RAMDirectory))\n      return sizeInBytes();\n    long size = 0;\n    for(final RAMFile file: ((RAMDirectory)in).fileMap.values()) {\n      size += file.ramBytesUsed();\n    }\n    return size;\n  }
381	private void addTermFrequencies(Reader r, Map<String, Map<String, Int>> perFieldTermFrequencies, String fieldName)\n      throws IOException {\n    if (analyzer == null) {\n      throw new UnsupportedOperationException("To use MoreLikeThis without " +\n          "term vectors, you must provide an Analyzer");\n    }\n    Map<String, Int> termFreqMap = perFieldTermFrequencies.get(fieldName);\n    if (termFreqMap == null) {\n      termFreqMap = new HashMap<>();\n      perFieldTermFrequencies.put(fieldName, termFreqMap);\n    }\n    try (TokenStream ts = analyzer.tokenStream(fieldName, r)) {\n      int tokenCount = 0;\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      ts.reset();\n      while (ts.incrementToken()) {\n        String word = termAtt.toString();\n        tokenCount++;\n        if (tokenCount > maxNumTokensParsed) {\n          break;\n        }\n        if (isNoiseWord(word)) {\n          continue;\n        }\n\n                Int cnt = termFreqMap.get(word);\n        if (cnt == null) {\n          termFreqMap.put(word, new Int());\n        } else {\n          cnt.x++;\n        }\n      }\n      ts.end();\n    }\n  }
382	private void appendAllInternalDependencies(StringBuilder builder) {\n    for (String artifactId : internalCompileScopeDependencies.keySet()) {\n      List<String> exclusions = new ArrayList<>();\n      exclusions.addAll(internalCompileScopeDependencies.get(artifactId));\n      SortedSet<ExternalDependency> extDeps = allExternalDependencies.get(artifactId);\n      if (null != extDeps) {\n        for (ExternalDependency externalDependency : extDeps) {\n          if ( ! externalDependency.isTestDependency && ! externalDependency.isOptional) {\n            exclusions.add(externalDependency.groupId + ':' + externalDependency.artifactId);\n          }\n        }\n      }\n      String groupId = ivyModuleInfo.get(artifactId);\n      appendDependencyXml(builder, groupId, artifactId, "      ", "${project.version}", false, false, null, exclusions);\n    }\n  }
383	public String[] retrieveInterestingTerms(Reader r, String fieldName) throws IOException {\n    ArrayList<Object> al = new ArrayList<>(maxQueryTerms);\n    PriorityQueue<ScoreTerm> pq = retrieveTerms(r, fieldName);\n    ScoreTerm scoreTerm;\n    int lim = maxQueryTerms;         while (((scoreTerm = pq.pop()) != null) && lim-- > 0) {\n      al.add(scoreTerm.word);     }\n    String[] res = new String[al.size()];\n    return al.toArray(res);\n  }
384	public static double calcDistanceFromErrPct(Shape shape, double distErrPct, SpatialContext ctx) {\n    if (distErrPct < 0 || distErrPct > 0.5) {\n      throw new IllegalArgumentException("distErrPct " + distErrPct + " must be between [0 to 0.5]");\n    }\n    if (distErrPct == 0 || shape instanceof Point) {\n      return 0;\n    }\n    Rectangle bbox = shape.getBoundingBox();\n                Point ctr = bbox.getCenter();\n    double y = (ctr.getY() >= 0 ? bbox.getMaxY() : bbox.getMinY());\n    double diagonalDist = ctx.getDistCalc().distance(ctr, bbox.getMaxX(), y);\n    return diagonalDist * distErrPct;\n  }
385	private boolean isNoiseWord(String term) {\n    int len = term.length();\n    if (minWordLen > 0 && len < minWordLen) {\n      return true;\n    }\n    if (maxWordLen > 0 && len > maxWordLen) {\n      return true;\n    }\n    return stopWords != null && stopWords.contains(term);\n  }
386	private boolean stretchToOrder() throws IOException {\n    Spans prevSpans = subSpans[0];\n    matchStart = prevSpans.startPosition();\n    assert prevSpans.startPosition() != NO_MORE_POSITIONS : "prevSpans no start position "+prevSpans;\n    assert prevSpans.endPosition() != NO_MORE_POSITIONS;\n    matchWidth = 0;\n    for (int i = 1; i < subSpans.length; i++) {\n      Spans spans = subSpans[i];\n      assert spans.startPosition() != NO_MORE_POSITIONS;\n      assert spans.endPosition() != NO_MORE_POSITIONS;\n      if (advancePosition(spans, prevSpans.endPosition()) == NO_MORE_POSITIONS) {\n        oneExhaustedInCurrentDoc = true;\n        return false;\n      }\n      matchWidth += (spans.startPosition() - prevSpans.endPosition());\n      prevSpans = spans;\n    }\n    matchEnd = subSpans[subSpans.length - 1].endPosition();\n    return true;   }
387	protected int minFrequencyToCache(Query query) {\n    if (isCostly(query)) {\n      return 2;\n    } else {\n            int minFrequency = 5;\n      if (query instanceof BooleanQuery\n          || query instanceof DisjunctionMaxQuery) {\n                                                minFrequency--;\n      }\n      return minFrequency;\n    }\n  }
388	protected static CharArraySet loadStopwordSet(final boolean ignoreCase,\n      final Class<? extends Analyzer> aClass, final String resource,\n      final String comment) throws IOException {\n    Reader reader = null;\n    try {\n      reader = IOUtils.getDecodingReader(aClass.getResourceAsStream(resource), StandardCharsets.UTF_8);\n      return WordlistLoader.getWordSet(reader, comment, new CharArraySet(16, ignoreCase));\n    } finally {\n      IOUtils.close(reader);\n    }\n    \n  }
389	public void add(long v) throws IOException {\n    if (v < previous) {\n      throw new IllegalArgumentException("Values do not come in order: " + previous + ", " + v);\n    }\n    if (bufferSize == buffer.length) {\n      flush();\n    }\n    buffer[bufferSize++] = v;\n    previous = v;\n    count++;\n  }
390	public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n            Automaton automaton = null;\n    try {\n                        final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n                        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n      tsta.setUnicodeArcs(unicodeAware);\n\n      automaton = tsta.toAutomaton(inputTokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(inputTokenStream);\n    }\n\n            automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n        return Operations.determinize(automaton, maxGraphExpansions);\n  }
391	private Arc<T> findTargetArc(int labelToMatch, Arc<T> follow, Arc<T> arc, BytesReader in, boolean useRootArcCache) throws IOException {\n\n    if (labelToMatch == END_LABEL) {\n      if (follow.isFinal()) {\n        if (follow.target <= 0) {\n          arc.flags = BIT_LAST_ARC;\n        } else {\n          arc.flags = 0;\n                    arc.nextArc = follow.target;\n        }\n        arc.output = follow.nextFinalOutput;\n        arc.label = END_LABEL;\n        return arc;\n      } else {\n        return null;\n      }\n    }\n\n        if (useRootArcCache && cachedRootArcs != null && follow.target == startNode && labelToMatch < cachedRootArcs.length) {\n      final Arc<T> result = cachedRootArcs[labelToMatch];\n\n                  assert assertRootCachedArc(labelToMatch, result);\n\n      if (result == null) {\n        return null;\n      } else {\n        arc.copyFrom(result);\n        return arc;\n      }\n    }\n\n    if (!targetHasArcs(follow)) {\n      return null;\n    }\n\n    in.setPosition(follow.target);\n\n    \n    if (in.readByte() == ARCS_AS_FIXED_ARRAY) {\n            arc.numArcs = in.readVInt();\n      if (version >= VERSION_VINT_TARGET) {\n        arc.bytesPerArc = in.readVInt();\n      } else {\n        arc.bytesPerArc = in.readInt();\n      }\n      arc.posArcsStart = in.getPosition();\n      int low = 0;\n      int high = arc.numArcs-1;\n      while (low <= high) {\n                int mid = (low + high) >>> 1;\n        in.setPosition(arc.posArcsStart);\n        in.skipBytes(arc.bytesPerArc*mid + 1);\n        int midLabel = readLabel(in);\n        final int cmp = midLabel - labelToMatch;\n        if (cmp < 0) {\n          low = mid + 1;\n        } else if (cmp > 0) {\n          high = mid - 1;\n        } else {\n          arc.arcIdx = mid-1;\n                    return readNextRealArc(arc, in);\n        }\n      }\n\n      return null;\n    }\n\n        readFirstRealTargetArc(follow.target, arc, in);\n\n    while(true) {\n                              if (arc.label == labelToMatch) {\n                return arc;\n      } else if (arc.label > labelToMatch) {\n        return null;\n      } else if (arc.isLast()) {\n        return null;\n      } else {\n        readNextRealArc(arc, in);\n      }\n    }\n  }
392	private boolean doNext() throws IOException {\n    if (loneState != null) {\n      restoreState(loneState);\n      loneState = null;\n      return true;\n    } else {\n      if (exhausted) {\n        return false;\n      } else if (input.incrementToken()) {\n        return true;\n      } else {\n        exhausted = true;\n        return false;\n      }\n    }\n  }
393	public static CharArraySet getWordSet(Reader reader, String comment, CharArraySet result) throws IOException {\n    BufferedReader br = null;\n    try {\n      br = getBufferedReader(reader);\n      String word = null;\n      while ((word = br.readLine()) != null) {\n        if (word.startsWith(comment) == false){\n          result.add(word.trim());\n        }\n      }\n    }\n    finally {\n      IOUtils.close(br);\n    }\n    return result;\n  }
394	public static void assertVocabulary(Analyzer a, Path zipFile, String voc, String out) throws IOException {\n    Path tmp = LuceneTestCase.createTempDir();\n    try (InputStream in = Files.newInputStream(zipFile)) {\n      TestUtil.unzip(in, tmp);\n    }\n    try (InputStream v = Files.newInputStream(tmp.resolve(voc)); \n         InputStream o = Files.newInputStream(tmp.resolve(out))) {\n      assertVocabulary(a, v, o);\n    }\n  }
395	public static String pathToString(String[] path, int length) {\n    if (length == 0) {\n      return "";\n    }\n    StringBuilder sb = new StringBuilder();\n    for(int i=0;i<length;i++) {\n      String s = path[i];\n      if (s.length() == 0) {\n        throw new IllegalArgumentException("each path component must have length > 0 (got: \"\")");\n      }\n      int numChars = s.length();\n      for(int j=0;j<numChars;j++) {\n        char ch = s.charAt(j);\n        if (ch == DELIM_CHAR || ch == ESCAPE_CHAR) {\n          sb.append(ESCAPE_CHAR);\n        }\n        sb.append(ch);\n      }\n      sb.append(DELIM_CHAR);\n    }\n\n        sb.setLength(sb.length()-1);\n    return sb.toString();\n  }
396	boolean stem(char[] term, int len) {\n    \n    result = null;\n    \n    k = len - 1;\n    if ((k <= 1) || (k >= MaxWordLen - 1)) {\n      return false;     }\n    \n            DictEntry entry = dict_ht.get(term, 0, len);\n    if (entry != null) {\n      if (entry.root != null) {\n        result = entry.root;\n        return true;\n      }\n      return false;\n    }\n    \n    \n    \n    word.reset();\n        word.reserve(len + 10);\n    for (int i = 0; i < len; i++) {\n      char ch = term[i];\n      if (!isAlpha(ch)) return false;                   word.unsafeWrite(ch);\n    }\n    \n    matchedEntry = null;\n    \n    \n    \n    while (true) {\n                  plural();\n      if (matched()) break;\n      pastTense();\n      if (matched()) break;\n      aspect();\n      if (matched()) break;\n      ityEndings();\n      if (matched()) break;\n      nessEndings();\n      if (matched()) break;\n      ionEndings();\n      if (matched()) break;\n      erAndOrEndings();\n      if (matched()) break;\n      lyEndings();\n      if (matched()) break;\n      alEndings();\n      if (matched()) break;\n      entry = wordInDict();\n      iveEndings();\n      if (matched()) break;\n      izeEndings();\n      if (matched()) break;\n      mentEndings();\n      if (matched()) break;\n      bleEndings();\n      if (matched()) break;\n      ismEndings();\n      if (matched()) break;\n      icEndings();\n      if (matched()) break;\n      ncyEndings();\n      if (matched()) break;\n      nceEndings();\n      matched();\n      break;\n    }\n    \n    \n    entry = matchedEntry;\n    if (entry != null) {\n      result = entry.root;     }\n    \n    \n    \n    "CASE:"","\n    \n        return true;\n  }
397	private void generatePart(boolean isSingleWord) {\n    clearAttributes();\n    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);\n    int startOffset = savedStartOffset + iterator.current;\n    int endOffset = savedStartOffset + iterator.end;\n    \n    if (hasIllegalOffsets) {\n                  if (isSingleWord && startOffset <= savedEndOffset) {\n        offsetAttribute.setOffset(startOffset, savedEndOffset);\n      } else {\n        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n      }\n    } else {\n      offsetAttribute.setOffset(startOffset, endOffset);\n    }\n    posIncAttribute.setPositionIncrement(position(false));\n    typeAttribute.setType(savedType);\n  }
398	public static FixedBitSet ensureCapacity(FixedBitSet bits, int numBits) {\n    if (numBits < bits.numBits) {\n      return bits;\n    } else {\n                  int numWords = bits2words(numBits);\n      long[] arr = bits.getBits();\n      if (numWords >= arr.length) {\n        arr = ArrayUtil.grow(arr, numWords + 1);\n      }\n      return new FixedBitSet(arr, arr.length << 6);\n    }\n  }
399	public void writeInt(int i) throws IOException {\n    writeByte((byte)(i >> 24));\n    writeByte((byte)(i >> 16));\n    writeByte((byte)(i >>  8));\n    writeByte((byte) i);\n  }
400	private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Integer>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Integer>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n        seenPatterns.put(".*", 0);\n    patterns.add(null);\n    \n        Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put("", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n            if (reader.getLineNumber() == 1 && line.startsWith("\uFEFF")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(MORPH_ALIAS_KEY)) {\n        parseMorphAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n                        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true;       } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split("\\s+");\n        if (parts.length != 2) {\n          throw new ParseException("Illegal CIRCUMFIX declaration", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(KEEPCASE_KEY)) {\n        String parts[] = line.split("\\s+");\n        if (parts.length != 2) {\n          throw new ParseException("Illegal KEEPCASE declaration", reader.getLineNumber());\n        }\n        keepcase = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(NEEDAFFIX_KEY) || line.startsWith(PSEUDOROOT_KEY)) {\n        String parts[] = line.split("\\s+");\n        if (parts.length != 2) {\n          throw new ParseException("Illegal NEEDAFFIX declaration", reader.getLineNumber());\n        }\n        needaffix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(ONLYINCOMPOUND_KEY)) {\n        String parts[] = line.split("\\s+");\n        if (parts.length != 2) {\n          throw new ParseException("Illegal ONLYINCOMPOUND declaration", reader.getLineNumber());\n        }\n        onlyincompound = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split("\\s+");\n        if (parts.length != 2) {\n          throw new ParseException("Illegal IGNORE declaration", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split("\\s+");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException("Illegal " + type + " declaration", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals("ICONV")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      } else if (line.startsWith(FULLSTRIP_KEY)) {\n        fullStrip = true;\n      } else if (line.startsWith(LANG_KEY)) {\n        language = line.substring(LANG_KEY.length()).trim();\n        alternateCasing = "tr_TR".equals(language) || "az_AZ".equals(language);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }
401	void skipBlock(IndexInput in) throws IOException {\n    final int numBits = in.readByte();\n    if (numBits == ALL_VALUES_EQUAL) {\n      in.readVInt();\n      return;\n    }\n    assert numBits > 0 && numBits <= 32 : numBits;\n    final int encodedSize = encodedSizes[numBits];\n    in.seek(in.getFilePointer() + encodedSize);\n  }
402	public void exorciseIndex(Status result) throws IOException {\n    ensureOpen();\n    if (result.partial) {\n      throw new IllegalArgumentException("can only exorcise an index that was fully checked (this status checked a subset of segments)");\n    }\n    result.newSegments.changed();\n    result.newSegments.commit(result.dir);\n  }
403	private void gramToken() {\n    buffer.append(termAttribute.buffer(), 0, termAttribute.length());\n    int endOffset = offsetAttribute.endOffset();\n\n    clearAttributes();\n\n    int length = buffer.length();\n    char termText[] = termAttribute.buffer();\n    if (length > termText.length) {\n      termText = termAttribute.resizeBuffer(length);\n    }\n    \n    buffer.getChars(0, length, termText, 0);\n    termAttribute.setLength(length);\n    posIncAttribute.setPositionIncrement(0);\n    posLenAttribute.setPositionLength(2);     offsetAttribute.setOffset(lastStartOffset, endOffset);\n    typeAttribute.setType(GRAM_TYPE);\n    buffer.setLength(0);\n  }
404	public static List<String> getLines(InputStream stream, Charset charset) throws IOException{\n    BufferedReader input = null;\n    ArrayList<String> lines;\n    boolean success = false;\n    try {\n      input = getBufferedReader(IOUtils.getDecodingReader(stream, charset));\n\n      lines = new ArrayList<>();\n      for (String word=null; (word=input.readLine())!=null;) {\n                if (lines.isEmpty() && word.length() > 0 && word.charAt(0) == '\uFEFF')\n          word = word.substring(1);\n                if (word.startsWith("#")) continue;\n        word=word.trim();\n                if (word.length()==0) continue;\n        lines.add(word);\n      }\n      success = true;\n      return lines;\n    } finally {\n      if (success) {\n        IOUtils.close(input);\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }
405	public void clearQuery(Query query) {\n    lock.lock();\n    try {\n      final Query singleton = uniqueQueries.remove(query);\n      if (singleton != null) {\n        onEviction(singleton);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }
406	public void waitApplyAll() throws IOException {\n\n    assert Thread.holdsLock(writer) == false;\n    \n    final long t0 = System.nanoTime();\n\n    Set<FrozenBufferedUpdates> waitFor;\n    synchronized (this) {\n      waitFor = new HashSet<>(updates);\n    }\n\n    waitApply(waitFor);\n  }
407	public Map<String, String[]> highlightFields(String[] fields, Query query, TopDocs topDocs, int[] maxPassages)\n      throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, docids, maxPassages);\n  }
408	public boolean eat(Row in, int remap[]) {\n    int sum = 0;\n    for (Iterator<Cell> i = in.cells.values().iterator(); i.hasNext();) {\n      Cell c = i.next();\n      sum += c.cnt;\n      if (c.ref >= 0) {\n        if (remap[c.ref] == 0) {\n          c.ref = -1;\n        }\n      }\n    }\n    int frame = sum / 10;\n    boolean live = false;\n    for (Iterator<Cell> i = in.cells.values().iterator(); i.hasNext();) {\n      Cell c = i.next();\n      if (c.cnt < frame && c.cmd >= 0) {\n        c.cnt = 0;\n        c.cmd = -1;\n      }\n      if (c.cmd >= 0 || c.ref >= 0) {\n        live |= true;\n      }\n    }\n    return !live;\n  }
409	public void forceMerge(int maxNumSegments, boolean doWait) throws IOException {\n    ensureOpen();\n\n    if (maxNumSegments < 1) {\n      throw new IllegalArgumentException("maxNumSegments must be >= 1; got " + maxNumSegments);\n    }\n\n    if (infoStream.isEnabled("IW")) {\n      infoStream.message("IW", "forceMerge: index now " + segString());\n      infoStream.message("IW", "now flush at forceMerge");\n    }\n    flush(true, true);\n    synchronized(this) {\n      resetMergeExceptions();\n      segmentsToMerge.clear();\n      for(SegmentCommitInfo info : segmentInfos) {\n        assert info != null;\n        segmentsToMerge.put(info, Boolean.TRUE);\n      }\n      mergeMaxNumSegments = maxNumSegments;\n\n                  for(final MergePolicy.OneMerge merge  : pendingMerges) {\n        merge.maxNumSegments = maxNumSegments;\n        if (merge.info != null) {\n                    segmentsToMerge.put(merge.info, Boolean.TRUE);\n        }\n      }\n\n      for (final MergePolicy.OneMerge merge: runningMerges) {\n        merge.maxNumSegments = maxNumSegments;\n        if (merge.info != null) {\n                    segmentsToMerge.put(merge.info, Boolean.TRUE);\n        }\n      }\n    }\n\n    maybeMerge(config.getMergePolicy(), MergeTrigger.EXPLICIT, maxNumSegments);\n\n    if (doWait) {\n      synchronized(this) {\n        while(true) {\n\n          if (tragedy != null) {\n            throw new IllegalStateException("this writer hit an unrecoverable error; cannot complete forceMerge", tragedy);\n          }\n\n          if (mergeExceptions.size() > 0) {\n                                    final int size = mergeExceptions.size();\n            for(int i=0;i<size;i++) {\n              final MergePolicy.OneMerge merge = mergeExceptions.get(i);\n              if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS) {\n                throw new IOException("background merge hit exception: " + merge.segString(), merge.getException());\n              }\n            }\n          }\n\n          if (maxNumSegmentsMergesPending())\n            doWait();\n          else\n            break;\n        }\n      }\n\n                              ensureOpen();\n    }\n              }
410	public static CharArraySet unmodifiableSet(CharArraySet set) {\n    if (set == null)\n      throw new NullPointerException("Given set is null");\n    if (set == EMPTY_SET)\n      return EMPTY_SET;\n    if (set.map instanceof CharArrayMap.UnmodifiableCharArrayMap)\n      return set;\n    return new CharArraySet(CharArrayMap.unmodifiableMap(set.map));\n  }
411	private float phraseFreq() throws IOException {\n    if (!initPhrasePositions()) {\n      return 0.0f;\n    }\n    float freq = 0.0f;\n    numMatches = 0;\n    PhrasePositions pp = pq.pop();\n    int matchLength = end - pp.position;\n    int next = pq.top().position; \n    while (advancePP(pp)) {\n      if (hasRpts && !advanceRpts(pp)) {\n        break;       }\n      if (pp.position > next) {         if (matchLength <= slop) {\n          freq += docScorer.computeSlopFactor(matchLength);           numMatches++;\n          if (!needsScores) {\n            return freq;\n          }\n        }      \n        pq.add(pp);\n        pp = pq.pop();\n        next = pq.top().position;\n        matchLength = end - pp.position;\n      } else {\n        int matchLength2 = end - pp.position;\n        if (matchLength2 < matchLength) {\n          matchLength = matchLength2;\n        }\n      }\n    }\n    if (matchLength <= slop) {\n      freq += docScorer.computeSlopFactor(matchLength);       numMatches++;\n    }    \n    return freq;\n  }
412	public void add(IntsRef input, T output) throws IOException {\n    "\nFST ADD: input="" ""\nFST ADD: input="" "" output="\n\n        if (output.equals(NO_OUTPUT)) {\n      output = NO_OUTPUT;\n    }\n\n    assert lastInput.length() == 0 || input.compareTo(lastInput.get()) >= 0: "inputs are added out of order lastInput=" + lastInput.get() + " vs input=" + input;\n    assert validOutput(output);\n\n        if (input.length == 0) {\n                                    frontier[0].inputCount++;\n      frontier[0].isFinal = true;\n      fst.setEmptyOutput(output);\n      return;\n    }\n\n        int pos1 = 0;\n    int pos2 = input.offset;\n    final int pos1Stop = Math.min(lastInput.length(), input.length);\n    while(true) {\n      frontier[pos1].inputCount++;\n            if (pos1 >= pos1Stop || lastInput.intAt(pos1) != input.ints[pos2]) {\n        break;\n      }\n      pos1++;\n      pos2++;\n    }\n    final int prefixLenPlus1 = pos1+1;\n      \n    if (frontier.length < input.length+1) {\n      final UnCompiledNode<T>[] next = ArrayUtil.grow(frontier, input.length+1);\n      for(int idx=frontier.length;idx<next.length;idx++) {\n        next[idx] = new UnCompiledNode<>(this, idx);\n      }\n      frontier = next;\n    }\n\n            freezeTail(prefixLenPlus1);\n\n        for(int idx=prefixLenPlus1;idx<=input.length;idx++) {\n      frontier[idx-1].addArc(input.ints[input.offset + idx - 1],\n                             frontier[idx]);\n      frontier[idx].inputCount++;\n    }\n\n    final UnCompiledNode<T> lastNode = frontier[input.length];\n    if (lastInput.length() != input.length || prefixLenPlus1 != input.length + 1) {\n      lastNode.isFinal = true;\n      lastNode.output = NO_OUTPUT;\n    }\n\n            for(int idx=1;idx<prefixLenPlus1;idx++) {\n      final UnCompiledNode<T> node = frontier[idx];\n      final UnCompiledNode<T> parentNode = frontier[idx-1];\n\n      final T lastOutput = parentNode.getLastOutput(input.ints[input.offset + idx - 1]);\n      assert validOutput(lastOutput);\n\n      final T commonOutputPrefix;\n      final T wordSuffix;\n\n      if (lastOutput != NO_OUTPUT) {\n        commonOutputPrefix = fst.outputs.common(output, lastOutput);\n        assert validOutput(commonOutputPrefix);\n        wordSuffix = fst.outputs.subtract(lastOutput, commonOutputPrefix);\n        assert validOutput(wordSuffix);\n        parentNode.setLastOutput(input.ints[input.offset + idx - 1], commonOutputPrefix);\n        node.prependOutput(wordSuffix);\n      } else {\n        commonOutputPrefix = wordSuffix = NO_OUTPUT;\n      }\n\n      output = fst.outputs.subtract(output, commonOutputPrefix);\n      assert validOutput(output);\n    }\n\n    if (lastInput.length() == input.length && prefixLenPlus1 == 1+input.length) {\n                  lastNode.output = fst.outputs.merge(lastNode.output, output);\n    } else {\n                  frontier[prefixLenPlus1-1].setLastOutput(input.ints[input.offset + prefixLenPlus1-1], output);\n    }\n\n        lastInput.copyInts(input);\n\n      }
413	public void clearIndex() throws IOException {\n    synchronized (modifyCurrentIndexLock) {\n      ensureOpen();\n      final Directory dir = this.spellIndex;\n      final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(null)\n          .setOpenMode(OpenMode.CREATE));\n      writer.close();\n      swapSearcher(dir);\n    }\n  }
414	public static long deinterleave(long b) {\n    b &= MAGIC[0];\n    b = (b ^ (b >>> SHIFT[0])) & MAGIC[1];\n    b = (b ^ (b >>> SHIFT[1])) & MAGIC[2];\n    b = (b ^ (b >>> SHIFT[2])) & MAGIC[3];\n    b = (b ^ (b >>> SHIFT[3])) & MAGIC[4];\n    b = (b ^ (b >>> SHIFT[4])) & MAGIC[5];\n    return b;\n  }
415	public static void assertVocabulary(Analyzer a, InputStream vocOut)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(vocOut, StandardCharsets.UTF_8));\n    String inputLine = null;\n    while ((inputLine = vocReader.readLine()) != null) {\n      if (inputLine.startsWith("#") || inputLine.trim().length() == 0)\n        continue; \n      String words[] = inputLine.split("\t");\n      BaseTokenStreamTestCase.checkOneTerm(a, words[0], words[1]);\n    }\n  }
416	public double surfaceDistance(final GeoPoint pt1, final GeoPoint pt2) {\n    final double L = pt2.getLongitude() - pt1.getLongitude();\n    final double U1 = Math.atan((1.0-flattening) * Math.tan(pt1.getLatitude()));\n    final double U2 = Math.atan((1.0-flattening) * Math.tan(pt2.getLatitude()));\n\n    final double sinU1 = Math.sin(U1);\n    final double cosU1 = Math.cos(U1);\n    final double sinU2 = Math.sin(U2);\n    final double cosU2 = Math.cos(U2);\n\n    final double dCosU1CosU2 = cosU1 * cosU2;\n    final double dCosU1SinU2 = cosU1 * sinU2;\n\n    final double dSinU1SinU2 = sinU1 * sinU2;\n    final double dSinU1CosU2 = sinU1 * cosU2;\n\n\n    double lambda = L;\n    double lambdaP = Math.PI * 2.0;\n    int iterLimit = 0;\n    double cosSqAlpha;\n    double sinSigma;\n    double cos2SigmaM;\n    double cosSigma;\n    double sigma;\n    double sinAlpha;\n    double C;\n    double sinLambda, cosLambda;\n\n    do {\n      sinLambda = Math.sin(lambda);\n      cosLambda = Math.cos(lambda);\n      sinSigma = Math.sqrt((cosU2*sinLambda) * (cosU2*sinLambda) +\n                                    (dCosU1SinU2 - dSinU1CosU2 * cosLambda) * (dCosU1SinU2 - dSinU1CosU2 * cosLambda));\n\n      if (sinSigma==0.0) {\n        return 0.0;\n      }\n      cosSigma = dSinU1SinU2 + dCosU1CosU2 * cosLambda;\n      sigma = Math.atan2(sinSigma, cosSigma);\n      sinAlpha = dCosU1CosU2 * sinLambda / sinSigma;\n      cosSqAlpha = 1.0 - sinAlpha * sinAlpha;\n      cos2SigmaM = cosSigma - 2.0 * dSinU1SinU2 / cosSqAlpha;\n\n      if (Double.isNaN(cos2SigmaM))\n        cos2SigmaM = 0.0;        C = flattening / 16.0 * cosSqAlpha * (4.0 + flattening * (4.0 - 3.0 * cosSqAlpha));\n      lambdaP = lambda;\n      lambda = L + (1.0 - C) * flattening * sinAlpha *\n        (sigma + C * sinSigma * (cos2SigmaM + C * cosSigma * (-1.0 + 2.0 * cos2SigmaM *cos2SigmaM)));\n    } while (Math.abs(lambda-lambdaP) >= Vector.MINIMUM_RESOLUTION && ++iterLimit < 100);\n    final double uSq = cosSqAlpha * this.squareRatio;\n    final double A = 1.0 + uSq / 16384.0 * (4096.0 + uSq * (-768.0 + uSq * (320.0 - 175.0 * uSq)));\n    final double B = uSq / 1024.0 * (256.0 + uSq * (-128.0 + uSq * (74.0 - 47.0 * uSq)));\n    final double deltaSigma = B * sinSigma * (cos2SigmaM + B / 4.0 * (cosSigma * (-1.0 + 2.0 * cos2SigmaM * cos2SigmaM)-\n                                        B / 6.0 * cos2SigmaM * (-3.0 + 4.0 * sinSigma * sinSigma) * (-3.0 + 4.0 * cos2SigmaM * cos2SigmaM)));\n\n    return c * inverseScale * A * (sigma - deltaSigma);\n  }
417	protected String tableTitle (String longestOp) {\n    StringBuilder sb = new StringBuilder();\n    sb.append(Format.format(OP,longestOp));\n    sb.append(ROUND);\n    sb.append(getRunData().getConfig().getColsNamesForValsByRound());\n    for (int i = 0; i < COLS.length; i++) {\n      sb.append(COLS[i]);\n    }\n    return sb.toString(); \n  }
418	boolean makeRoomLRU() {\n    if (!isCacheFull()) {\n      return false;\n    }\n    int n = cache.size() - (2*maxCacheSize)/3;\n    if (n<=0) {\n      return false;\n    }\n    Iterator<Object> it = cache.keySet().iterator();\n    int i = 0;\n    while (i<n && it.hasNext()) {\n      it.next();\n      it.remove();\n      i++;\n    }\n    return true;\n  }
419	static boolean positionsOrdered(Spans spans1, Spans spans2) {\n    assert spans1.docID() == spans2.docID() : "doc1 " + spans1.docID() + " != doc2 " + spans2.docID();\n    int start1 = spans1.startPosition();\n    int start2 = spans2.startPosition();\n    return (start1 == start2) ? (spans1.endPosition() < spans2.endPosition()) : (start1 < start2);\n  }
420	private int getMaxTopNSearcherQueueSize(int topN, int numDocs, double liveDocsRatio, boolean filterEnabled) {\n    long maxQueueSize = topN * maxAnalyzedPathsPerOutput;\n        assert liveDocsRatio <= 1.0d;\n    maxQueueSize = (long) (maxQueueSize / liveDocsRatio);\n    if (filterEnabled) {\n      maxQueueSize = maxQueueSize + (numDocs/2);\n    }\n    return (int) Math.min(MAX_TOP_N_QUEUE_SIZE, maxQueueSize);\n  }
421	void decRef(Collection<String> files) throws IOException {\n    assert locked();\n    Set<String> toDelete = new HashSet<>();\n    Throwable firstThrowable = null;\n    for(final String file : files) {\n      try {\n        if (decRef(file)) {\n          toDelete.add(file);\n        }\n      } catch (Throwable t) {\n        if (firstThrowable == null) {\n                    firstThrowable = t;\n        }\n      }\n    }\n\n    try {\n      deleteFiles(toDelete);\n    } catch (Throwable t) {\n      if (firstThrowable == null) {\n                firstThrowable = t;\n      }\n    }\n\n    if (firstThrowable != null) {\n      throw IOUtils.rethrowAlways(firstThrowable);\n    }\n  }
422	public void writeInt(long pos, int value) {\n    int blockIndex = (int) (pos >> blockBits);\n    int upto = (int) (pos & blockMask);\n    byte[] block = blocks.get(blockIndex);\n    int shift = 24;\n    for(int i=0;i<4;i++) {\n      block[upto++] = (byte) (value >> shift);\n      shift -= 8;\n      if (upto == blockSize) {\n        upto = 0;\n        blockIndex++;\n        block = blocks.get(blockIndex);\n      }\n    }\n  }
423	public static byte[] checkIndexHeaderID(DataInput in, byte[] expectedID) throws IOException {\n    byte id[] = new byte[StringHelper.ID_LENGTH];\n    in.readBytes(id, 0, id.length);\n    if (!Arrays.equals(id, expectedID)) {\n      throw new CorruptIndexException("file mismatch, expected id=" + StringHelper.idToString(expectedID) \n                                                         + ", got=" + StringHelper.idToString(id), in);\n    }\n    return id;\n  }
424	private Iterable<Map.Entry<String,String>> combinedCommitData(Iterable<Map.Entry<String,String>> commitData) {\n    Map<String,String> m = new HashMap<>();\n    if (commitData != null) {\n      for(Map.Entry<String,String> ent : commitData) {\n        m.put(ent.getKey(), ent.getValue());\n      }\n    }\n    m.put(INDEX_EPOCH, Long.toString(indexEpoch, 16));\n    return m.entrySet();\n  }
425	public int addByPoolOffset(int offset) {\n    assert bytesStart != null : "Bytesstart is null - not initialized";\n        int code = offset;\n    int hashPos = offset & hashMask;\n    int e = ids[hashPos];\n    if (e != -1 && bytesStart[e] != offset) {\n                  do {\n        code++;\n        hashPos = code & hashMask;\n        e = ids[hashPos];\n      } while (e != -1 && bytesStart[e] != offset);\n    }\n    if (e == -1) {\n            if (count >= bytesStart.length) {\n        bytesStart = bytesStartArray.grow();\n        assert count < bytesStart.length + 1 : "count: " + count + " len: "\n            + bytesStart.length;\n      }\n      e = count++;\n      bytesStart[e] = offset;\n      assert ids[hashPos] == -1;\n      ids[hashPos] = e;\n\n      if (count == hashHalfSize) {\n        rehash(2 * hashSize, false);\n      }\n      return e;\n    }\n    return -(e + 1);\n  }
426	public static PlanetObject readPlanetObject(final InputStream inputStream) throws IOException {\n    final PlanetModel pm = new PlanetModel(inputStream);\n    final SerializableObject so = readObject(pm, inputStream);\n    if (!(so instanceof PlanetObject)) {\n      throw new IOException("Type of object is not expected PlanetObject: "+so.getClass().getName());\n    }\n    return (PlanetObject)so;\n  }
427	public Status checkIndex(List<String> onlySegments) throws IOException {\n    ensureOpen();\n    long startNS = System.nanoTime();\n    NumberFormat nf = NumberFormat.getInstance(Locale.ROOT);\n    SegmentInfos sis = null;\n    Status result = new Status();\n    result.dir = dir;\n    String[] files = dir.listAll();\n    String lastSegmentsFile = SegmentInfos.getLastCommitSegmentsFileName(files);\n    if (lastSegmentsFile == null) {\n      throw new IndexNotFoundException("no segments* file found in " + dir + ": files: " + Arrays.toString(files));\n    }\n    try {\n                  sis = SegmentInfos.readCommit(dir, lastSegmentsFile);\n    } catch (Throwable t) {\n      if (failFast) {\n        throw IOUtils.rethrowAlways(t);\n      }\n      msg(infoStream, "ERROR: could not read any segments file in directory");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n        Version oldest = null;\n    Version newest = null;\n    String oldSegs = null;\n    for (SegmentCommitInfo si : sis) {\n      Version version = si.info.getVersion();\n      if (version == null) {\n                oldSegs = "pre-3.1";\n      } else {\n        if (oldest == null || version.onOrAfter(oldest) == false) {\n          oldest = version;\n        }\n        if (newest == null || version.onOrAfter(newest)) {\n          newest = version;\n        }\n      }\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getSegmentsFileName();\n        IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName, IOContext.READONCE);\n    } catch (Throwable t) {\n      if (failFast) {\n        throw IOUtils.rethrowAlways(t);\n      }\n      msg(infoStream, "ERROR: could not open segments file in directory");\n      if (infoStream != null) {\n        t.printStackTrace(infoStream);\n      }\n      result.cantOpenSegments = true;\n      return result;\n    }\n    try {\n       input.readInt();\n    } catch (Throwable t) {\n      if (failFast) {\n        throw IOUtils.rethrowAlways(t);\n      }\n      msg(infoStream, "ERROR: could not read segment file version in directory");\n      if (infoStream != null) {\n        t.printStackTrace(infoStream);\n      }\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = " userData=" + sis.getUserData();\n    } else {\n      userDataString = "";\n    }\n\n    String versionString = "";\n    if (oldSegs != null) {\n      if (newest != null) {\n        versionString = "versions=[" + oldSegs + " .. " + newest + "]";\n      } else {\n        versionString = "version=" + oldSegs;\n      }\n    } else if (newest != null) {       versionString = oldest.equals(newest) ? ( "version=" + oldest ) : ("versions=[" + oldest + " .. " + newest + "]");\n    }\n\n    msg(infoStream, "Segments file=" + segmentsFileName + " numSegments=" + numSegments\n        + " " + versionString + " id=" + StringHelper.idToString(sis.getId()) + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null) {\n        infoStream.print("\nChecking only these segments:");\n        for (String s : onlySegments) {\n          infoStream.print(" " + s);\n        }\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(infoStream, ":");\n    }\n\n\n\n    result.newSegments = sis.clone();\n    result.newSegments.clear();\n    result.maxSegmentName = -1;\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentCommitInfo info = sis.info(i);\n      long segmentName = Long.parseLong(info.info.name.substring(1), Character.MAX_RADIX);\n      if (segmentName > result.maxSegmentName) {\n        result.maxSegmentName = segmentName;\n      }\n      if (onlySegments != null && !onlySegments.contains(info.info.name)) {\n        continue;\n      }\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(infoStream, "  " + (1+i) + " of " + numSegments + ": name=" + info.info.name + " maxDoc=" + info.info.maxDoc());\n      segInfoStat.name = info.info.name;\n      segInfoStat.maxDoc = info.info.maxDoc();\n      \n      final Version version = info.info.getVersion();\n      if (info.info.maxDoc() <= 0) {\n        throw new RuntimeException("illegal number of documents: maxDoc=" + info.info.maxDoc());\n      }\n\n      int toLoseDocCount = info.info.maxDoc();\n\n      SegmentReader reader = null;\n      Sort previousIndexSort = null;\n\n      try {\n        msg(infoStream, "    version=" + (version == null ? "3.0" : version));\n        msg(infoStream, "    id=" + StringHelper.idToString(info.info.getId()));\n        final Codec codec = info.info.getCodec();\n        msg(infoStream, "    codec=" + codec);\n        segInfoStat.codec = codec;\n        msg(infoStream, "    compound=" + info.info.getUseCompoundFile());\n        segInfoStat.compound = info.info.getUseCompoundFile();\n        msg(infoStream, "    numFiles=" + info.files().size());\n        Sort indexSort = info.info.getIndexSort();\n        if (indexSort != null) {\n          msg(infoStream, "    sort=" + indexSort);\n          if (previousIndexSort != null) {\n            if (previousIndexSort.equals(indexSort) == false) {\n              throw new RuntimeException("index sort changed from " + previousIndexSort + " to " + indexSort);\n            }\n          } else {\n            previousIndexSort = indexSort;\n          }\n        }\n        segInfoStat.numFiles = info.files().size();\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        msg(infoStream, "    size (MB)=" + nf.format(segInfoStat.sizeMB));\n        Map<String,String> diagnostics = info.info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(infoStream, "    diagnostics = " + diagnostics);\n        }\n\n        if (!info.hasDeletions()) {\n          msg(infoStream, "    no deletions");\n          segInfoStat.hasDeletions = false;\n        } else {\n          msg(infoStream, "    has deletions [delGen=" + info.getDelGen() + "]");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsGen = info.getDelGen();\n        }\n        \n        long startOpenReaderNS = System.nanoTime();\n        if (infoStream != null)\n          infoStream.print("    test: open reader.........");\n        reader = new SegmentReader(info, sis.getIndexCreatedVersionMajor(), IOContext.DEFAULT);\n        msg(infoStream, String.format(Locale.ROOT, "OK [took %.3f sec]", nsToSec(System.nanoTime()-startOpenReaderNS)));\n\n        segInfoStat.openReaderPassed = true;\n        \n        long startIntegrityNS = System.nanoTime();\n        if (infoStream != null)\n          infoStream.print("    test: check integrity.....");\n        reader.checkIntegrity();\n        msg(infoStream, String.format(Locale.ROOT, "OK [took %.3f sec]", nsToSec(System.nanoTime()-startIntegrityNS)));\n\n        if (reader.maxDoc() != info.info.maxDoc()) {\n          throw new RuntimeException("SegmentReader.maxDoc() " + reader.maxDoc() + " != SegmentInfo.maxDoc " + info.info.maxDoc());\n        }\n        \n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        \n        if (reader.hasDeletions()) {\n          if (reader.numDocs() != info.info.maxDoc() - info.getDelCount()) {\n            throw new RuntimeException("delete count mismatch: info=" + (info.info.maxDoc() - info.getDelCount()) + " vs reader=" + reader.numDocs());\n          }\n          if ((info.info.maxDoc() - reader.numDocs()) > reader.maxDoc()) {\n            throw new RuntimeException("too many deleted docs: maxDoc()=" + reader.maxDoc() + " vs del count=" + (info.info.maxDoc() - reader.numDocs()));\n          }\n          if (info.info.maxDoc() - reader.numDocs() != info.getDelCount()) {\n            throw new RuntimeException("delete count mismatch: info=" + info.getDelCount() + " vs reader=" + (info.info.maxDoc() - reader.numDocs()));\n          }\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException("delete count mismatch: info=" + info.getDelCount() + " vs reader=" + (info.info.maxDoc() - reader.numDocs()));\n          }\n        }\n        \n        if (checksumsOnly == false) {\n                    segInfoStat.liveDocStatus = testLiveDocs(reader, infoStream, failFast);\n\n                    segInfoStat.fieldInfoStatus = testFieldInfos(reader, infoStream, failFast);\n        \n                    segInfoStat.fieldNormStatus = testFieldNorms(reader, infoStream, failFast);\n\n                    segInfoStat.termIndexStatus = testPostings(reader, infoStream, verbose, failFast, version);\n\n                    segInfoStat.storedFieldStatus = testStoredFields(reader, infoStream, failFast);\n\n                    segInfoStat.termVectorStatus = testTermVectors(reader, infoStream, verbose, crossCheckTermVectors, failFast, version);\n\n                    segInfoStat.docValuesStatus = testDocValues(reader, infoStream, failFast);\n\n                    segInfoStat.pointsStatus = testPoints(reader, infoStream, failFast);\n\n                    segInfoStat.indexSortStatus = testSort(reader, indexSort, infoStream, failFast);\n\n                              if (segInfoStat.liveDocStatus.error != null) {\n            throw new RuntimeException("Live docs test failed");\n          } else if (segInfoStat.fieldInfoStatus.error != null) {\n            throw new RuntimeException("Field Info test failed");\n          } else if (segInfoStat.fieldNormStatus.error != null) {\n            throw new RuntimeException("Field Norm test failed");\n          } else if (segInfoStat.termIndexStatus.error != null) {\n            throw new RuntimeException("Term Index test failed");\n          } else if (segInfoStat.storedFieldStatus.error != null) {\n            throw new RuntimeException("Stored Field test failed");\n          } else if (segInfoStat.termVectorStatus.error != null) {\n            throw new RuntimeException("Term Vector test failed");\n          } else if (segInfoStat.docValuesStatus.error != null) {\n            throw new RuntimeException("DocValues test failed");\n          } else if (segInfoStat.pointsStatus.error != null) {\n            throw new RuntimeException("Points test failed");\n          }\n        }\n\n        msg(infoStream, "");\n        \n        if (verbose) {\n          msg(infoStream, "detailed segment RAM usage: ");\n          msg(infoStream, Accountables.toString(reader));\n        }\n\n      } catch (Throwable t) {\n        if (failFast) {\n          throw IOUtils.rethrowAlways(t);\n        }\n        msg(infoStream, "FAILED");\n        String comment;\n        comment = "exorciseIndex() would remove reference to this segment";\n        msg(infoStream, "    WARNING: " + comment + "; full exception:");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(infoStream, "");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n            result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n    } else\n      msg(infoStream, "WARNING: " + result.numBadSegments + " broken segments (containing " + result.totLoseDocCount + " documents) detected");\n\n    if ( ! (result.validCounter = (result.maxSegmentName < sis.counter))) {\n      result.clean = false;\n      result.newSegments.counter = result.maxSegmentName + 1; \n      msg(infoStream, "ERROR: Next segment name counter " + sis.counter + " is not greater than max segment name " + result.maxSegmentName);\n    }\n    \n    if (result.clean) {\n      msg(infoStream, "No problems were detected with this index.\n");\n    }\n\n    msg(infoStream, String.format(Locale.ROOT, "Took %.3f sec total.", nsToSec(System.nanoTime()-startNS)));\n\n    return result;\n  }
428	private boolean checkIvyXmlFile(File ivyXmlFile)\n      throws ParserConfigurationException, SAXException, IOException {\n    log("Scanning: " + ivyXmlFile.getPath(), verboseLevel);\n    XMLReader xmlReader = XMLReaderFactory.createXMLReader();\n    DependencyRevChecker revChecker = new DependencyRevChecker(ivyXmlFile); \n    xmlReader.setContentHandler(revChecker);\n    xmlReader.setErrorHandler(revChecker);\n    xmlReader.parse(new InputSource(ivyXmlFile.getAbsolutePath()));\n    return ! revChecker.fail;\n  }
429	public List<CharsRef> uniqueStems(char word[], int length) {\n    List<CharsRef> stems = stem(word, length);\n    if (stems.size() < 2) {\n      return stems;\n    }\n    CharArraySet terms = new CharArraySet(8, dictionary.ignoreCase);\n    List<CharsRef> deduped = new ArrayList<>();\n    for (CharsRef s : stems) {\n      if (!terms.contains(s)) {\n        deduped.add(s);\n        terms.add(s);\n      }\n    }\n    return deduped;\n  }
430	protected void addMultiTermClauses(List<BooleanClause> clauses, Query q) {\n            if (q == null) {\n      return;\n    }\n    boolean allNestedTermQueries = false;\n    if (q instanceof BooleanQuery) {\n      allNestedTermQueries = true;\n      for (BooleanClause clause : ((BooleanQuery)q).clauses()) {\n        if ( ! (clause.getQuery() instanceof TermQuery)) {\n          allNestedTermQueries = false;\n          break;\n        }\n      }\n    }\n    if (allNestedTermQueries) {\n      clauses.addAll(((BooleanQuery)q).clauses());\n    } else {\n      BooleanClause.Occur occur = operator == OR_OPERATOR ? BooleanClause.Occur.SHOULD : BooleanClause.Occur.MUST;\n      if (q instanceof BooleanQuery) {\n        for (BooleanClause clause : ((BooleanQuery)q).clauses()) {\n          clauses.add(newBooleanClause(clause.getQuery(), occur));\n        }\n      } else {\n        clauses.add(newBooleanClause(q, occur));\n      }\n    }\n  }
431	private void mergeContiguousFragments(TextFragment[] frag)\n  {\n    boolean mergingStillBeingDone;\n    if (frag.length > 1)\n      do\n      {\n        mergingStillBeingDone = false;                 for (int i = 0; i < frag.length; i++)\n        {\n          if (frag[i] == null)\n          {\n            continue;\n          }\n                    for (int x = 0; x < frag.length; x++)\n          {\n            if (frag[x] == null)\n            {\n              continue;\n            }\n            if (frag[i] == null)\n            {\n              break;\n            }\n            TextFragment frag1 = null;\n            TextFragment frag2 = null;\n            int frag1Num = 0;\n            int frag2Num = 0;\n            int bestScoringFragNum;\n            int worstScoringFragNum;\n                        if (frag[i].follows(frag[x]))\n            {\n              frag1 = frag[x];\n              frag1Num = x;\n              frag2 = frag[i];\n              frag2Num = i;\n            }\n            else\n              if (frag[x].follows(frag[i]))\n              {\n                frag1 = frag[i];\n                frag1Num = i;\n                frag2 = frag[x];\n                frag2Num = x;\n              }\n                        if (frag1 != null)\n            {\n              if (frag1.getScore() > frag2.getScore())\n              {\n                bestScoringFragNum = frag1Num;\n                worstScoringFragNum = frag2Num;\n              }\n              else\n              {\n                bestScoringFragNum = frag2Num;\n                worstScoringFragNum = frag1Num;\n              }\n              frag1.merge(frag2);\n              frag[worstScoringFragNum] = null;\n              mergingStillBeingDone = true;\n              frag[bestScoringFragNum] = frag1;\n            }\n          }\n        }\n      }\n      while (mergingStillBeingDone);\n  }
432	private ParseTree getAntlrParseTree() throws ParseException {\n    final ANTLRInputStream antlrInputStream = new ANTLRInputStream(sourceText);\n    final JavascriptErrorHandlingLexer javascriptLexer = new JavascriptErrorHandlingLexer(antlrInputStream);\n    javascriptLexer.removeErrorListeners();\n    final JavascriptParser javascriptParser = new JavascriptParser(new CommonTokenStream(javascriptLexer));\n    javascriptParser.removeErrorListeners();\n    javascriptParser.setErrorHandler(new JavascriptParserErrorStrategy());\n    return javascriptParser.compile();\n  }
433	protected int countDocsWithClass() throws IOException {\n    Terms terms = MultiFields.getTerms(this.indexReader, this.classFieldName);\n    int docCount;\n    if (terms == null || terms.getDocCount() == -1) {       TotalHitCountCollector classQueryCountCollector = new TotalHitCountCollector();\n      BooleanQuery.Builder q = new BooleanQuery.Builder();\n      q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, String.valueOf(WildcardQuery.WILDCARD_STRING))), BooleanClause.Occur.MUST));\n      if (query != null) {\n        q.add(query, BooleanClause.Occur.MUST);\n      }\n      indexSearcher.search(q.build(),\n          classQueryCountCollector);\n      docCount = classQueryCountCollector.getTotalHits();\n    } else {\n      docCount = terms.getDocCount();\n    }\n    return docCount;\n  }
434	public static DocIdSetIterator intersectIterators(List<DocIdSetIterator> iterators) {\n    if (iterators.size() < 2) {\n      throw new IllegalArgumentException("Cannot make a ConjunctionDISI of less than 2 iterators");\n    }\n    final List<DocIdSetIterator> allIterators = new ArrayList<>();\n    final List<TwoPhaseIterator> twoPhaseIterators = new ArrayList<>();\n    for (DocIdSetIterator iterator : iterators) {\n      addIterator(iterator, allIterators, twoPhaseIterators);\n    }\n\n    return createConjunction(allIterators, twoPhaseIterators);\n  }
435	public static int compareArray(char[] larray, int lstartIndex, char[] rarray,\n      int rstartIndex) {\n\n    if (larray == null) {\n      if (rarray == null || rstartIndex >= rarray.length)\n        return 0;\n      else\n        return -1;\n    } else {\n            if (rarray == null) {\n        if (lstartIndex >= larray.length)\n          return 0;\n        else\n          return 1;\n      }\n    }\n\n    int li = lstartIndex, ri = rstartIndex;\n    while (li < larray.length && ri < rarray.length && larray[li] == rarray[ri]) {\n      li++;\n      ri++;\n    }\n    if (li == larray.length) {\n      if (ri == rarray.length) {\n                return 0;\n      } else {\n                return -1;\n      }\n    } else {\n            if (ri == rarray.length) {\n                return 1;\n      } else {\n                if (larray[li] > rarray[ri])\n          return 1;\n        else\n          return -1;\n      }\n    }\n  }
436	static void writeClass(final OutputStream outputStream, final Class<?> clazz) throws IOException {\n    Integer index = StandardObjects.classRegsitry.get(clazz);\n    if (index == null){\n      writeBoolean(outputStream, false);\n      writeString(outputStream, clazz.getName());\n    }\n    else {\n      writeBoolean(outputStream, true);\n      outputStream.write(index);\n    }\n  }
437	public static void cleanupOldIndexFiles(Directory dir, String segmentsFile, InfoStream infoStream) {\n    try {\n      IndexCommit commit = getLastCommit(dir);\n                        if (commit != null && commit.getSegmentsFileName().equals(segmentsFile)) {\n        Set<String> commitFiles = new HashSet<>();\n        commitFiles.addAll(commit.getFileNames());\n        Matcher matcher = IndexFileNames.CODEC_FILE_PATTERN.matcher("");\n        for (String file : dir.listAll()) {\n          if (!commitFiles.contains(file)\n              && (matcher.reset(file).matches() || file.startsWith(IndexFileNames.SEGMENTS))) {\n                        IOUtils.deleteFilesIgnoringExceptions(dir, file);\n          }\n        }\n      }\n    } catch (Throwable t) {\n                        if (infoStream.isEnabled(INFO_STREAM_COMPONENT)) {\n        infoStream.message(INFO_STREAM_COMPONENT, "cleanupOldIndexFiles(): failed on error " + t.getMessage());\n      }\n    }\n  }
438	public static long checkFooter(ChecksumIndexInput in) throws IOException {\n    validateFooter(in);\n    long actualChecksum = in.getChecksum();\n    long expectedChecksum = readCRC(in);\n    if (expectedChecksum != actualChecksum) {\n      throw new CorruptIndexException("checksum failed (hardware problem?) : expected=" + Long.toHexString(expectedChecksum) +  \n                                                       " actual=" + Long.toHexString(actualChecksum), in);\n    }\n    return actualChecksum;\n  }
439	public static IntsRef toUTF32(char[] s, int offset, int length, IntsRefBuilder scratch) {\n    int charIdx = offset;\n    int intIdx = 0;\n    final int charLimit = offset + length;\n    while(charIdx < charLimit) {\n      scratch.grow(intIdx+1);\n      final int utf32 = Character.codePointAt(s, charIdx, charLimit);\n      scratch.setIntAt(intIdx, utf32);\n      charIdx += Character.charCount(utf32);\n      intIdx++;\n    }\n    scratch.setLength(intIdx);\n    return scratch.get();\n  }
440	public void report(QualityQuery qq, TopDocs td, String docNameField, IndexSearcher searcher) throws IOException {\n    if (logger==null) {\n      return;\n    }\n    ScoreDoc sd[] = td.scoreDocs;\n    String sep = " \t ";\n    DocNameExtractor xt = new DocNameExtractor(docNameField);\n    for (int i=0; i<sd.length; i++) {\n      String docName = xt.docName(searcher,sd[i].doc);\n      logger.println(\n          qq.getQueryID()       + sep +\n          "Q0"                   + sep +\n          format(docName,20)    + sep +\n          format(""+i,7)        + sep +\n          nf.format(sd[i].score) + sep +\n          name\n          );\n    }\n  }
441	private void updateFreq() throws IOException {\n    assert freq >= minShouldMatch;\n                                for (int i = tailSize - 1; i >= 0; --i) {\n      advanceTail(tail[i]);\n    }\n    tailSize = 0;\n  }
442	public static String getQueryAsXmlString(Properties formProperties, Templates template)\n      throws ParserConfigurationException, TransformerException {\n        StringWriter writer = new StringWriter();\n    StreamResult result = new StreamResult(writer);\n    transformCriteria(formProperties, template, result);\n    return writer.toString();\n  }
443	protected OffsetSource getOffsetSource(String field) {\n    FieldInfo fieldInfo = getFieldInfo(field);\n    if (fieldInfo != null) {\n      if (fieldInfo.getIndexOptions() == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) {\n        return fieldInfo.hasVectors() ? OffsetSource.POSTINGS_WITH_TERM_VECTORS : OffsetSource.POSTINGS;\n      }\n      if (fieldInfo.hasVectors()) {         return OffsetSource.TERM_VECTORS;\n      }\n    }\n    return OffsetSource.ANALYSIS;\n  }
444	public static Bits getLiveDocs(IndexReader reader) {\n    if (reader.hasDeletions()) {\n      final List<LeafReaderContext> leaves = reader.leaves();\n      final int size = leaves.size();\n      assert size > 0 : "A reader with deletions must have at least one leave";\n      if (size == 1) {\n        return leaves.get(0).reader().getLiveDocs();\n      }\n      final Bits[] liveDocs = new Bits[size];\n      final int[] starts = new int[size + 1];\n      for (int i = 0; i < size; i++) {\n                final LeafReaderContext ctx = leaves.get(i);\n        liveDocs[i] = ctx.reader().getLiveDocs();\n        starts[i] = ctx.docBase;\n      }\n      starts[size] = reader.maxDoc();\n      return new MultiBits(liveDocs, starts, true);\n    } else {\n      return null;\n    }\n  }
445	public boolean visit() throws IOException {\n        for(int i=0;i<10;i++) {\n      long bytesLeft = bytesToCopy - bytesCopied;\n      if (bytesLeft == 0) {\n        long checksum = out.getChecksum();\n        if (checksum != metaData.checksum) {\n                    dest.message("file " + tmpName + ": checksum mismatch after copy (bits flipped during network copy?) after-copy checksum=" + checksum + " vs expected=" + metaData.checksum + "; cancel job");\n          throw new IOException("file " + name + ": checksum mismatch after file copy");\n        }\n\n                        long actualChecksumIn = in.readLong();\n        if (actualChecksumIn != checksum) {\n          dest.message("file " + tmpName + ": checksum claimed by primary disagrees with the file's footer: claimed checksum=" + checksum + " vs actual=" + actualChecksumIn);\n          throw new IOException("file " + name + ": checksum mismatch after file copy");\n        }\n        out.writeLong(checksum);\n        bytesCopied += Long.BYTES;\n        close();\n\n        if (Node.VERBOSE_FILES) {\n          dest.message(String.format(Locale.ROOT, "file %s: done copying [%s, %.3fms]",\n                                     name,\n                                     Node.bytesToString(metaData.length),\n                                     (System.nanoTime() - copyStartNS)/1000000.0));\n        }\n\n        return true;\n      }\n\n      int toCopy = (int) Math.min(bytesLeft, buffer.length);\n      in.readBytes(buffer, 0, toCopy);\n      out.writeBytes(buffer, 0, toCopy);\n\n            bytesCopied += toCopy;\n    }\n\n    return false;\n  }
446	void waitIfStalled() {\n    if (stalled) {\n      synchronized (this) {\n        if (stalled) {                     try {\n            incWaiters();\n                                    wait(1000);\n            decrWaiters();\n          } catch (InterruptedException e) {\n            throw new ThreadInterruptedException(e);\n          }\n        }\n      }\n    }\n  }
447	private static Double computeAngle(final GeoPoint point,\n    final double sinLatitude,\n    final double cosLatitude,\n    final double sinLongitude,\n    final double cosLongitude) {\n                                                              \n    final double x1 = point.x * cosLongitude + point.y * sinLongitude;\n    final double y1 = - point.x * sinLongitude + point.y * cosLongitude;\n    final double z1 = point.z;\n      \n        final double y2 = y1;\n    final double z2 = - x1 * sinLatitude + z1 * cosLatitude;\n    \n            if (Math.sqrt(y2*y2 + z2*z2) < Vector.MINIMUM_RESOLUTION) {\n      return null;\n    }\n    \n    return Math.atan2(z2, y2);\n  }
448	public static final VariableContext[] parse(String variable) {\n    char[] text = variable.toCharArray();\n    List<VariableContext> contexts = new ArrayList<>();\n    int i = addMember(text, 0, contexts);     while (i < text.length) {\n      if (text[i] == '[') {\n        if (text[++i] == '\'') {\n          i = addStringIndex(text, i, contexts);\n        } else {\n          i = addIntIndex(text, i, contexts);\n        }\n        ++i;       } else {         i = addMember(text, i + 1, contexts);\n      }\n    }\n    return contexts.toArray(new VariableContext[contexts.size()]);\n  }
449	public final void clear() {\n    for (int i = 0; i <= size; i++) {\n      heap[i] = null;\n    }\n    size = 0;\n  }
450	private synchronized void encode(String id, Document doc) throws IOException {\n    assert id.equals(doc.get("docid")): "id=" + id + " vs docid=" + doc.get("docid");\n    buffer.writeString(id);\n    writeNullableString(doc.get("title"));\n    writeNullableString(doc.get("body"));\n    writeNullableString(doc.get("marker"));\n  }
451	public Cell merge(Cell m, Cell e) {\n    Cell n = new Cell();\n    \n    if (m.skip != e.skip) {\n      return null;\n    }\n    \n    if (m.cmd >= 0) {\n      if (e.cmd >= 0) {\n        if (m.cmd == e.cmd) {\n          n.cmd = m.cmd;\n        } else {\n          return null;\n        }\n      } else {\n        n.cmd = m.cmd;\n      }\n    } else {\n      n.cmd = e.cmd;\n    }\n    if (m.ref >= 0) {\n      if (e.ref >= 0) {\n        if (m.ref == e.ref) {\n          if (m.skip == e.skip) {\n            n.ref = m.ref;\n          } else {\n            return null;\n          }\n        } else {\n          return null;\n        }\n      } else {\n        n.ref = m.ref;\n      }\n    } else {\n      n.ref = e.ref;\n    }\n    n.cnt = m.cnt + e.cnt;\n    n.skip = m.skip;\n    return n;\n  }
452	public void or(DocIdSetIterator iter) throws IOException {\n    checkUnpositioned(iter);\n    for (int doc = iter.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = iter.nextDoc()) {\n      set(doc);\n    }\n  }
453	private boolean needToPreserve(char[] input, int inputLength) {\n    if(inputLength != outputPos) {\n      return true;\n    }\n    for(int i = 0; i < inputLength; i++) {\n      if(input[i] != output[i]) {\n        return true;\n      }\n    }\n    return false;\n  }
454	public static TermContext build(IndexReaderContext context, Term term)\n      throws IOException {\n    assert context != null && context.isTopLevel;\n    final String field = term.field();\n    final BytesRef bytes = term.bytes();\n    final TermContext perReaderTermState = new TermContext(context);\n        for (final LeafReaderContext ctx : context.leaves()) {\n            final Terms terms = ctx.reader().terms(field);\n      if (terms != null) {\n        final TermsEnum termsEnum = terms.iterator();\n        if (termsEnum.seekExact(bytes)) { \n          final TermState termState = termsEnum.termState();\n                    perReaderTermState.register(termState, ctx.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        }\n      }\n    }\n    return perReaderTermState;\n  }
455	public synchronized LiveIndexWriterConfig setRAMBufferSizeMB(double ramBufferSizeMB) {\n    if (ramBufferSizeMB != IndexWriterConfig.DISABLE_AUTO_FLUSH && ramBufferSizeMB <= 0.0) {\n      throw new IllegalArgumentException("ramBufferSize should be > 0.0 MB when enabled");\n    }\n    if (ramBufferSizeMB == IndexWriterConfig.DISABLE_AUTO_FLUSH\n        && maxBufferedDocs == IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n      throw new IllegalArgumentException("at least one of ramBufferSize and maxBufferedDocs must be enabled");\n    }\n    this.ramBufferSizeMB = ramBufferSizeMB;\n    return this;\n  }
456	private boolean initPhrasePositions() throws IOException {\n    end = Integer.MIN_VALUE;\n    if (!checkedRpts) {\n      return initFirstTime();\n    }\n    if (!hasRpts) {\n      initSimple();\n      return true;     }\n    return initComplex();\n  }
457	public State complete() {\n    if (this.stateRegistry == null) throw new IllegalStateException();\n    \n    if (root.hasChildren()) replaceOrRegister(root);\n    \n    stateRegistry = null;\n    return root;\n  }
458	public Bounds addYValue(final double y) {\n    final double small = y - FUDGE_FACTOR;\n    if (minY == null || minY > small) {\n      minY = new Double(small);\n    }\n    final double large = y + FUDGE_FACTOR;\n    if (maxY == null || maxY < large) {\n      maxY = new Double(large);\n    }\n    return this;\n  }
459	protected void encode(ByteSequencesWriter writer, ByteArrayDataOutput output, byte[] buffer, BytesRef spare, BytesRef payload, Set<BytesRef> contexts, long weight) throws IOException {\n    int requiredLength = spare.length + 8 + ((hasPayloads) ? 2 + payload.length : 0);\n    if (hasContexts) {\n      for(BytesRef ctx : contexts) {\n        requiredLength += 2 + ctx.length;\n      }\n      requiredLength += 2;     }\n    if (requiredLength >= buffer.length) {\n      buffer = ArrayUtil.grow(buffer, requiredLength);\n    }\n    output.reset(buffer);\n    output.writeBytes(spare.bytes, spare.offset, spare.length);\n    if (hasContexts) {\n      for (BytesRef ctx : contexts) {\n        output.writeBytes(ctx.bytes, ctx.offset, ctx.length);\n        output.writeShort((short) ctx.length);\n      }\n      output.writeShort((short) contexts.size());\n    }\n    if (hasPayloads) {\n      output.writeBytes(payload.bytes, payload.offset, payload.length);\n      output.writeShort((short) payload.length);\n    }\n    output.writeLong(weight);\n    writer.write(buffer, 0, output.getPosition());\n  }
460	Query makeWithin(Rectangle bbox) {\n\n        \n            Query qMinY = this.makeNumericRangeQuery(field_minY, bbox.getMinY(), null, true, false);\n    Query qMaxY = this.makeNumericRangeQuery(field_maxY, null, bbox.getMaxY(), false, true);\n    Query yConditions = this.makeQuery(BooleanClause.Occur.MUST, qMinY, qMaxY);\n\n        Query xConditions;\n\n    if (ctx.isGeo() && bbox.getMinX() == -180.0 && bbox.getMaxX() == 180.0) {\n            return yConditions;\n\n    } else if (!bbox.getCrossesDateLine()) {\n      \n            Query qMinX = this.makeNumericRangeQuery(field_minX, bbox.getMinX(), null, true, false);\n      Query qMaxX = this.makeNumericRangeQuery(field_maxX, null, bbox.getMaxX(), false, true);\n      Query qMinMax = this.makeQuery(BooleanClause.Occur.MUST, qMinX, qMaxX);\n\n      double edge = 0;      if (bbox.getMinX() == -180.0)\n        edge = 180;\n      else if (bbox.getMaxX() == 180.0)\n        edge = -180;\n      if (edge != 0 && ctx.isGeo()) {\n        Query edgeQ = makeQuery(BooleanClause.Occur.MUST,\n            makeNumberTermQuery(field_minX, edge), makeNumberTermQuery(field_maxX, edge));\n        qMinMax = makeQuery(BooleanClause.Occur.SHOULD, qMinMax, edgeQ);\n      }\n\n      xConditions = this.makeXDL(false, qMinMax);\n\n          } else {\n\n      \n                  Query qMinXLeft = this.makeNumericRangeQuery(field_minX, bbox.getMinX(), null, true, false);\n      Query qMaxXLeft = this.makeNumericRangeQuery(field_maxX, null, 180.0, false, true);\n      Query qLeft = this.makeQuery(BooleanClause.Occur.MUST, qMinXLeft, qMaxXLeft);\n\n                  Query qMinXRight = this.makeNumericRangeQuery(field_minX, -180.0, null, true, false);\n      Query qMaxXRight = this.makeNumericRangeQuery(field_maxX, null, bbox.getMaxX(), false, true);\n      Query qRight = this.makeQuery(BooleanClause.Occur.MUST, qMinXRight, qMaxXRight);\n\n                  Query qLeftRight = this.makeQuery(BooleanClause.Occur.SHOULD, qLeft, qRight);\n      Query qNonXDL = this.makeXDL(false, qLeftRight);\n\n                                    Query qXDLLeft = this.makeNumericRangeQuery(field_minX, bbox.getMinX(), null, true, false);\n      Query qXDLRight = this.makeNumericRangeQuery(field_maxX, null, bbox.getMaxX(), false, true);\n      Query qXDLLeftRight = this.makeQuery(BooleanClause.Occur.MUST, qXDLLeft, qXDLRight);\n      Query qXDL = this.makeXDL(true, qXDLLeftRight);\n\n            xConditions = this.makeQuery(BooleanClause.Occur.SHOULD, qNonXDL, qXDL);\n    }\n\n        return this.makeQuery(BooleanClause.Occur.MUST, xConditions, yConditions);\n  }
461	public int normalize(char s[], int len) {\n\n    for (int i = 0; i < len; i++) {\n      switch (s[i]) {\n              case '\u0928':\n        if (i + 1 < len && s[i + 1] == '\u094D') {\n          s[i] = '\u0902';\n          len = delete(s, i + 1, len);\n        }\n        break;\n            case '\u0901':\n        s[i] = '\u0902';\n        break;\n            case '\u093C':\n        len = delete(s, i, len);\n        i--;\n        break;      \n      case '\u0929':\n        s[i] = '\u0928';\n        break;\n      case '\u0931':\n        s[i] = '\u0930';\n        break;\n      case '\u0934':\n        s[i] = '\u0933';\n        break;\n      case '\u0958':\n        s[i] = '\u0915';\n        break;\n      case '\u0959':\n        s[i] = '\u0916';\n        break;\n      case '\u095A':\n        s[i] = '\u0917';\n        break;\n      case '\u095B':\n        s[i] = '\u091C';\n        break;\n      case '\u095C':\n        s[i] = '\u0921';\n        break;\n      case '\u095D':\n        s[i] = '\u0922';\n        break;\n      case '\u095E':\n        s[i] = '\u092B';\n        break;\n      case '\u095F':\n        s[i] = '\u092F';\n        break;\n              case '\u200D':\n      case '\u200C':\n        len = delete(s, i, len);\n        i--;\n        break;\n              case '\u094D':\n        len = delete(s, i, len);\n        i--;\n        break;\n              case '\u0945':\n      case '\u0946':\n        s[i] = '\u0947';\n        break;\n      case '\u0949':\n      case '\u094A':\n        s[i] = '\u094B';\n        break;\n      case '\u090D':\n      case '\u090E':\n        s[i] = '\u090F';\n        break;\n      case '\u0911':\n      case '\u0912':\n        s[i] = '\u0913';\n        break;\n      case '\u0972':\n        s[i] = '\u0905';\n        break;\n              case '\u0906':\n        s[i] = '\u0905';\n        break;\n      case '\u0908':\n        s[i] = '\u0907';\n        break;\n      case '\u090A':\n        s[i] = '\u0909';\n        break;\n      case '\u0960':\n        s[i] = '\u090B';\n        break;\n      case '\u0961':\n        s[i] = '\u090C';\n        break;\n      case '\u0910':\n        s[i] = '\u090F';\n        break;\n      case '\u0914':\n        s[i] = '\u0913';\n        break;\n              case '\u0940':\n        s[i] = '\u093F';\n        break;\n      case '\u0942':\n        s[i] = '\u0941';\n        break;\n      case '\u0944':\n        s[i] = '\u0943';\n        break;\n      case '\u0963':\n        s[i] = '\u0962';\n        break;\n      case '\u0948':\n        s[i] = '\u0947';\n        break;\n      case '\u094C':\n        s[i] = '\u094B';\n        break;\n      default:\n        break;\n      }\n    }\n\n    return len;\n  }
462	public double arcDistance(final PlanetModel planetModel, final double x, final double y, final double z, final Membership... bounds) {\n\n    if (evaluateIsZero(x,y,z)) {\n      if (meetsAllBounds(x,y,z, bounds))\n        return 0.0;\n      return Double.POSITIVE_INFINITY;\n    }\n    \n        final Plane perpPlane = new Plane(this.y * z - this.z * y, this.z * x - this.x * z, this.x * y - this.y * x, 0.0);\n\n                \n    final GeoPoint[] intersectionPoints = findIntersections(planetModel, perpPlane);\n    \n        double minDistance = Double.POSITIVE_INFINITY;\n    \n    for (final GeoPoint intersectionPoint : intersectionPoints) {\n      if (meetsAllBounds(intersectionPoint, bounds)) {\n        final double theDistance = intersectionPoint.arcDistance(x,y,z);\n        if (theDistance < minDistance) {\n          minDistance = theDistance;\n        }\n      }\n    }\n    return minDistance;\n\n  }
463	public Reader freeze(boolean trim) {\n    if (frozen) {\n      throw new IllegalStateException("already frozen");\n    }\n    if (didSkipBytes) {\n      throw new IllegalStateException("cannot freeze when copy(BytesRef, BytesRef) was used");\n    }\n    if (trim && upto < blockSize) {\n      final byte[] newBlock = new byte[upto];\n      System.arraycopy(currentBlock, 0, newBlock, 0, upto);\n      currentBlock = newBlock;\n    }\n    if (currentBlock == null) {\n      currentBlock = EMPTY_BYTES;\n    }\n    addBlock(currentBlock);\n    frozen = true;\n    currentBlock = null;\n    return new PagedBytes.Reader(this);\n  }
464	public int getPrefixMatch(char[] charArray, int knownStart) {\n    short index = getWordItemTableIndex(charArray[0]);\n    if (index == -1)\n      return -1;\n    char[][] items = wordItem_charArrayTable[wordIndexTable[index]];\n    int start = knownStart, end = items.length - 1;\n\n    int mid = (start + end) / 2, cmpResult;\n\n        while (start <= end) {\n      cmpResult = Utility.compareArrayByPrefix(charArray, 1, items[mid], 0);\n      if (cmpResult == 0) {\n                while (mid >= 0\n            && Utility.compareArrayByPrefix(charArray, 1, items[mid], 0) == 0)\n          mid--;\n        mid++;\n        return mid;      } else if (cmpResult < 0)\n        end = mid - 1;\n      else\n        start = mid + 1;\n      mid = (start + end) / 2;\n    }\n    return -1;\n  }
465	public static int compareArrayByPrefix(char[] shortArray, int shortIndex,\n      char[] longArray, int longIndex) {\n\n        if (shortArray == null)\n      return 0;\n    else if (longArray == null)\n      return (shortIndex < shortArray.length) ? 1 : 0;\n\n    int si = shortIndex, li = longIndex;\n    while (si < shortArray.length && li < longArray.length\n        && shortArray[si] == longArray[li]) {\n      si++;\n      li++;\n    }\n    if (si == shortArray.length) {\n            return 0;\n    } else {\n            if (li == longArray.length)\n        return 1;\n      else\n                return (shortArray[si] > longArray[li]) ? 1 : -1;\n    }\n  }
466	public Row merge(Row master, Row existing) {\n    Iterator<Character> i = master.cells.keySet().iterator();\n    Row n = new Row();\n    for (; i.hasNext();) {\n      Character ch = i.next();\n            Cell a = master.cells.get(ch);\n      Cell b = existing.cells.get(ch);\n      \n      Cell s = (b == null) ? new Cell(a) : merge(a, b);\n      if (s == null) {\n        return null;\n      }\n      n.cells.put(ch, s);\n    }\n    i = existing.cells.keySet().iterator();\n    for (; i.hasNext();) {\n      Character ch = i.next();\n      if (master.at(ch) != null) {\n        continue;\n      }\n      n.cells.put(ch, existing.at(ch));\n    }\n    return n;\n  }
467	protected long decode(BytesRef scratch, ByteArrayDataInput tmpInput) {\n    tmpInput.reset(scratch.bytes, scratch.offset, scratch.length);\n    tmpInput.skipBytes(scratch.length - 8);     scratch.length -= Long.BYTES;     return tmpInput.readLong();\n  }
468	protected double calculateCoefficient(int position) {\n\n    double coefficient;\n    switch (blenderType) {\n      case POSITION_LINEAR:\n        coefficient = 1 - LINEAR_COEF * position;\n        break;\n\n      case POSITION_RECIPROCAL:\n        coefficient = 1. / (position + 1);\n        break;\n\n      case POSITION_EXPONENTIAL_RECIPROCAL:\n        coefficient = 1. / Math.pow((position + 1.0), exponent);\n        break;\n\n      default:\n        coefficient = 1;\n    }\n\n    return coefficient;\n  }
469	public static void deleteFiles(Directory dir, Collection<String> names) throws IOException {\n    Throwable th = null;\n    for (String name : names) {\n      if (name != null) {\n        try {\n          dir.deleteFile(name);\n        } catch (Throwable t) {\n          addSuppressed(th, t);\n          if (th == null) {\n            th = t;\n          }\n        }\n      }\n    }\n\n    if (th != null) {\n      throw rethrowAlways(th);\n    }\n  }
470	void add(CharSequence key, CharSequence cmd) {\n    if (key == null || cmd == null) {\n      return;\n    }\n    if (cmd.length() == 0) {\n      return;\n    }\n    int id_cmd = cmds.indexOf(cmd);\n    if (id_cmd == -1) {\n      id_cmd = cmds.size();\n      cmds.add(cmd);\n    }\n    \n    int node = root;\n    Row r = getRow(node);\n    \n    StrEnum e = new StrEnum(key, forward);\n    \n    for (int i = 0; i < e.length() - 1; i++) {\n      Character ch = new Character(e.next());\n      node = r.getRef(ch);\n      if (node >= 0) {\n        r = getRow(node);\n      } else {\n        node = rows.size();\n        Row n;\n        rows.add(n = new Row());\n        r.setRef(ch, node);\n        r = n;\n      }\n    }\n    r.setCmd(new Character(e.next()), id_cmd);\n  }
471	protected Query newDefaultQuery(String text) {\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    for (Map.Entry<String,Float> entry : weights.entrySet()) {\n      Query q = createBooleanQuery(entry.getKey(), text, defaultOperator);\n      if (q != null) {\n        float boost = entry.getValue();\n        if (boost != 1f) {\n          q = new BoostQuery(q, boost);\n        }\n        bq.add(q, BooleanClause.Occur.SHOULD);\n      }\n    }\n    return simplify(bq.build());\n  }
472	protected BytesRef decodePayload(BytesRef scratch, ByteArrayDataInput tmpInput) {\n    tmpInput.reset(scratch.bytes, scratch.offset, scratch.length);\n    tmpInput.skipBytes(scratch.length - 2);     short payloadLength = tmpInput.readShort();     assert payloadLength >= 0: payloadLength;\n    tmpInput.setPosition(scratch.offset + scratch.length - 2 - payloadLength);     BytesRef payloadScratch = new BytesRef(payloadLength); \n    tmpInput.readBytes(payloadScratch.bytes, 0, payloadLength);     payloadScratch.length = payloadLength;\n    scratch.length -= 2;     scratch.length -= payloadLength;     return payloadScratch;\n  }
473	public static int strcmp(String str, char[] a, int start) {\n    int i, d, len = str.length();\n    for (i = 0; i < len; i++) {\n      d = (int) str.charAt(i) - a[start + i];\n      if (d != 0) {\n        return d;\n      }\n      if (a[start + i] == 0) {\n        return d;\n      }\n    }\n    if (a[start + i] != 0) {\n      return -a[start + i];\n    }\n    return 0;\n\n  }
474	Partition readPartition(ByteSequencesReader reader) throws IOException, InterruptedException {\n    if (partitionsInRAM != null) {\n      partitionsInRAM.acquire();\n    }\n    boolean success = false;\n    try {\n      long start = System.currentTimeMillis();\n      SortableBytesRefArray buffer;\n      boolean exhausted = false;\n      int count;\n      if (valueLength != -1) {\n                buffer = new FixedLengthBytesRefArray(valueLength);\n        int limit = ramBufferSize.bytes / valueLength;\n        for(int i=0;i<limit;i++) {\n          BytesRef item = null;\n          try {\n            item = reader.next();\n          } catch (Throwable t) {\n            verifyChecksum(t, reader);\n          }\n          if (item == null) {\n            exhausted = true;\n            break;\n          }\n          buffer.append(item);\n        }\n      } else {\n        Counter bufferBytesUsed = Counter.newCounter();\n        buffer = new BytesRefArray(bufferBytesUsed);\n        while (true) {\n          BytesRef item = null;\n          try {\n            item = reader.next();\n          } catch (Throwable t) {\n            verifyChecksum(t, reader);\n          }\n          if (item == null) {\n            exhausted = true;\n            break;\n          }\n          buffer.append(item);\n                              if (bufferBytesUsed.get() > ramBufferSize.bytes) {\n            break;\n          }\n        }\n      }\n      sortInfo.readTimeMS += System.currentTimeMillis() - start;\n      success = true;\n      return new Partition(buffer, exhausted);\n    } finally {\n      if (success == false && partitionsInRAM != null) {\n        partitionsInRAM.release();\n      }\n    }\n  }
475	public IndexableField getField(FieldInfo fieldInfo) {  \n\n    fieldNames.add(fieldInfo.name);\n    List<LazyField> values = fields.get(fieldInfo.number);\n    if (null == values) {\n      values = new ArrayList<>();\n      fields.put(fieldInfo.number, values);\n    } \n\n    LazyField value = new LazyField(fieldInfo.name, fieldInfo.number);\n    values.add(value);\n\n    synchronized (this) {\n                              doc = null;\n    }\n    return value;\n  }
476	private List<String> matchAlmostRecursion(TSTNode currentNode, int charIndex,\n          int d, CharSequence matchAlmostKey, int matchAlmostNumReturnValues,\n          List<String> matchAlmostResult2, boolean upTo) {\n    if ((currentNode == null)\n            || (matchAlmostNumReturnValues != -1 && matchAlmostResult2.size() >= matchAlmostNumReturnValues)\n            || (d < 0) || (charIndex >= matchAlmostKey.length())) {\n      return matchAlmostResult2;\n    }\n    int charComp = compareCharsAlphabetically(matchAlmostKey.charAt(charIndex),\n            currentNode.splitchar);\n    List<String> matchAlmostResult = matchAlmostResult2;\n    if ((d > 0) || (charComp < 0)) {\n      matchAlmostResult = matchAlmostRecursion(\n              currentNode.relatives[TSTNode.LOKID], charIndex, d,\n              matchAlmostKey, matchAlmostNumReturnValues, matchAlmostResult,\n              upTo);\n    }\n    int nextD = (charComp == 0) ? d : d - 1;\n    boolean cond = (upTo) ? (nextD >= 0) : (nextD == 0);\n    if ((matchAlmostKey.length() == charIndex + 1) && cond\n            && (currentNode.data != null)) {\n      matchAlmostResult.add(getKey(currentNode));\n    }\n    matchAlmostResult = matchAlmostRecursion(\n            currentNode.relatives[TSTNode.EQKID], charIndex + 1, nextD,\n            matchAlmostKey, matchAlmostNumReturnValues, matchAlmostResult, upTo);\n    if ((d > 0) || (charComp > 0)) {\n      matchAlmostResult = matchAlmostRecursion(\n              currentNode.relatives[TSTNode.HIKID], charIndex, d,\n              matchAlmostKey, matchAlmostNumReturnValues, matchAlmostResult,\n              upTo);\n    }\n    return matchAlmostResult;\n  }
477	static String getDictionaryEncoding(InputStream affix) throws IOException, ParseException {\n    final StringBuilder encoding = new StringBuilder();\n    for (;;) {\n      encoding.setLength(0);\n      int ch;\n      while ((ch = affix.read()) >= 0) {\n        if (ch == '\n') {\n          break;\n        }\n        if (ch != '\r') {\n          encoding.append((char)ch);\n        }\n      }\n      if (\n          encoding.length() == 0 || encoding.charAt(0) == '#' ||\n                    encoding.toString().trim().length() == 0\n      ) {\n        if (ch < 0) {\n          throw new ParseException("Unexpected end of affix file.", 0);\n        }\n        continue;\n      }\n      Matcher matcher = ENCODING_PATTERN.matcher(encoding);\n      if (matcher.find()) {\n        int last = matcher.end();\n        return encoding.substring(last).trim();\n      }\n    }\n  }
478	public static <T> TopGroups<T> merge(TopGroups<T>[] shardGroups, Sort groupSort, Sort docSort, int docOffset, int docTopN, ScoreMergeMode scoreMergeMode) {\n\n    \n    if (shardGroups.length == 0) {\n      return null;\n    }\n\n    int totalHitCount = 0;\n    int totalGroupedHitCount = 0;\n        Integer totalGroupCount = null;\n\n    final int numGroups = shardGroups[0].groups.length;\n    for(TopGroups<T> shard : shardGroups) {\n      if (numGroups != shard.groups.length) {\n        throw new IllegalArgumentException("number of groups differs across shards; you must pass same top groups to all shards' second-pass collector");\n      }\n      totalHitCount += shard.totalHitCount;\n      totalGroupedHitCount += shard.totalGroupedHitCount;\n      if (shard.totalGroupCount != null) {\n        if (totalGroupCount == null) {\n          totalGroupCount = 0;\n        }\n\n        totalGroupCount += shard.totalGroupCount;\n      }\n    }\n\n    @SuppressWarnings({"unchecked","rawtypes"})\n    final GroupDocs<T>[] mergedGroupDocs = new GroupDocs[numGroups];\n\n    final TopDocs[] shardTopDocs;\n    if (docSort.equals(Sort.RELEVANCE)) {\n      shardTopDocs = new TopDocs[shardGroups.length];\n    } else {\n      shardTopDocs = new TopFieldDocs[shardGroups.length];\n    }\n    float totalMaxScore = Float.MIN_VALUE;\n\n    for(int groupIDX=0;groupIDX<numGroups;groupIDX++) {\n      final T groupValue = shardGroups[0].groups[groupIDX].groupValue;\n            float maxScore = Float.MIN_VALUE;\n      int totalHits = 0;\n      double scoreSum = 0.0;\n      for(int shardIDX=0;shardIDX<shardGroups.length;shardIDX++) {\n                final TopGroups<T> shard = shardGroups[shardIDX];\n        final GroupDocs<?> shardGroupDocs = shard.groups[groupIDX];\n        if (groupValue == null) {\n          if (shardGroupDocs.groupValue != null) {\n            throw new IllegalArgumentException("group values differ across shards; you must pass same top groups to all shards' second-pass collector");\n          }\n        } else if (!groupValue.equals(shardGroupDocs.groupValue)) {\n          throw new IllegalArgumentException("group values differ across shards; you must pass same top groups to all shards' second-pass collector");\n        }\n\n        "      doc="\n\n        if (docSort.equals(Sort.RELEVANCE)) {\n          shardTopDocs[shardIDX] = new TopDocs(shardGroupDocs.totalHits,\n                                               shardGroupDocs.scoreDocs,\n                                               shardGroupDocs.maxScore);\n        } else {\n          shardTopDocs[shardIDX] = new TopFieldDocs(shardGroupDocs.totalHits,\n              shardGroupDocs.scoreDocs,\n              docSort.getSort(),\n              shardGroupDocs.maxScore);\n        }\n        maxScore = Math.max(maxScore, shardGroupDocs.maxScore);\n        totalHits += shardGroupDocs.totalHits;\n        scoreSum += shardGroupDocs.score;\n      }\n\n      final TopDocs mergedTopDocs;\n      if (docSort.equals(Sort.RELEVANCE)) {\n        mergedTopDocs = TopDocs.merge(docOffset + docTopN, shardTopDocs);\n      } else {\n        mergedTopDocs = TopDocs.merge(docSort, docOffset + docTopN, (TopFieldDocs[]) shardTopDocs);\n      }\n\n            final ScoreDoc[] mergedScoreDocs;\n      if (docOffset == 0) {\n        mergedScoreDocs = mergedTopDocs.scoreDocs;\n      } else if (docOffset >= mergedTopDocs.scoreDocs.length) {\n        mergedScoreDocs = new ScoreDoc[0];\n      } else {\n        mergedScoreDocs = new ScoreDoc[mergedTopDocs.scoreDocs.length - docOffset];\n        System.arraycopy(mergedTopDocs.scoreDocs,\n                         docOffset,\n                         mergedScoreDocs,\n                         0,\n                         mergedTopDocs.scoreDocs.length - docOffset);\n      }\n\n      final float groupScore;\n      switch(scoreMergeMode) {\n      case None:\n        groupScore = Float.NaN;\n        break;\n      case Avg:\n        if (totalHits > 0) {\n          groupScore = (float) (scoreSum / totalHits);\n        } else {\n          groupScore = Float.NaN;\n        }\n        break;\n      case Total:\n        groupScore = (float) scoreSum;\n        break;\n      default:\n        throw new IllegalArgumentException("can't handle ScoreMergeMode " + scoreMergeMode);\n      }\n        \n            mergedGroupDocs[groupIDX] = new GroupDocs<>(groupScore,\n                                                   maxScore,\n                                                   totalHits,\n                                                   mergedScoreDocs,\n                                                   groupValue,\n                                                   shardGroups[0].groups[groupIDX].groupSortValues);\n      totalMaxScore = Math.max(totalMaxScore, maxScore);\n    }\n\n    if (totalGroupCount != null) {\n      TopGroups<T> result = new TopGroups<>(groupSort.getSort(),\n                              docSort.getSort(),\n                              totalHitCount,\n                              totalGroupedHitCount,\n                              mergedGroupDocs,\n                              totalMaxScore);\n      return new TopGroups<>(result, totalGroupCount);\n    } else {\n      return new TopGroups<>(groupSort.getSort(),\n                              docSort.getSort(),\n                              totalHitCount,\n                              totalGroupedHitCount,\n                              mergedGroupDocs,\n                              totalMaxScore);\n    }\n  }
479	public static int toCodePoints(char[] src, int srcOff, int srcLen, int[] dest, int destOff) {\n    if (srcLen < 0) {\n      throw new IllegalArgumentException("srcLen must be >= 0");\n    }\n    int codePointCount = 0;\n    for (int i = 0; i < srcLen; ) {\n      final int cp = Character.codePointAt(src, srcOff + i, srcOff + srcLen);\n      final int charCount = Character.charCount(cp);\n      dest[destOff + codePointCount++] = cp;\n      i += charCount;\n    }\n    return codePointCount;\n  }
480	protected synchronized void closeResources() throws IOException {\n    if (initializedReaderManager) {\n      readerManager.close();\n      readerManager = null;\n      initializedReaderManager = false;\n    }\n    if (cache != null) {\n      cache.close();\n    }\n  }
481	private LinkedHashMap<Term,Integer> repeatingTerms() {\n    LinkedHashMap<Term,Integer> tord = new LinkedHashMap<>();\n    HashMap<Term,Integer> tcnt = new HashMap<>();\n    for (PhrasePositions pp : phrasePositions) {\n      for (Term t : pp.terms) {\n        Integer cnt0 = tcnt.get(t);\n        Integer cnt = cnt0==null ? new Integer(1) : new Integer(1+cnt0.intValue());\n        tcnt.put(t, cnt);\n        if (cnt==2) {\n          tord.put(t,tord.size());\n        }\n      }\n    }\n    return tord;\n  }
482	public void add(String dim, Query subQuery) {\n    assert drillDownDims.size() == dimQueries.size();\n    if (drillDownDims.containsKey(dim) == false) {\n      drillDownDims.put(dim, drillDownDims.size());\n      BooleanQuery.Builder builder = new BooleanQuery.Builder();\n      dimQueries.add(builder);\n    }\n    final int index = drillDownDims.get(dim);\n    dimQueries.get(index).add(subQuery, Occur.SHOULD);\n  }
483	private SortedSet<String> getIANARootZoneDatabase() throws IOException {\n    final SortedSet<String> TLDs = new TreeSet<>();\n    final URLConnection connection = tldFileURL.openConnection();\n    connection.setUseCaches(false);\n    connection.addRequestProperty("Cache-Control", "no-cache");\n    connection.connect();\n    tldFileLastModified = connection.getLastModified();\n    BufferedReader reader = new BufferedReader\n      (new InputStreamReader(connection.getInputStream(), StandardCharsets.US_ASCII));\n    try {\n      String line;\n      while (null != (line = reader.readLine())) {\n        Matcher matcher = TLD_PATTERN_1.matcher(line);\n        if (matcher.matches()) {\n          TLDs.add(matcher.group(1).toLowerCase(Locale.ROOT));\n        } else {\n          matcher = TLD_PATTERN_2.matcher(line);\n          if (matcher.matches()) {\n            TLDs.add(matcher.group(1).toLowerCase(Locale.ROOT));\n          }\n        }\n      }\n    } finally {\n      reader.close();\n    }\n    return TLDs;\n  }
484	public static byte getType(int ch) {\n    switch (Character.getType(ch)) {\n      case Character.UPPERCASE_LETTER: return UPPER;\n      case Character.LOWERCASE_LETTER: return LOWER;\n\n      case Character.TITLECASE_LETTER:\n      case Character.MODIFIER_LETTER:\n      case Character.OTHER_LETTER:\n      case Character.NON_SPACING_MARK:\n      case Character.ENCLOSING_MARK:        case Character.COMBINING_SPACING_MARK:\n        return ALPHA; \n\n      case Character.DECIMAL_DIGIT_NUMBER:\n      case Character.LETTER_NUMBER:\n      case Character.OTHER_NUMBER:\n        return DIGIT;\n\n                                    \n      case Character.SURROGATE:          return ALPHA|DIGIT;  \n\n                                                                  \n      default: return SUBWORD_DELIM;\n    }\n  }
485	private void resubstitute( StringBuilder buffer )\n    {\n      for ( int c = 0; c < buffer.length(); c++ ) {\n        if ( buffer.charAt( c ) == '*' ) {\n          char x = buffer.charAt( c - 1 );\n          buffer.setCharAt( c, x );\n        }\n        else if ( buffer.charAt( c ) == '$' ) {\n          buffer.setCharAt( c, 's' );\n          buffer.insert( c + 1, new char[]{'c', 'h'}, 0, 2 );\n        }\n        else if ( buffer.charAt( c ) == '§' ) {\n          buffer.setCharAt( c, 'c' );\n          buffer.insert( c + 1, 'h' );\n        }\n        else if ( buffer.charAt( c ) == '%' ) {\n          buffer.setCharAt( c, 'e' );\n          buffer.insert( c + 1, 'i' );\n        }\n        else if ( buffer.charAt( c ) == '&' ) {\n          buffer.setCharAt( c, 'i' );\n          buffer.insert( c + 1, 'e' );\n        }\n        else if ( buffer.charAt( c ) == '#' ) {\n          buffer.setCharAt( c, 'i' );\n          buffer.insert( c + 1, 'g' );\n        }\n        else if ( buffer.charAt( c ) == '!' ) {\n          buffer.setCharAt( c, 's' );\n          buffer.insert( c + 1, 't' );\n        }\n      }\n    }
486	private boolean handleFetchFiles(Random random, Socket socket, DataInput destIn, DataOutput destOut, BufferedOutputStream bos) throws IOException {\n    Thread.currentThread().setName("send");\n\n    int replicaID = destIn.readVInt();\n    message("top: start fetch for R" + replicaID + " socket=" + socket);\n    byte b = destIn.readByte();\n    CopyState copyState;\n    if (b == 0) {\n            copyState = null;\n    } else if (b == 1) {\n            copyState = getCopyState();\n      Thread.currentThread().setName("send-R" + replicaID + "-" + copyState.version);\n    } else {\n            throw new IllegalArgumentException("invalid CopyState byte=" + b);\n    }\n\n    try {\n      if (copyState != null) {\n                writeCopyState(copyState, destOut);\n        bos.flush();\n      }\n\n      byte[] buffer = new byte[16384];\n      int fileCount = 0;\n      long totBytesSent = 0;\n      while (true) {\n        byte done = destIn.readByte();\n        if (done == 1) {\n          break;\n        } else if (done != 0) {\n          throw new IllegalArgumentException("expected 0 or 1 byte but got " + done);\n        }\n\n                String fileName = destIn.readString();\n\n                long fpStart = destIn.readVLong();\n\n        try (IndexInput in = dir.openInput(fileName, IOContext.DEFAULT)) {\n          long len = in.length();\n                    destOut.writeVLong(len);\n          in.seek(fpStart);\n          long upto = fpStart;\n          while (upto < len) {\n            int chunk = (int) Math.min(buffer.length, (len-upto));\n            in.readBytes(buffer, 0, chunk);\n            if (doFlipBitsDuringCopy) {\n              if (random.nextInt(3000) == 17 && bitFlipped.contains(fileName) == false) {\n                bitFlipped.add(fileName);\n                message("file " + fileName + " to R" + replicaID + ": now randomly flipping a bit at byte=" + upto);\n                int x = random.nextInt(chunk);\n                int bit = random.nextInt(8);\n                buffer[x] ^= 1 << bit;\n              }\n            }\n            destOut.writeBytes(buffer, 0, chunk);\n            upto += chunk;\n            totBytesSent += chunk;\n          }\n        }\n\n        fileCount++;\n      }\n\n      message("top: done fetch files for R" + replicaID + ": sent " + fileCount + " files; sent " + totBytesSent + " bytes");\n    } catch (Throwable t) {\n      message("top: exception during fetch: " + t.getMessage() + "; now close socket");\n      socket.close();\n      return false;\n    } finally {\n      if (copyState != null) {\n        message("top: fetch: now release CopyState");\n        releaseCopyState(copyState);\n      }\n    }\n\n    return true;\n  }
487	private static void sumHistogram(int[] histogram, int[] endOffsets) {\n    int accum = 0;\n    for (int i = 0; i < HISTOGRAM_SIZE; ++i) {\n      final int count = histogram[i];\n      histogram[i] = accum;\n      accum += count;\n      endOffsets[i] = accum;\n    }\n  }
488	public static byte[] randomId() {\n\n                                                    \n    byte bits[];\n    synchronized(idLock) {\n      bits = nextId.toByteArray();\n      nextId = nextId.add(BigInteger.ONE).and(mask128);\n    }\n    \n        if (bits.length > ID_LENGTH) {\n      assert bits.length == ID_LENGTH + 1;\n      assert bits[0] == 0;\n      return Arrays.copyOfRange(bits, 1, bits.length);\n    } else {\n      byte[] result = new byte[ID_LENGTH];\n      System.arraycopy(bits, 0, result, result.length - bits.length, bits.length);\n      return result;\n    }\n  }
489	private BigDecimal parseNumber(NumberBuffer buffer) {\n    BigDecimal sum = BigDecimal.ZERO;\n    BigDecimal result = parseLargePair(buffer);\n\n    if (result == null) {\n      return null;\n    }\n\n    while (result != null) {\n      sum = sum.add(result);\n      result = parseLargePair(buffer);\n    }\n\n    return sum;\n  }
490	private BigDecimal parseMediumPair(NumberBuffer buffer) {\n\n    BigDecimal first = parseBasicNumber(buffer);\n    BigDecimal second = parseMediumKanjiNumeral(buffer);\n\n    if (first == null && second == null) {\n      return null;\n    }\n\n    if (second == null) {\n                  return first;\n    }\n\n    if (first == null) {\n                  return second;\n    }\n\n        return first.multiply(second);\n  }
491	synchronized void maybeThrowDeterministicException() throws IOException {\n    if (failures != null) {\n      for(int i = 0; i < failures.size(); i++) {\n        try {\n          failures.get(i).eval(this);\n        } catch (Throwable t) {\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println("MockDirectoryWrapper: throw exc");\n            t.printStackTrace(System.out);\n          }\n          throw IOUtils.rethrowAlways(t);\n        }\n      }\n    }\n  }
492	public static Plane constructNormalizedXPlane(final Vector... planePoints) {\n        double bestDistance = 0.0;\n    Vector bestPoint = null;\n    for (final Vector point : planePoints) {\n      final double pointDist = point.y * point.y + point.z * point.z;\n      if (pointDist > bestDistance) {\n        bestDistance = pointDist;\n        bestPoint = point;\n      }\n    }\n    return constructNormalizedXPlane(bestPoint.y, bestPoint.z, 0.0);\n  }
493	public int allocSlice(final byte[] slice, final int upto) {\n\n    final int level = slice[upto] & 15;\n    final int newLevel = NEXT_LEVEL_ARRAY[level];\n    final int newSize = LEVEL_SIZE_ARRAY[newLevel];\n\n        if (byteUpto > BYTE_BLOCK_SIZE-newSize) {\n      nextBuffer();\n    }\n\n    final int newUpto = byteUpto;\n    final int offset = newUpto + byteOffset;\n    byteUpto += newSize;\n\n            buffer[newUpto] = slice[upto-3];\n    buffer[newUpto+1] = slice[upto-2];\n    buffer[newUpto+2] = slice[upto-1];\n\n        slice[upto-3] = (byte) (offset >>> 24);\n    slice[upto-2] = (byte) (offset >>> 16);\n    slice[upto-1] = (byte) (offset >>> 8);\n    slice[upto] = (byte) offset;\n        \n        buffer[byteUpto-1] = (byte) (16|newLevel);\n\n    return newUpto+3;\n  }
494	protected int isGeoAreaShapeInsideShape(final GeoShape geoshape)  {\n    boolean foundOutside = false;\n    boolean foundInside = false;\n    for (GeoPoint p : getEdgePoints()) {\n      if (geoshape.isWithin(p)) {\n        foundInside = true;\n      } else {\n        foundOutside = true;\n      }\n      if (foundInside && foundOutside) {\n        return SOME_INSIDE;\n      }\n    }\n    if (!foundInside && !foundOutside)\n      return NONE_INSIDE;\n    if (foundInside && !foundOutside)\n      return ALL_INSIDE;\n    if (foundOutside && !foundInside)\n      return NONE_INSIDE;\n    return SOME_INSIDE;\n  }
495	public synchronized void finished(FrozenBufferedUpdates packet) {\n                assert packet.applied.getCount() == 1: "packet=" + packet;\n\n    packet.applied.countDown();\n\n    updates.remove(packet);\n    numTerms.addAndGet(-packet.numTermDeletes);\n    assert numTerms.get() >= 0: "numTerms=" + numTerms + " packet=" + packet;\n    \n    bytesUsed.addAndGet(-packet.bytesUsed);\n\n    finishedSegment(packet.delGen());\n  }
496	private void capture() {\n    assert liveToken;\n    liveToken = false;\n    BufferedInputToken token = lookahead.get(lookaheadNextWrite);\n    lookaheadNextWrite++;\n\n    token.state = captureState();\n    token.startOffset = offsetAtt.startOffset();\n    token.endOffset = offsetAtt.endOffset();\n    assert token.term.length() == 0;\n    token.term.append(termAtt);\n\n    captureCount++;\n    maxLookaheadUsed = Math.max(maxLookaheadUsed, lookahead.getBufferSize());\n      }
497	public void bufferSkip(int df) throws IOException {\n\n    assert df % skipInterval == 0;\n    int numLevels = 1;\n    df /= skipInterval;\n   \n        while ((df % skipMultiplier) == 0 && numLevels < numberOfSkipLevels) {\n      numLevels++;\n      df /= skipMultiplier;\n    }\n    \n    long childPointer = 0;\n    \n    for (int level = 0; level < numLevels; level++) {\n      writeSkipData(level, skipBuffer[level]);\n      \n      long newChildPointer = skipBuffer[level].getFilePointer();\n      \n      if (level != 0) {\n                skipBuffer[level].writeVLong(childPointer);\n      }\n      \n            childPointer = newChildPointer;\n    }\n  }
498	private void initSimple() throws IOException {\n        pq.clear();\n        for (PhrasePositions pp : phrasePositions) {\n      pp.firstPosition();\n      if (pp.position > end) {\n        end = pp.position;\n      }\n      pq.add(pp);\n    }\n  }
499	private static void checkFunction(Method method) {\n        final MethodType type;\n    try {\n      type = MethodHandles.publicLookup().unreflect(method).type();\n    } catch (IllegalAccessException iae) {\n      throw new IllegalArgumentException(method + " is not accessible (declaring class or method not public).");\n    }\n        if (!Modifier.isStatic(method.getModifiers())) {\n      throw new IllegalArgumentException(method + " is not static.");\n    }\n    for (int arg = 0, arity = type.parameterCount(); arg < arity; arg++) {\n      if (type.parameterType(arg) != double.class) {\n        throw new IllegalArgumentException(method + " must take only double parameters.");\n      }\n    }\n    if (type.returnType() != double.class) {\n      throw new IllegalArgumentException(method + " does not return a double.");\n    }\n  }
500	private FacetResult drillDown() throws IOException {\n    DirectoryReader indexReader = DirectoryReader.open(indexDir);\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);\n\n            DrillDownQuery q = new DrillDownQuery(config);\n\n        q.add("tags", "solr");\n    FacetsCollector fc = new FacetsCollector();\n    FacetsCollector.search(searcher, q, 10, fc);\n\n        Facets facets = new TaxonomyFacetSumFloatAssociations("$genre", taxoReader, config, fc);\n    FacetResult result = facets.getTopChildren(10, "genre");\n\n    indexReader.close();\n    taxoReader.close();\n    \n    return result;\n  }
501	public Term[] getStopWords() {\n    List<Term> allStopWords = new ArrayList<>();\n    for (String fieldName : stopWordsPerField.keySet()) {\n      Set<String> stopWords = stopWordsPerField.get(fieldName);\n      for (String text : stopWords) {\n        allStopWords.add(new Term(fieldName, text));\n      }\n    }\n    return allStopWords.toArray(new Term[allStopWords.size()]);\n  }
502	public GeoPoint surfacePointOnBearing(final GeoPoint from, final double dist, final double bearing) {\n            \n    double lat = from.getLatitude();\n    double lon = from.getLongitude();\n    double sinα1 = Math.sin(bearing);\n    double cosα1 = Math.cos(bearing);\n\n    double tanU1 = (1.0 - flattening) * Math.tan(lat);\n    double cosU1 = 1.0 / Math.sqrt((1.0 + tanU1 * tanU1));\n    double sinU1 = tanU1 * cosU1;\n\n    double σ1 = Math.atan2(tanU1, cosα1);\n    double sinα = cosU1 * sinα1;\n    double cosSqα = 1.0 - sinα * sinα;\n    double uSq = cosSqα * squareRatio;\n    double A = 1.0 + uSq / 16384.0 * (4096.0 + uSq * (-768.0 + uSq * (320.0 - 175.0 * uSq)));\n    double B = uSq / 1024.0 * (256.0 + uSq * (-128.0 + uSq * (74.0 - 47.0 * uSq)));\n\n    double cos2σM;\n    double sinσ;\n    double cosσ;\n    double Δσ;\n\n    double σ = dist / (c * inverseScale * A);\n    double σʹ;\n    double iterations = 0;\n    do {\n      cos2σM = Math.cos(2.0 * σ1 + σ);\n      sinσ = Math.sin(σ);\n      cosσ = Math.cos(σ);\n      Δσ = B * sinσ * (cos2σM + B / 4.0 * (cosσ * (-1.0 + 2.0 * cos2σM * cos2σM) -\n          B / 6.0 * cos2σM * (-3.0 + 4.0 * sinσ * sinσ) * (-3.0 + 4.0 * cos2σM * cos2σM)));\n      σʹ = σ;\n      σ = dist / (c * inverseScale * A) + Δσ;\n    } while (Math.abs(σ - σʹ) >= Vector.MINIMUM_RESOLUTION && ++iterations < 100);\n    double x = sinU1 * sinσ - cosU1 * cosσ * cosα1;\n    double φ2 = Math.atan2(sinU1 * cosσ + cosU1 * sinσ * cosα1, (1.0 - flattening) * Math.sqrt(sinα * sinα + x * x));\n    double λ = Math.atan2(sinσ * sinα1, cosU1 * cosσ - sinU1 * sinσ * cosα1);\n    double C = flattening / 16.0 * cosSqα * (4.0 + flattening * (4.0 - 3.0 * cosSqα));\n    double L = λ - (1.0 - C) * flattening * sinα *\n        (σ + C * sinσ * (cos2σM + C * cosσ * (-1.0 + 2.0 * cos2σM * cos2σM)));\n    double λ2 = (lon + L + 3.0 * Math.PI) % (2.0 * Math.PI) - Math.PI;  \n    return new GeoPoint(this, φ2, λ2);\n  }
503	public static long shallowSizeOf(Object obj) {\n    if (obj == null) return 0;\n    final Class<?> clz = obj.getClass();\n    if (clz.isArray()) {\n      return shallowSizeOfArray(obj);\n    } else {\n      return shallowSizeOfInstance(clz);\n    }\n  }
504	protected Query newPhraseQuery(String text, int slop) {\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    for (Map.Entry<String,Float> entry : weights.entrySet()) {\n      Query q = createPhraseQuery(entry.getKey(), text, slop);\n      if (q != null) {\n        float boost = entry.getValue();\n        if (boost != 1f) {\n          q = new BoostQuery(q, boost);\n        }\n        bq.add(q, BooleanClause.Occur.SHOULD);\n      }\n    }\n    return simplify(bq.build());\n  }
505	private PriorityQueue<ScoreTerm> createQueue(Map<String, Map<String, Int>> perFieldTermFrequencies) throws IOException {\n        int numDocs = ir.numDocs();\n    final int limit = Math.min(maxQueryTerms, this.getTermsCount(perFieldTermFrequencies));\n    FreqQ queue = new FreqQ(limit);     for (Map.Entry<String, Map<String, Int>> entry : perFieldTermFrequencies.entrySet()) {\n      Map<String, Int> perWordTermFrequencies = entry.getValue();\n      String fieldName = entry.getKey();\n\n      for (Map.Entry<String, Int> tfEntry : perWordTermFrequencies.entrySet()) {         String word = tfEntry.getKey();\n        int tf = tfEntry.getValue().x;         if (minTermFreq > 0 && tf < minTermFreq) {\n          continue;         }\n\n        int docFreq = ir.docFreq(new Term(fieldName, word));\n\n        if (minDocFreq > 0 && docFreq < minDocFreq) {\n          continue;         }\n\n        if (docFreq > maxDocFreq) {\n          continue;         }\n\n        if (docFreq == 0) {\n          continue;         }\n\n        float idf = similarity.idf(docFreq, numDocs);\n        float score = tf * idf;\n\n        if (queue.size() < limit) {\n                    queue.add(new ScoreTerm(word, fieldName, score, idf, docFreq, tf));\n        } else {\n          ScoreTerm term = queue.top();\n          if (term.score < score) {             term.update(word, fieldName, score, idf, docFreq, tf);\n            queue.updateTop();\n          }\n        }\n      }\n    }\n    return queue;\n  }
506	public static CharArraySet getWordSet(Reader reader, CharArraySet result) throws IOException {\n    BufferedReader br = null;\n    try {\n      br = getBufferedReader(reader);\n      String word = null;\n      while ((word = br.readLine()) != null) {\n        result.add(word.trim());\n      }\n    }\n    finally {\n      IOUtils.close(br);\n    }\n    return result;\n  }
507	protected Query analyzeBoolean(String field, TokenStream stream) throws IOException {\n    TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    \n    stream.reset();\n    List<Term> terms = new ArrayList<>();\n    while (stream.incrementToken()) {\n      terms.add(new Term(field, termAtt.getBytesRef()));\n    }\n    \n    return newSynonymQuery(terms.toArray(new Term[terms.size()]));\n  }
508	private void concatenate(WordDelimiterConcatenation concatenation) {\n    if (concatenation.isEmpty()) {\n      concatenation.type = iterator.type();\n      concatenation.startPart = iterator.current;\n      concatenation.startPos = wordPos;\n    }\n    concatenation.append(savedTermBuffer, iterator.current, iterator.end - iterator.current);\n    concatenation.endPart = iterator.end;\n  }
509	public void perform(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n    String[] pathElements = getPathElements(req);\n    \n    if (pathElements.length != 2) {\n      throw new ServletException("invalid path, must contain shard ID and action, e.g. */s1/update");\n    }\n    \n    final ReplicationAction action;\n    try {\n      action = ReplicationAction.valueOf(pathElements[ACTION_IDX].toUpperCase(Locale.ENGLISH));\n    } catch (IllegalArgumentException e) {\n      throw new ServletException("Unsupported action provided: " + pathElements[ACTION_IDX]);\n    }\n    \n    final Replicator replicator = replicators.get(pathElements[SHARD_IDX]);\n    if (replicator == null) {\n      throw new ServletException("unrecognized shard ID " + pathElements[SHARD_IDX]);\n    }\n    \n        ServletOutputStream resOut = resp.getOutputStream();\n    try {\n      switch (action) {\n        case OBTAIN:\n          final String sessionID = extractRequestParam(req, REPLICATE_SESSION_ID_PARAM);\n          final String fileName = extractRequestParam(req, REPLICATE_FILENAME_PARAM);\n          final String source = extractRequestParam(req, REPLICATE_SOURCE_PARAM);\n          InputStream in = replicator.obtainFile(sessionID, source, fileName);\n          try {\n            copy(in, resOut);\n          } finally {\n            in.close();\n          }\n          break;\n        case RELEASE:\n          replicator.release(extractRequestParam(req, REPLICATE_SESSION_ID_PARAM));\n          break;\n        case UPDATE:\n          String currVersion = req.getParameter(REPLICATE_VERSION_PARAM);\n          SessionToken token = replicator.checkForUpdate(currVersion);\n          if (token == null) {\n            resOut.write(0);           } else {\n            resOut.write(1);\n            token.serialize(new DataOutputStream(resOut));\n          }\n          break;\n      }\n    } catch (Exception e) {\n      resp.setStatus(HttpStatus.SC_INTERNAL_SERVER_ERROR);       try {\n        "identified exceptions"\n        ObjectOutputStream oos = new ObjectOutputStream(resOut);\n        oos.writeObject(e);\n        oos.flush();\n      } catch (Exception e2) {\n        throw new IOException("Could not serialize", e2);\n      }\n    } finally {\n      resp.flushBuffer();\n    }\n  }
510	private boolean checkCondition(int condition, char c1[], int c1off, int c1len, char c2[], int c2off, int c2len) {\n    if (condition != 0) {\n      CharacterRunAutomaton pattern = dictionary.patterns.get(condition);\n      int state = 0;\n      for (int i = c1off; i < c1off + c1len; i++) {\n        state = pattern.step(state, c1[i]);\n        if (state == -1) {\n          return false;\n        }\n      }\n      for (int i = c2off; i < c2off + c2len; i++) {\n        state = pattern.step(state, c2[i]);\n        if (state == -1) {\n          return false;\n        }\n      }\n      return pattern.isAccept(state);\n    }\n    return true;\n  }
511	public static GeoPolygon makeGeoPolygon(final PlanetModel planetModel,\n    final List<GeoPoint> pointList,\n    final List<GeoPolygon> holes,\n    final double leniencyValue) {\n                final List<GeoPoint> firstFilteredPointList = filterPoints(pointList);\n    if (firstFilteredPointList == null) {\n      return null;\n    }\n    final List<GeoPoint> filteredPointList = filterEdges(firstFilteredPointList, leniencyValue);\n        if (filteredPointList == null) {\n      return null;\n    }\n                final Random generator = new Random(1234);\n    for (int counter = 0; counter < 1000000; counter++) {\n                  final GeoPoint pole = pickPole(generator, planetModel, filteredPointList);\n            final Boolean isPoleInside = isInsidePolygon(pole, filteredPointList);\n      if (isPoleInside != null) {\n                                return generateGeoPolygon(planetModel, filteredPointList, holes, pole, isPoleInside);\n      }\n          }\n    throw new IllegalArgumentException("cannot find a point that is inside the polygon "+filteredPointList);\n  }
512	private void indexDocValue(PerField fp, DocValuesType dvType, IndexableField field) throws IOException {\n\n    if (fp.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n                        fieldInfos.globalFieldNumbers.setDocValuesType(fp.fieldInfo.number, fp.fieldInfo.name, dvType);\n    }\n    fp.fieldInfo.setDocValuesType(dvType);\n\n    int docID = docState.docID;\n\n    switch(dvType) {\n\n      case NUMERIC:\n        if (fp.docValuesWriter == null) {\n          fp.docValuesWriter = new NumericDocValuesWriter(fp.fieldInfo, bytesUsed);\n        }\n        ((NumericDocValuesWriter) fp.docValuesWriter).addValue(docID, field.numericValue().longValue());\n        break;\n\n      case BINARY:\n        if (fp.docValuesWriter == null) {\n          fp.docValuesWriter = new BinaryDocValuesWriter(fp.fieldInfo, bytesUsed);\n        }\n        ((BinaryDocValuesWriter) fp.docValuesWriter).addValue(docID, field.binaryValue());\n        break;\n\n      case SORTED:\n        if (fp.docValuesWriter == null) {\n          fp.docValuesWriter = new SortedDocValuesWriter(fp.fieldInfo, bytesUsed);\n        }\n        ((SortedDocValuesWriter) fp.docValuesWriter).addValue(docID, field.binaryValue());\n        break;\n        \n      case SORTED_NUMERIC:\n        if (fp.docValuesWriter == null) {\n          fp.docValuesWriter = new SortedNumericDocValuesWriter(fp.fieldInfo, bytesUsed);\n        }\n        ((SortedNumericDocValuesWriter) fp.docValuesWriter).addValue(docID, field.numericValue().longValue());\n        break;\n\n      case SORTED_SET:\n        if (fp.docValuesWriter == null) {\n          fp.docValuesWriter = new SortedSetDocValuesWriter(fp.fieldInfo, bytesUsed);\n        }\n        ((SortedSetDocValuesWriter) fp.docValuesWriter).addValue(docID, field.binaryValue());\n        break;\n\n      default:\n        throw new AssertionError("unrecognized DocValues.Type: " + dvType);\n    }\n  }
513	public boolean store(DataOutput output) throws IOException {\n    final FST<PairOutputs.Pair<Long, BytesRef>> build = builder.finish();\n    if (build == null) {\n      return false;\n    }\n    build.save(output);\n\n    \n    assert maxAnalyzedPathsPerOutput > 0;\n    output.writeVInt(maxAnalyzedPathsPerOutput);\n    output.writeVInt(END_BYTE);\n    output.writeVInt(PAYLOAD_SEP);\n    return true;\n  }
514	public GeoPoint[] interpolate(final GeoPoint start, final GeoPoint end, final double[] proportions) {\n                                                                                                                                                                \n        double A = x;\n    double B = y;\n    double C = z;\n\n        final double transX = -D * A;\n    final double transY = -D * B;\n    final double transZ = -D * C;\n\n    double cosRA;\n    double sinRA;\n    double cosHA;\n    double sinHA;\n\n    double magnitude = magnitude();\n    if (magnitude >= MINIMUM_RESOLUTION) {\n      final double denom = 1.0 / magnitude;\n      A *= denom;\n      B *= denom;\n      C *= denom;\n\n                              final double xyMagnitude = Math.sqrt(A * A + B * B);\n      if (xyMagnitude >= MINIMUM_RESOLUTION) {\n        final double xyDenom = 1.0 / xyMagnitude;\n        cosRA = A * xyDenom;\n        sinRA = -B * xyDenom;\n      } else {\n        cosRA = 1.0;\n        sinRA = 0.0;\n      }\n\n                  sinHA = xyMagnitude;\n      cosHA = C;\n    } else {\n      cosRA = 1.0;\n      sinRA = 0.0;\n      cosHA = 1.0;\n      sinHA = 0.0;\n    }\n\n        final Vector modifiedStart = modify(start, transX, transY, transZ, sinRA, cosRA, sinHA, cosHA);\n    final Vector modifiedEnd = modify(end, transX, transY, transZ, sinRA, cosRA, sinHA, cosHA);\n    if (Math.abs(modifiedStart.z) >= MINIMUM_RESOLUTION)\n      throw new IllegalArgumentException("Start point was not on plane: " + modifiedStart.z);\n    if (Math.abs(modifiedEnd.z) >= MINIMUM_RESOLUTION)\n      throw new IllegalArgumentException("End point was not on plane: " + modifiedEnd.z);\n\n        final double startAngle = Math.atan2(modifiedStart.y, modifiedStart.x);\n    final double endAngle = Math.atan2(modifiedEnd.y, modifiedEnd.x);\n\n    final double startMagnitude = Math.sqrt(modifiedStart.x * modifiedStart.x + modifiedStart.y * modifiedStart.y);\n    double delta;\n\n    double newEndAngle = endAngle;\n    while (newEndAngle < startAngle) {\n      newEndAngle += Math.PI * 2.0;\n    }\n\n    if (newEndAngle - startAngle <= Math.PI) {\n      delta = newEndAngle - startAngle;\n    } else {\n      double newStartAngle = startAngle;\n      while (newStartAngle < endAngle) {\n        newStartAngle += Math.PI * 2.0;\n      }\n      delta = newStartAngle - endAngle;\n    }\n\n    final GeoPoint[] returnValues = new GeoPoint[proportions.length];\n    for (int i = 0; i < returnValues.length; i++) {\n      final double newAngle = startAngle + proportions[i] * delta;\n      final double sinNewAngle = Math.sin(newAngle);\n      final double cosNewAngle = Math.cos(newAngle);\n      final Vector newVector = new Vector(cosNewAngle * startMagnitude, sinNewAngle * startMagnitude, 0.0);\n      returnValues[i] = reverseModify(newVector, transX, transY, transZ, sinRA, cosRA, sinHA, cosHA);\n    }\n\n    return returnValues;\n  }
515	public static long pop_andnot(long[] arr1, long[] arr2, int wordOffset, int numWords) {\n    long popCount = 0;\n    for (int i = wordOffset, end = wordOffset + numWords; i < end; ++i) {\n      popCount += Long.bitCount(arr1[i] & ~arr2[i]);\n    }\n    return popCount;\n  }
516	public String toString(Calendar cal) {\n    final int calPrecField = getCalPrecisionField(cal);    if (calPrecField == -1)\n      return "*";\n    try {\n      StringBuilder builder = new StringBuilder("yyyy-MM-dd'T'HH:mm:ss.SSS".length());      int year = cal.get(Calendar.YEAR);       if (cal.get(Calendar.ERA) == 0) {         year -= 1;         if (year > 0) {\n          builder.append('-');\n        }\n      } else if (year > 9999) {\n        builder.append('+');\n      }\n      appendPadded(builder, year, (short) 4);\n      if (calPrecField >= Calendar.MONTH) {\n        builder.append('-');\n        appendPadded(builder, cal.get(Calendar.MONTH) + 1, (short) 2);       }\n      if (calPrecField >= Calendar.DAY_OF_MONTH) {\n        builder.append('-');\n        appendPadded(builder, cal.get(Calendar.DAY_OF_MONTH), (short) 2);\n      }\n      if (calPrecField >= Calendar.HOUR_OF_DAY) {\n        builder.append('T');\n        appendPadded(builder, cal.get(Calendar.HOUR_OF_DAY), (short) 2);\n      }\n      if (calPrecField >= Calendar.MINUTE) {\n        builder.append(':');\n        appendPadded(builder, cal.get(Calendar.MINUTE), (short) 2);\n      }\n      if (calPrecField >= Calendar.SECOND) {\n        builder.append(':');\n        appendPadded(builder, cal.get(Calendar.SECOND), (short) 2);\n      }\n      if (calPrecField >= Calendar.MILLISECOND && cal.get(Calendar.MILLISECOND) > 0) {         builder.append('.');\n        appendPadded(builder,  cal.get(Calendar.MILLISECOND), (short) 3);\n      }\n\n      return builder.toString();\n    } finally {\n      clearFieldsAfter(cal, calPrecField);    }\n  }
517	public final BytesRef normalize(final String fieldName, final String text) {\n    try {\n            final String filteredText;\n      try (Reader reader = new StringReader(text)) {\n        Reader filterReader = initReaderForNormalization(fieldName, reader);\n        char[] buffer = new char[64];\n        StringBuilder builder = new StringBuilder();\n        for (;;) {\n          final int read = filterReader.read(buffer, 0, buffer.length);\n          if (read == -1) {\n            break;\n          }\n          builder.append(buffer, 0, read);\n        }\n        filteredText = builder.toString();\n      } catch (IOException e) {\n        throw new IllegalStateException("Normalization threw an unexpected exception", e);\n      }\n\n      final AttributeFactory attributeFactory = attributeFactory(fieldName);\n      try (TokenStream ts = normalize(fieldName,\n          new StringTokenStream(attributeFactory, filteredText, text.length()))) {\n        final TermToBytesRefAttribute termAtt = ts.addAttribute(TermToBytesRefAttribute.class);\n        ts.reset();\n        if (ts.incrementToken() == false) {\n          throw new IllegalStateException("The normalization token stream is "\n              + "expected to produce exactly 1 token, but got 0 for analyzer "\n              + this + " and input \"" + text + "\"");\n        }\n        final BytesRef term = BytesRef.deepCopyOf(termAtt.getBytesRef());\n        if (ts.incrementToken()) {\n          throw new IllegalStateException("The normalization token stream is "\n              + "expected to produce exactly 1 token, but got 2+ for analyzer "\n              + this + " and input \"" + text + "\"");\n        }\n        ts.end();\n        return term;\n      }\n    } catch (IOException e) {\n      throw new IllegalStateException("Normalization threw an unexpected exception", e);\n    }\n  }
518	public QualityQuery[] readQueries(BufferedReader reader) throws IOException {\n    ArrayList<QualityQuery> res = new ArrayList<>();\n    StringBuilder sb;\n    try {\n      while (null!=(sb=read(reader,"<top>",null,false,false))) {\n        HashMap<String,String> fields = new HashMap<>();\n                sb = read(reader,"<num>",null,true,false);\n        int k = sb.indexOf(":");\n        String id = sb.substring(k+1).trim();\n                sb = read(reader,"<title>",null,true,false);\n        k = sb.indexOf(">");\n        String title = sb.substring(k+1).trim();\n                read(reader,"<desc>",null,false,false);\n        sb.setLength(0);\n        String line = null;\n        while ((line = reader.readLine()) != null) {\n          if (line.startsWith("<narr>"))\n            break;\n          if (sb.length() > 0) sb.append(' ');\n          sb.append(line);\n        }\n        String description = sb.toString().trim();\n                sb.setLength(0);\n        while ((line = reader.readLine()) != null) {\n          if (line.startsWith("</top>"))\n            break;\n          if (sb.length() > 0) sb.append(' ');\n          sb.append(line);\n        }\n        String narrative = sb.toString().trim();\n                fields.put("title",title);\n        fields.put("description",description);\n        fields.put("narrative", narrative);\n        QualityQuery topic = new QualityQuery(id,fields);\n        res.add(topic);\n      }\n    } finally {\n      reader.close();\n    }\n        QualityQuery qq[] = res.toArray(new QualityQuery[0]);\n    Arrays.sort(qq);\n    return qq;\n  }
519	public boolean crosses(final PlanetModel planetModel, final Plane q, final GeoPoint[] notablePoints, final GeoPoint[] moreNotablePoints, final Membership[] bounds, final Membership... moreBounds) {\n                        if (isNumericallyIdentical(q)) {\n                        for (GeoPoint p : notablePoints) {\n        if (meetsAllBounds(p, bounds, moreBounds)) {\n                    return true;\n        }\n      }\n      for (GeoPoint p : moreNotablePoints) {\n        if (meetsAllBounds(p, bounds, moreBounds)) {\n                    return true;\n        }\n      }\n            return false;\n    }\n    \n                final double lineVectorX = y * q.z - z * q.y;\n    final double lineVectorY = z * q.x - x * q.z;\n    final double lineVectorZ = x * q.y - y * q.x;\n\n    if (Math.abs(lineVectorX) < MINIMUM_RESOLUTION && Math.abs(lineVectorY) < MINIMUM_RESOLUTION && Math.abs(lineVectorZ) < MINIMUM_RESOLUTION) {\n                  return false;\n    }\n\n                                                                                double x0;\n    double y0;\n    double z0;\n        final double denomYZ = this.y * q.z - this.z * q.y;\n    final double denomXZ = this.x * q.z - this.z * q.x;\n    final double denomXY = this.x * q.y - this.y * q.x;\n    if (Math.abs(denomYZ) >= Math.abs(denomXZ) && Math.abs(denomYZ) >= Math.abs(denomXY)) {\n            if (Math.abs(denomYZ) < MINIMUM_RESOLUTION_SQUARED) {\n                return false;\n      }\n      final double denom = 1.0 / denomYZ;\n      x0 = 0.0;\n      y0 = (-this.D * q.z - this.z * -q.D) * denom;\n      z0 = (this.y * -q.D + this.D * q.y) * denom;\n    } else if (Math.abs(denomXZ) >= Math.abs(denomXY) && Math.abs(denomXZ) >= Math.abs(denomYZ)) {\n            if (Math.abs(denomXZ) < MINIMUM_RESOLUTION_SQUARED) {\n                return false;\n      }\n      final double denom = 1.0 / denomXZ;\n      x0 = (-this.D * q.z - this.z * -q.D) * denom;\n      y0 = 0.0;\n      z0 = (this.x * -q.D + this.D * q.x) * denom;\n    } else {\n            if (Math.abs(denomXY) < MINIMUM_RESOLUTION_SQUARED) {\n                return false;\n      }\n      final double denom = 1.0 / denomXY;\n      x0 = (-this.D * q.y - this.y * -q.D) * denom;\n      y0 = (this.x * -q.D + this.D * q.x) * denom;\n      z0 = 0.0;\n    }\n\n                                final double A = lineVectorX * lineVectorX * planetModel.inverseAbSquared +\n      lineVectorY * lineVectorY * planetModel.inverseAbSquared +\n      lineVectorZ * lineVectorZ * planetModel.inverseCSquared;\n    final double B = 2.0 * (lineVectorX * x0 * planetModel.inverseAbSquared + lineVectorY * y0 * planetModel.inverseAbSquared + lineVectorZ * z0 * planetModel.inverseCSquared);\n    final double C = x0 * x0 * planetModel.inverseAbSquared + y0 * y0 * planetModel.inverseAbSquared + z0 * z0 * planetModel.inverseCSquared - 1.0;\n\n    final double BsquaredMinus = B * B - 4.0 * A * C;\n    if (Math.abs(BsquaredMinus) < MINIMUM_RESOLUTION_SQUARED) {\n                  return false;\n    } else if (BsquaredMinus > 0.0) {\n            final double inverse2A = 1.0 / (2.0 * A);\n            final double sqrtTerm = Math.sqrt(BsquaredMinus);\n      final double t1 = (-B + sqrtTerm) * inverse2A;\n      final double t2 = (-B - sqrtTerm) * inverse2A;\n            final double point1X = lineVectorX * t1 + x0;\n      final double point1Y = lineVectorY * t1 + y0;\n      final double point1Z = lineVectorZ * t1 + z0;\n      boolean point1Valid = true;\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(point1X, point1Y, point1Z)) {\n          point1Valid = false;\n          break;\n        }\n      }\n      if (point1Valid) {\n        for (final Membership bound : moreBounds) {\n          if (!bound.isWithin(point1X, point1Y, point1Z)) {\n            point1Valid = false;\n            break;\n          }\n        }\n      }\n      if (point1Valid) {\n        return true;\n      }\n      final double point2X = lineVectorX * t2 + x0;\n      final double point2Y = lineVectorY * t2 + y0;\n      final double point2Z = lineVectorZ * t2 + z0;\n      for (final Membership bound : bounds) {\n        if (!bound.isWithin(point2X, point2Y, point2Z)) {\n          return false;\n        }\n      }\n      for (final Membership bound : moreBounds) {\n        if (!bound.isWithin(point2X, point2Y, point2Z)) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n            return false;\n    }\n  }
520	synchronized void abort(IndexWriter writer) {\n    assert !Thread.holdsLock(writer) : "IndexWriter lock should never be hold when aborting";\n    boolean success = false;\n    try {\n      deleteQueue.clear();\n      if (infoStream.isEnabled("DW")) {\n        infoStream.message("DW", "abort");\n      }\n      final int limit = perThreadPool.getActiveThreadStateCount();\n      for (int i = 0; i < limit; i++) {\n        final ThreadState perThread = perThreadPool.getThreadState(i);\n        perThread.lock();\n        try {\n          abortThreadState(perThread);\n        } finally {\n          perThread.unlock();\n        }\n      }\n      flushControl.abortPendingFlushes();\n      flushControl.waitForFlush();\n      success = true;\n    } finally {\n      if (infoStream.isEnabled("DW")) {\n        infoStream.message("DW", "done abort success=" + success);\n      }\n    }\n  }
521	public List<CharsRef> stem(char word[], int length) {    \n\n    if (dictionary.needsInputCleaning) {\n      scratchSegment.setLength(0);\n      scratchSegment.append(word, 0, length);\n      CharSequence cleaned = dictionary.cleanInput(scratchSegment, segment);\n      scratchBuffer = ArrayUtil.grow(scratchBuffer, cleaned.length());\n      length = segment.length();\n      segment.getChars(0, length, scratchBuffer, 0);\n      word = scratchBuffer;\n    }\n    \n    int caseType = caseOf(word, length);\n    if (caseType == UPPER_CASE) {\n            caseFoldTitle(word, length);\n      caseFoldLower(titleBuffer, length);\n      List<CharsRef> list = doStem(word, length, false);\n      list.addAll(doStem(titleBuffer, length, true));\n      list.addAll(doStem(lowerBuffer, length, true));\n      return list;\n    } else if (caseType == TITLE_CASE) {\n            caseFoldLower(word, length);\n      List<CharsRef> list = doStem(word, length, false);\n      list.addAll(doStem(lowerBuffer, length, true));\n      return list;\n    } else {\n            return doStem(word, length, false);\n    }\n  }
522	protected Query newGraphSynonymQuery(Iterator<Query> queries) {\n    BooleanQuery.Builder builder = new BooleanQuery.Builder();\n    while (queries.hasNext()) {\n      builder.add(queries.next(), BooleanClause.Occur.SHOULD);\n    }\n    BooleanQuery bq = builder.build();\n    if (bq.clauses().size() == 1) {\n      return bq.clauses().get(0).getQuery();\n    }\n    return bq;\n  }
523	private void addSharedExternalDependencies() {\n            Map<String,SortedSet<ExternalDependency>> sharedDependencies = new HashMap<>();\n    for (String module : interModuleExternalCompileScopeDependencies.keySet()) {\n      TreeSet<ExternalDependency> deps = new TreeSet<>();\n      sharedDependencies.put(module, deps);\n      Set<String> moduleDependencies = interModuleExternalCompileScopeDependencies.get(module);\n      if (null != moduleDependencies) {\n        for (String otherArtifactId : moduleDependencies) {\n          SortedSet<ExternalDependency> otherExtDeps = allExternalDependencies.get(otherArtifactId); \n          if (null != otherExtDeps) {\n            for (ExternalDependency otherDep : otherExtDeps) {\n              if ( ! otherDep.isTestDependency) {\n                deps.add(otherDep);\n              }\n            }\n          }\n        }\n      }\n    }\n    for (String module : interModuleExternalTestScopeDependencies.keySet()) {\n      SortedSet<ExternalDependency> deps = sharedDependencies.get(module);\n      if (null == deps) {\n        deps = new TreeSet<>();\n        sharedDependencies.put(module, deps);\n      }\n      Set<String> moduleDependencies = interModuleExternalTestScopeDependencies.get(module);\n      if (null != moduleDependencies) {\n        for (String otherArtifactId : moduleDependencies) {\n          int testScopePos = otherArtifactId.indexOf(":test");\n          boolean isTestScope = false;\n          if (-1 != testScopePos) {\n            otherArtifactId = otherArtifactId.substring(0, testScopePos);\n            isTestScope = true;\n          }\n          SortedSet<ExternalDependency> otherExtDeps = allExternalDependencies.get(otherArtifactId);\n          if (null != otherExtDeps) {\n            for (ExternalDependency otherDep : otherExtDeps) {\n              if (otherDep.isTestDependency == isTestScope) {\n                if (  ! deps.contains(otherDep)\n                   && (  null == allExternalDependencies.get(module)\n                      || ! allExternalDependencies.get(module).contains(otherDep))) {\n                                    ExternalDependency otherDepTestScope = new ExternalDependency\n                      (otherDep.groupId, otherDep.artifactId, otherDep.classifier, true, otherDep.isOptional);\n                  deps.add(otherDepTestScope);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    for (String module : sharedDependencies.keySet()) {\n      SortedSet<ExternalDependency> deps = allExternalDependencies.get(module);\n      if (null == deps) {\n        deps = new TreeSet<>();\n        allExternalDependencies.put(module, deps);\n      }\n      for (ExternalDependency dep : sharedDependencies.get(module)) {\n        String dependencyCoordinate = dep.groupId + ":" + dep.artifactId;\n        if (globalOptionalExternalDependencies.contains(dependencyCoordinate)\n            || (perModuleOptionalExternalDependencies.containsKey(module)\n                && perModuleOptionalExternalDependencies.get(module).contains(dependencyCoordinate))) {\n                    dep = new ExternalDependency(dep.groupId, dep.artifactId, dep.classifier, dep.isTestDependency, true);\n        }\n        deps.add(dep);\n      }\n    }\n  }
524	protected void resetSkip() {\n    if (skipBuffer == null) {\n      init();\n    } else {\n      for (int i = 0; i < skipBuffer.length; i++) {\n        skipBuffer[i].reset();\n      }\n    }      \n  }
525	private void countMultiValued(String field, List<MatchingDocs> matchingDocs) throws IOException {\n\n    for (MatchingDocs hits : matchingDocs) {\n      SortedNumericDocValues values = hits.context.reader().getSortedNumericDocValues(field);\n      if (values == null) {\n                continue;\n      }\n\n      NumericDocValues singleValues = DocValues.unwrapSingleton(values);\n\n      if (singleValues != null) {\n        countOneSegment(singleValues, hits);\n      } else {\n\n        DocIdSetIterator it = ConjunctionDISI.intersectIterators(\n                                 Arrays.asList(hits.bits.iterator(), values));\n      \n        for (int doc = it.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = it.nextDoc()) {\n          int limit = values.docValueCount();\n          totCount += limit;\n          for (int i = 0; i < limit; i++) {\n            increment(values.nextValue());\n          }\n        }\n      }\n    }\n  }
526	void waitForMerges() throws IOException {\n\n                mergeScheduler.merge(this, MergeTrigger.CLOSING, false);\n\n    synchronized (this) {\n      ensureOpen(false);\n      if (infoStream.isEnabled("IW")) {\n        infoStream.message("IW", "waitForMerges");\n      }\n\n      while (pendingMerges.size() > 0 || runningMerges.size() > 0) {\n        doWait();\n      }\n\n            assert 0 == mergingSegments.size();\n\n      if (infoStream.isEnabled("IW")) {\n        infoStream.message("IW", "waitForMerges done");\n      }\n    }\n  }
527	protected Query getPrefixQuery(String field, String termStr) throws ParseException\n  {\n    if (!allowLeadingWildcard && termStr.startsWith("*"))\n      throw new ParseException("'*' not allowed as first character in PrefixQuery");\n    BytesRef term = getAnalyzer().normalize(field, termStr);\n    Term t = new Term(field, term);\n    return newPrefixQuery(t);\n  }
528	private boolean isBreak(int lastType, int type) {\n    if ((type & lastType) != 0) {\n      return false;\n    }\n    \n    if (!splitOnCaseChange && isAlpha(lastType) && isAlpha(type)) {\n            return false;\n    } else if (isUpper(lastType) && isAlpha(type)) {\n            return false;\n    } else if (!splitOnNumerics && ((isAlpha(lastType) && isDigit(type)) || (isDigit(lastType) && isAlpha(type)))) {\n            return false;\n    }\n\n    return true;\n  }
529	private static int atMost(Automaton.Builder builder, String x, int n) {\n    int s = builder.createState();\n    if (x.length() == n) {\n      builder.setAccept(s, true);\n    } else {\n      char c = x.charAt(n);\n      builder.addTransition(s, atMost(builder, x, (char) n + 1), c);\n      if (c > '0') {\n        builder.addTransition(s, anyOfRightLength(builder, x, n + 1), '0', (char) (c - 1));\n      }\n    }\n    return s;\n  }
530	public synchronized void clear() {\n    updates.clear();\n    nextGen = 1;\n    finishedSegments.clear();\n    numTerms.set(0);\n    bytesUsed.set(0);\n  }
531	private Expression compileExpression(ClassLoader parent) throws ParseException {\n    final Map<String, Integer> externalsMap = new LinkedHashMap<>();\n    final ClassWriter classWriter = new ClassWriter(ClassWriter.COMPUTE_FRAMES | ClassWriter.COMPUTE_MAXS);\n\n    try {\n      generateClass(getAntlrParseTree(), classWriter, externalsMap);\n\n      final Class<? extends Expression> evaluatorClass = new Loader(parent)\n        .define(COMPILED_EXPRESSION_CLASS, classWriter.toByteArray());\n      final Constructor<? extends Expression> constructor = evaluatorClass.getConstructor(String.class, String[].class);\n\n      return constructor.newInstance(sourceText, externalsMap.keySet().toArray(new String[externalsMap.size()]));\n    } catch (RuntimeException re) {\n      if (re.getCause() instanceof ParseException) {\n        throw (ParseException)re.getCause();\n      }\n      throw re;\n    } catch (ReflectiveOperationException exception) {\n      throw new IllegalStateException("An internal error occurred attempting to compile the expression (" + sourceText + ").", exception);\n    }\n  }
532	protected ThreadState findLargestNonPendingWriter(\n      DocumentsWriterFlushControl control, ThreadState perThreadState) {\n    assert perThreadState.dwpt.getNumDocsInRAM() > 0;\n        ThreadState maxRamUsingThreadState = control.findLargestNonPendingWriter();\n    assert assertMessage("set largest ram consuming thread pending on lower watermark");\n    return maxRamUsingThreadState;\n  }
533	public static void printStats(TaxonomyReader r, PrintStream out, boolean printTree) throws IOException {\n    out.println(r.getSize() + " total categories.");\n\n    ChildrenIterator it = r.getChildren(TaxonomyReader.ROOT_ORDINAL);\n    int child;\n    while ((child = it.next()) != TaxonomyReader.INVALID_ORDINAL) {\n      ChildrenIterator chilrenIt = r.getChildren(child);\n      int numImmediateChildren = 0;\n      while (chilrenIt.next() != TaxonomyReader.INVALID_ORDINAL) {\n        numImmediateChildren++;\n      }\n      FacetLabel cp = r.getPath(child);\n      out.println("/" + cp.components[0] + ": " + numImmediateChildren + " immediate children; " + (1+countAllChildren(r, child)) + " total categories");\n      if (printTree) {\n        printAllChildren(out, r, child, "  ", 1);\n      }\n    }\n  }
534	private boolean initFirstTime() throws IOException {\n        checkedRpts = true;\n    placeFirstPositions();\n\n    LinkedHashMap<Term,Integer> rptTerms = repeatingTerms(); \n    hasRpts = !rptTerms.isEmpty();\n\n    if (hasRpts) {\n      rptStack = new PhrasePositions[numPostings];       ArrayList<ArrayList<PhrasePositions>> rgs = gatherRptGroups(rptTerms);\n      sortRptGroups(rgs);\n      if (!advanceRepeatGroups()) {\n        return false;       }\n    }\n    \n    fillQueue();\n    return true;   }
535	private ArrayList<FixedBitSet> ppTermsBitSets(PhrasePositions[] rpp, HashMap<Term,Integer> tord) {\n    ArrayList<FixedBitSet> bb = new ArrayList<>(rpp.length);\n    for (PhrasePositions pp : rpp) {\n      FixedBitSet b = new FixedBitSet(tord.size());\n      Integer ord;\n      for (Term t: pp.terms) {\n        if ((ord=tord.get(t))!=null) {\n          b.set(ord);\n        }\n      }\n      bb.add(b);\n    }\n    return bb;\n  }
536	protected static Map<String, String> parseMap(String body) {\n    Map<String, String> map = new HashMap<>();\n    StringTokenizer st = new StringTokenizer(body, " \n\t");\n    while (st.hasMoreTokens()) {\n      String a = st.nextToken();\n      int idx = a.indexOf('=');\n      if (idx > 0) {\n        String k = a.substring(0, idx);\n        String v = a.substring(idx + 1);\n        map.put(k, v);\n      } else {\n        map.put(a, a);\n      }\n    }\n    return map;\n  }
537	private static int convert(Automaton.Builder a, State s,\n      IdentityHashMap<State,Integer> visited) {\n\n    Integer converted = visited.get(s);\n    if (converted != null) {\n      return converted;\n    }\n    \n    converted = a.createState();\n    a.setAccept(converted, s.is_final);\n    \n    visited.put(s, converted);\n    int i = 0;\n    int[] labels = s.labels;\n    for (DaciukMihovAutomatonBuilder.State target : s.states) {\n      a.addTransition(converted, convert(a, target, visited), labels[i++]);\n    }\n    \n    return converted;\n  }
538	private static void findConflictsBeneathNode(IvyNodeElement node) {\n        Map<ModuleId,Collection<IvyNodeElement>> moduleRevisionMap = new HashMap<>();\n    IvyNodeElement[] deepDependencies = node.getDeepDependencies();\n    for (int i = 0; i < deepDependencies.length; i++) {\n      if (deepDependencies[i].isEvicted())\n        continue;\n\n      ModuleId moduleId = deepDependencies[i].getModuleRevisionId().getModuleId();\n      if (moduleRevisionMap.containsKey(moduleId)) {\n        Collection<IvyNodeElement> conflicts = moduleRevisionMap.get(moduleId);\n        conflicts.add(deepDependencies[i]);\n        for (Iterator<IvyNodeElement> iter = conflicts.iterator(); iter.hasNext();) {\n          IvyNodeElement conflict = iter.next();\n          conflict.setConflicts(conflicts);\n        }\n      } else {\n        List<IvyNodeElement> immutableMatchingSet = Arrays.asList(deepDependencies[i]);\n        moduleRevisionMap.put(moduleId, new HashSet<>(immutableMatchingSet));\n      }\n    }\n  }
539	static void readVIntBlock(IndexInput docIn, int[] docBuffer,\n      int[] freqBuffer, int num, boolean indexHasFreq) throws IOException {\n    if (indexHasFreq) {\n      for(int i=0;i<num;i++) {\n        final int code = docIn.readVInt();\n        docBuffer[i] = code >>> 1;\n        if ((code & 1) != 0) {\n          freqBuffer[i] = 1;\n        } else {\n          freqBuffer[i] = docIn.readVInt();\n        }\n      }\n    } else {\n      for(int i=0;i<num;i++) {\n        docBuffer[i] = docIn.readVInt();\n      }\n    }\n  }
540	static byte[] encode(double minLat, double minLon, double maxLat, double maxLon) {\n    byte[] b = new byte[BYTES * 4];\n    encode(minLat, minLon, b, 0);\n    encode(maxLat, maxLon, b, BYTES*2);\n    return b;\n  }
541	protected Facets buildFacetsResult(FacetsCollector drillDowns, FacetsCollector[] drillSideways,\n          String[] drillSidewaysDims) throws IOException {\n\n    Facets drillDownFacets;\n    Map<String, Facets> drillSidewaysFacets = new HashMap<>();\n\n    if (taxoReader != null) {\n      drillDownFacets = new FastTaxonomyFacetCounts(taxoReader, config, drillDowns);\n      if (drillSideways != null) {\n        for (int i = 0; i < drillSideways.length; i++) {\n          drillSidewaysFacets.put(drillSidewaysDims[i],\n                  new FastTaxonomyFacetCounts(taxoReader, config, drillSideways[i]));\n        }\n      }\n    } else {\n      drillDownFacets = new SortedSetDocValuesFacetCounts(state, drillDowns);\n      if (drillSideways != null) {\n        for (int i = 0; i < drillSideways.length; i++) {\n          drillSidewaysFacets.put(drillSidewaysDims[i], new SortedSetDocValuesFacetCounts(state, drillSideways[i]));\n        }\n      }\n    }\n\n    if (drillSidewaysFacets.isEmpty()) {\n      return drillDownFacets;\n    } else {\n      return new MultiFacets(drillSidewaysFacets, drillDownFacets);\n    }\n  }
542	public static Version parseLeniently(String version) throws ParseException {\n    String versionOrig = version;\n    version = version.toUpperCase(Locale.ROOT);\n    switch (version) {\n      case "LATEST":\n      case "LUCENE_CURRENT":\n        return LATEST;\n      default:\n        version = version\n          .replaceFirst("^LUCENE_(\\d+)_(\\d+)_(\\d+)$", "$1.$2.$3")\n          .replaceFirst("^LUCENE_(\\d+)_(\\d+)$", "$1.$2.0")\n          .replaceFirst("^LUCENE_(\\d)(\\d)$", "$1.$2.0");\n        try {\n          return parse(version);\n        } catch (ParseException pe) {\n          ParseException pe2 = new ParseException("failed to parse lenient version string \"" + versionOrig + "\": " + pe.getMessage(), 0);\n          pe2.initCause(pe);\n          throw pe2;\n        }\n    }\n  }
543	private synchronized void updateIOThrottle(OneMerge newMerge, MergeRateLimiter rateLimiter) throws IOException {\n    if (doAutoIOThrottle == false) {\n      return;\n    }\n\n    double mergeMB = bytesToMB(newMerge.estimatedMergeBytes);\n    if (mergeMB < MIN_BIG_MERGE_MB) {\n                  return;\n    }\n\n    long now = System.nanoTime();\n\n                boolean newBacklog = isBacklog(now, newMerge);\n\n    boolean curBacklog = false;\n\n    if (newBacklog == false) {\n      if (mergeThreads.size() > maxThreadCount) {\n                curBacklog = true;\n      } else {\n                for (MergeThread mergeThread : mergeThreads) {\n          if (isBacklog(now, mergeThread.merge)) {\n            curBacklog = true;\n            break;\n          }\n        }\n      }\n    }\n\n    double curMBPerSec = targetMBPerSec;\n\n    if (newBacklog) {\n            targetMBPerSec *= 1.20;\n      if (targetMBPerSec > MAX_MERGE_MB_PER_SEC) {\n        targetMBPerSec = MAX_MERGE_MB_PER_SEC;\n      }\n      if (verbose()) {\n        if (curMBPerSec == targetMBPerSec) {\n          message(String.format(Locale.ROOT, "io throttle: new merge backlog; leave IO rate at ceiling %.1f MB/sec", targetMBPerSec));\n        } else {\n          message(String.format(Locale.ROOT, "io throttle: new merge backlog; increase IO rate to %.1f MB/sec", targetMBPerSec));\n        }\n      }\n    } else if (curBacklog) {\n            if (verbose()) {\n        message(String.format(Locale.ROOT, "io throttle: current merge backlog; leave IO rate at %.1f MB/sec",\n                              targetMBPerSec));\n      }\n    } else {\n            targetMBPerSec /= 1.10;\n      if (targetMBPerSec < MIN_MERGE_MB_PER_SEC) {\n        targetMBPerSec = MIN_MERGE_MB_PER_SEC;\n      }\n      if (verbose()) {\n        if (curMBPerSec == targetMBPerSec) {\n          message(String.format(Locale.ROOT, "io throttle: no merge backlog; leave IO rate at floor %.1f MB/sec", targetMBPerSec));\n        } else {\n          message(String.format(Locale.ROOT, "io throttle: no merge backlog; decrease IO rate to %.1f MB/sec", targetMBPerSec));\n        }\n      }\n    }\n\n    double rate;\n\n    if (newMerge.maxNumSegments != -1) {\n      rate = forceMergeMBPerSec;\n    } else {\n      rate = targetMBPerSec;\n    }\n    rateLimiter.setMBPerSec(rate);\n    targetMBPerSecChanged();\n  }
544	void reset() {\n    position = -1;\n    length = 0;\n    numOverlap = 0;\n    offset = 0;\n    maxTermFrequency = 0;\n    uniqueTermCount = 0;\n    lastStartOffset = 0;\n    lastPosition = 0;\n  }
545	public long next() throws IOException {\n    if (ord == valueCount) {\n      throw new EOFException();\n    }\n    if (off == blockSize) {\n      refill();\n    }\n    final long value = values[off++];\n    ++ord;\n    return value;\n  }
546	public Document nextDoc() throws IOException {\n    String line;\n    synchronized(this) {\n      line = reader.readLine();\n      if (line == null) {\n                if (LuceneTestCase.VERBOSE) {\n          System.out.println("TEST: LineFileDocs: now rewind file...");\n        }\n        reader.close();\n        reader = null;\n        open(null);\n        line = reader.readLine();\n      }\n    }\n\n    DocState docState = threadDocs.get();\n    if (docState == null) {\n      docState = new DocState();\n      threadDocs.set(docState);\n    }\n\n    int spot = line.indexOf(SEP);\n    if (spot == -1) {\n      throw new RuntimeException("line: [" + line + "] is in an invalid format !");\n    }\n    int spot2 = line.indexOf(SEP, 1 + spot);\n    if (spot2 == -1) {\n      throw new RuntimeException("line: [" + line + "] is in an invalid format !");\n    }\n\n    docState.body.setStringValue(line.substring(1+spot2, line.length()));\n    final String title = line.substring(0, spot);\n    docState.title.setStringValue(title);\n    if (docState.titleDV != null) {\n      docState.titleDV.setBytesValue(new BytesRef(title));\n    }\n    docState.titleTokenized.setStringValue(title);\n    docState.date.setStringValue(line.substring(1+spot, spot2));\n    final int i = id.getAndIncrement();\n    docState.id.setStringValue(Integer.toString(i));\n    docState.idNum.setIntValue(i);\n    if (docState.idNumDV != null) {\n      docState.idNumDV.setLongValue(i);\n    }\n\n    if (random.nextInt(5) == 4) {\n            Document doc = new Document();\n      for(IndexableField field : docState.doc) {\n        doc.add(field);\n      }\n\n      if (random.nextInt(3) == 1) {\n        int x = random.nextInt(4);\n        doc.add(new IntPoint("docLength" + x, line.length()));\n      }\n\n      if (random.nextInt(3) == 1) {\n        int x = random.nextInt(4);\n        doc.add(new IntPoint("docTitleLength" + x, title.length()));\n      }\n\n      if (random.nextInt(3) == 1) {\n        int x = random.nextInt(4);\n        doc.add(new NumericDocValuesField("docLength" + x, line.length()));\n      }\n\n          }\n\n    return docState.doc;\n  }
547	private synchronized boolean setCurrentInfos(Set<String> completedMergeFiles) throws IOException {\n\n    IndexSearcher searcher = null;\n    SegmentInfos infos;\n    try {\n      searcher = mgr.acquire();\n      infos = ((StandardDirectoryReader) searcher.getIndexReader()).getSegmentInfos();\n    } finally {\n      if (searcher != null) {\n        mgr.release(searcher);\n      }\n    }\n    if (curInfos != null && infos.getVersion() == curInfos.getVersion()) {\n            message("top: skip switch to infos: version=" + infos.getVersion() + " is unchanged: " + infos.toString());\n      return false;\n    }\n\n    SegmentInfos oldInfos = curInfos;\n    writer.incRefDeleter(infos);\n    curInfos = infos;\n    if (oldInfos != null) {\n      writer.decRefDeleter(oldInfos);\n    }\n\n    message("top: switch to infos=" + infos.toString() + " version=" + infos.getVersion());\n\n        RAMOutputStream out = new RAMOutputStream(new RAMFile(), true);\n    infos.write(dir, out);\n    byte[] infosBytes = new byte[(int) out.getFilePointer()];\n    out.writeTo(infosBytes, 0);\n\n    Map<String,FileMetaData> filesMetaData = new HashMap<String,FileMetaData>();\n    for(SegmentCommitInfo info : infos) {\n      for(String fileName : info.files()) {\n        FileMetaData metaData = readLocalFileMetaData(fileName);\n                assert metaData != null;\n        assert filesMetaData.containsKey(fileName) == false;\n        filesMetaData.put(fileName, metaData);\n      }\n    }\n\n    lastFileMetaData = Collections.unmodifiableMap(filesMetaData);\n\n    message("top: set copyState primaryGen=" + primaryGen + " version=" + infos.getVersion() + " files=" + filesMetaData.keySet());\n    copyState = new CopyState(lastFileMetaData,\n                              infos.getVersion(), infos.getGeneration(), infosBytes, completedMergeFiles,\n                              primaryGen, curInfos);\n    return true;\n  }
548	@SuppressWarnings("unchecked")\n  public static <V> CharArrayMap<V> copy(final Map<?,? extends V> map) {\n    if(map == EMPTY_MAP)\n      return emptyMap();\n    if(map instanceof CharArrayMap) {\n      CharArrayMap<V> m = (CharArrayMap<V>) map;\n                  final char[][] keys = new char[m.keys.length][];\n      System.arraycopy(m.keys, 0, keys, 0, keys.length);\n      final V[] values = (V[]) new Object[m.values.length];\n      System.arraycopy(m.values, 0, values, 0, values.length);\n      m = new CharArrayMap<>(m);\n      m.keys = keys;\n      m.values = values;\n      return m;\n    }\n    return new CharArrayMap<>(map, false);\n  }
549	public void write(String baseDir) throws IOException {\n    final String baseName = getBaseFileName(baseDir);\n    writeDictionary(baseName + BinaryDictionary.DICT_FILENAME_SUFFIX);\n    writeTargetMap(baseName + BinaryDictionary.TARGETMAP_FILENAME_SUFFIX);\n    writePosDict(baseName + BinaryDictionary.POSDICT_FILENAME_SUFFIX);\n  }
550	public void liftUp(Row in, List<Row> nodes) {\n    Iterator<Cell> i = in.cells.values().iterator();\n    for (; i.hasNext();) {\n      Cell c = i.next();\n      if (c.ref >= 0) {\n        Row to = nodes.get(c.ref);\n        int sum = to.uniformCmd(changeSkip);\n        if (sum >= 0) {\n          if (sum == c.cmd) {\n            if (changeSkip) {\n              if (c.skip != to.uniformSkip + 1) {\n                continue;\n              }\n              c.skip = to.uniformSkip + 1;\n            } else {\n              c.skip = 0;\n            }\n            c.cnt += to.uniformCnt;\n            c.ref = -1;\n          } else if (c.cmd < 0) {\n            c.cnt = to.uniformCnt;\n            c.cmd = sum;\n            c.ref = -1;\n            if (changeSkip) {\n              c.skip = to.uniformSkip + 1;\n            } else {\n              c.skip = 0;\n            }\n          }\n        }\n      }\n    }\n  }
551	final void mergeInit(MergePolicy.OneMerge merge) throws IOException {\n\n        bufferedUpdatesStream.waitApplyForMerge(merge.segments);\n\n    boolean success = false;\n    try {\n      _mergeInit(merge);\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled("IW")) {\n          infoStream.message("IW", "hit exception in mergeInit");\n        }\n        mergeFinish(merge);\n      }\n    }\n  }
552	public void add(long l) throws IOException {\n    checkNotFinished();\n    if (off == values.length) {\n      flush();\n    }\n    values[off++] = l;\n    ++ord;\n  }
553	private static int calcRowsOrCols(double cellRange, double cellMin, double requestRange, double requestMin,\n                                    double worldRange) {\n    assert requestMin >= cellMin;\n        double range = (requestRange + (requestMin - cellMin));\n    if (range == 0) {\n      return 1;\n    }\n    final double intervals = Math.ceil(range / cellRange);\n    if (intervals > Integer.MAX_VALUE) {\n      return Integer.MAX_VALUE;    }\n        final long intervalsMax = Math.round(worldRange / cellRange);\n    if (intervalsMax > Integer.MAX_VALUE) {\n            return (int) intervals;\n    }\n    return Math.min((int)intervalsMax, (int)intervals);\n  }
554	final void callOpenHook(Path path, Closeable stream) throws IOException {\n    boolean success = false;\n    try {\n      onOpen(path, stream);\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(stream);\n      }\n    }\n  }
555	protected Query analyzeTerm(String field, TokenStream stream) throws IOException {\n    TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    \n    stream.reset();\n    if (!stream.incrementToken()) {\n      throw new AssertionError();\n    }\n    \n    return newTermQuery(new Term(field, termAtt.getBytesRef()));\n  }
556	public static void merge(Directory srcIndexDir, Directory srcTaxoDir, OrdinalMap map, IndexWriter destIndexWriter,\n      DirectoryTaxonomyWriter destTaxoWriter, FacetsConfig srcConfig) throws IOException {\n    \n        destTaxoWriter.addTaxonomy(srcTaxoDir, map);\n    int ordinalMap[] = map.getMap();\n    DirectoryReader reader = DirectoryReader.open(srcIndexDir);\n    try {\n      List<LeafReaderContext> leaves = reader.leaves();\n      int numReaders = leaves.size();\n      CodecReader wrappedLeaves[] = new CodecReader[numReaders];\n      for (int i = 0; i < numReaders; i++) {\n        wrappedLeaves[i] = SlowCodecReaderWrapper.wrap(new OrdinalMappingLeafReader(leaves.get(i).reader(), ordinalMap, srcConfig));\n      }\n      destIndexWriter.addIndexes(wrappedLeaves);\n      \n            destTaxoWriter.commit();\n      destIndexWriter.commit();\n    } finally {\n      reader.close();\n    }\n  }
557	private void setBytesRef(BytesRefBuilder spare, BytesRef result, int index) {\n    if (index < lastElement) {\n      int offset = offsets[index];\n      int length;\n      if (index == lastElement - 1) {\n        length = currentOffset - offset;\n      } else {\n        length = offsets[index + 1] - offset;\n      }\n      pool.setBytesRef(spare, result, offset, length);\n    } else {\n      throw new IndexOutOfBoundsException("index " + index + " must be less than the size: " + lastElement);\n    }\n  }
558	public BigDecimal parseMediumKanjiNumeral(NumberBuffer buffer) {\n    int i = buffer.position();\n\n    if (i >= buffer.length()) {\n      return null;\n    }\n\n    char c = buffer.charAt(i);\n    int power = exponents[c];\n\n    if (1 <= power && power <= 3) {\n      buffer.advance();\n      return BigDecimal.TEN.pow(power);\n    }\n\n    return null;\n  }
559	public static Expression compile(String sourceText, Map<String,Method> functions, ClassLoader parent) throws ParseException {\n    if (parent == null) {\n      throw new NullPointerException("A parent ClassLoader must be given.");\n    }\n    for (Method m : functions.values()) {\n      checkFunctionClassLoader(m, parent);\n      checkFunction(m);\n    }\n    return new JavascriptCompiler(sourceText, functions).compileExpression(parent);\n  }
560	public Map<String,String> readMapOfStrings() throws IOException {\n    int count = readVInt();\n    if (count == 0) {\n      return Collections.emptyMap();\n    } else if (count == 1) {\n      return Collections.singletonMap(readString(), readString());\n    } else {\n      Map<String,String> map = count > 10 ? new HashMap<>() : new TreeMap<>();\n      for (int i = 0; i < count; i++) {\n        final String key = readString();\n        final String val = readString();\n        map.put(key, val);\n      }\n      return Collections.unmodifiableMap(map);\n    }\n  }
561	protected final SpanQuery createSpanQuery(TokenStream in, String field) throws IOException {\n    TermToBytesRefAttribute termAtt = in.getAttribute(TermToBytesRefAttribute.class);\n    if (termAtt == null) {\n      return null;\n    }\n\n    List<SpanTermQuery> terms = new ArrayList<>();\n    while (in.incrementToken()) {\n      terms.add(new SpanTermQuery(new Term(field, termAtt.getBytesRef())));\n    }\n\n    if (terms.isEmpty()) {\n      return null;\n    } else if (terms.size() == 1) {\n      return terms.get(0);\n    } else {\n      return new SpanNearQuery(terms.toArray(new SpanTermQuery[0]), 0, true);\n    }\n  }
562	protected List<LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num,\n                                             CharSequence charSequence,\n                                             boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n    List<LookupResult> results = new ArrayList<>();\n    for (int i=0;i<hits.scoreDocs.length;i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      textDV.advance(fd.doc);\n      BytesRef term = textDV.binaryValue();\n      String text = term.utf8ToString();\n      long score = (Long) fd.fields[0];\n\n                  BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), "payloads");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n            int segment = ReaderUtil.subIndex(fd.doc, leaves);\n      SortedSetDocValues contextsDV = leaves.get(segment).reader().getSortedSetDocValues(CONTEXTS_FIELD_NAME);\n      Set<BytesRef> contexts;\n      if (contextsDV != null) {\n        contexts = new HashSet<BytesRef>();\n        int targetDocID = fd.doc - leaves.get(segment).docBase;\n        if (contextsDV.advance(targetDocID) == targetDocID) {\n          long ord;\n          while ((ord = contextsDV.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            BytesRef context = BytesRef.deepCopyOf(contextsDV.lookupOrd(ord));\n            contexts.add(context);\n          }\n        }\n      } else {\n        contexts = null;\n      }\n\n      LookupResult result;\n\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload, contexts);\n      } else {\n        result = new LookupResult(text, score, payload, contexts);\n      }\n\n      results.add(result);\n    }\n\n    return results;\n  }
563	private void unhyphenate() {\n    restoreState(savedState);\n    savedState = null;\n    \n    char term[] = termAttribute.buffer();\n    int length = hyphenated.length();\n    if (length > termAttribute.length()) {\n      term = termAttribute.resizeBuffer(length);\n    }\n    \n    hyphenated.getChars(0, length, term, 0);\n    termAttribute.setLength(length);\n    offsetAttribute.setOffset(offsetAttribute.startOffset(), lastEndOffset);\n    hyphenated.setLength(0);\n  }
564	protected void insertBalanced(String[] k, char[] v, int offset, int n) {\n    int m;\n    if (n < 1) {\n      return;\n    }\n    m = n >> 1;\n\n    insert(k[m + offset], v[m + offset]);\n    insertBalanced(k, v, offset, m);\n\n    insertBalanced(k, v, offset + m + 1, n - m - 1);\n  }
565	public int stemSuffix(char s[], int len) {\n    for (int i = 0; i < suffixes.length; i++) \n      if (endsWithCheckLength(s, len, suffixes[i]))\n        len = deleteN(s, len - suffixes[i].length, len, suffixes[i].length);\n    return len;\n  }
566	public synchronized void setMultiValued(String dimName, boolean v) {\n    DimConfig ft = fieldTypes.get(dimName);\n    if (ft == null) {\n      ft = new DimConfig();\n      fieldTypes.put(dimName, ft);\n    }\n    ft.multiValued = v;\n  }
567	public void addResult(int n, boolean isRelevant, long docNameExtractTime) {\n    if (Math.abs(numPoints+1 - n) > 1E-6) {\n      throw new IllegalArgumentException("point "+n+" illegal after "+numPoints+" points!");\n    }\n    if (isRelevant) {\n      numGoodPoints+=1;\n      recallPoints.add(new RecallPoint(n,numGoodPoints));\n      if (recallPoints.size()==1 && n<=5) {         mrr =  1.0 / n;\n      }\n    }\n    numPoints = n;\n    double p = numGoodPoints / numPoints;\n    if (isRelevant) {\n      pReleventSum += p;\n    }\n    if (n<pAt.length) {\n      pAt[n] = p;\n    }\n    recall = maxGoodPoints<=0 ? p : numGoodPoints/maxGoodPoints;\n    docNamesExtractTime += docNameExtractTime;\n  }
568	private BigDecimal parseMediumNumber(NumberBuffer buffer) {\n    BigDecimal sum = BigDecimal.ZERO;\n    BigDecimal result = parseMediumPair(buffer);\n\n    if (result == null) {\n      return null;\n    }\n\n    while (result != null) {\n      sum = sum.add(result);\n      result = parseMediumPair(buffer);\n    }\n\n    return sum;\n  }
569	private void handleFlush(DataInput topIn, DataOutput topOut, BufferedOutputStream bos) throws IOException {\n    Thread.currentThread().setName("flush");\n\n    int atLeastMarkerCount = topIn.readVInt();\n\n    int[] replicaTCPPorts;\n    int[] replicaIDs;\n    synchronized (this) {\n      replicaTCPPorts = this.replicaTCPPorts;\n      replicaIDs = this.replicaIDs;\n    }\n\n    message("now flush; " + replicaIDs.length + " replicas");\n\n    if (flushAndRefresh()) {\n      \n      verifyAtLeastMarkerCount(atLeastMarkerCount, null);\n \n                 long version = getCopyStateVersion();\n      message("send flushed version=" + version);\n      topOut.writeLong(version);\n      bos.flush();\n\n            for(int i=0;i<replicaIDs.length;i++) {\n        int replicaID = replicaIDs[i];\n        try (Connection c = new Connection(replicaTCPPorts[i])) {\n          message("send NEW_NRT_POINT to R" + replicaID + " at tcpPort=" + replicaTCPPorts[i]);\n          c.out.writeByte(SimpleReplicaNode.CMD_NEW_NRT_POINT);\n          c.out.writeVLong(version);\n          c.out.writeVLong(primaryGen);\n          c.out.writeInt(tcpPort);\n          c.flush();\n                                      } catch (Throwable t) {\n          message("top: failed to connect R" + replicaID + " for newNRTPoint; skipping: " + t.getMessage());\n        }\n      }\n    } else {\n            topOut.writeLong(-getCopyStateVersion());\n    }\n  }
570	private DisiWrapper popTail() {\n    assert tailSize > 0;\n    final DisiWrapper result = tail[0];\n    tail[0] = tail[--tailSize];\n    downHeapCost(tail, tailSize);\n    return result;\n  }
571	public List<SegToken> getShortPath() {\n    int current;\n    int nodeCount = getToCount();\n    List<PathNode> path = new ArrayList<>();\n    PathNode zeroPath = new PathNode();\n    zeroPath.weight = 0;\n    zeroPath.preNode = 0;\n    path.add(zeroPath);\n    for (current = 1; current <= nodeCount; current++) {\n      double weight;\n      List<SegTokenPair> edges = getToList(current);\n\n      double minWeight = Double.MAX_VALUE;\n      SegTokenPair minEdge = null;\n      for (SegTokenPair edge : edges) {\n        weight = edge.weight;\n        PathNode preNode = path.get(edge.from);\n        if (preNode.weight + weight < minWeight) {\n          minWeight = preNode.weight + weight;\n          minEdge = edge;\n        }\n      }\n      PathNode newNode = new PathNode();\n      newNode.weight = minWeight;\n      newNode.preNode = minEdge.from;\n      path.add(newNode);\n    }\n\n        int preNode, lastNode;\n    lastNode = path.size() - 1;\n    current = lastNode;\n    List<Integer> rpath = new ArrayList<>();\n    List<SegToken> resultPath = new ArrayList<>();\n\n    rpath.add(current);\n    while (current != 0) {\n      PathNode currentPathNode = path.get(current);\n      preNode = currentPathNode.preNode;\n      rpath.add(Integer.valueOf(preNode));\n      current = preNode;\n    }\n    for (int j = rpath.size() - 1; j >= 0; j--) {\n      Integer idInteger = rpath.get(j);\n      int id = idInteger.intValue();\n      SegToken t = segTokenList.get(id);\n      resultPath.add(t);\n    }\n    return resultPath;\n\n  }
572	public static int toChars(int[] src, int srcOff, int srcLen, char[] dest, int destOff) {\n    if (srcLen < 0) {\n      throw new IllegalArgumentException("srcLen must be >= 0");\n    }\n    int written = 0;\n    for (int i = 0; i < srcLen; ++i) {\n      written += Character.toChars(src[srcOff + i], dest, destOff + written);\n    }\n    return written;\n  }
573	public Hyphenation hyphenate(char[] w, int offset, int len,\n      int remainCharCount, int pushCharCount) {\n    int i;\n    char[] word = new char[len + 3];\n\n        char[] c = new char[2];\n    int iIgnoreAtBeginning = 0;\n    int iLength = len;\n    boolean bEndOfLetters = false;\n    for (i = 1; i <= len; i++) {\n      c[0] = w[offset + i - 1];\n      int nc = classmap.find(c, 0);\n      if (nc < 0) {         if (i == (1 + iIgnoreAtBeginning)) {\n                    iIgnoreAtBeginning++;\n        } else {\n                    bEndOfLetters = true;\n        }\n        iLength--;\n      } else {\n        if (!bEndOfLetters) {\n          word[i - iIgnoreAtBeginning] = (char) nc;\n        } else {\n          return null;\n        }\n      }\n    }\n    len = iLength;\n    if (len < (remainCharCount + pushCharCount)) {\n            return null;\n    }\n    int[] result = new int[len + 1];\n    int k = 0;\n\n        String sw = new String(word, 1, len);\n    if (stoplist.containsKey(sw)) {\n                  ArrayList<Object> hw = stoplist.get(sw);\n      int j = 0;\n      for (i = 0; i < hw.size(); i++) {\n        Object o = hw.get(i);\n                        if (o instanceof String) {\n          j += ((String) o).length();\n          if (j >= remainCharCount && j < (len - pushCharCount)) {\n            result[k++] = j + iIgnoreAtBeginning;\n          }\n        }\n      }\n    } else {\n            word[0] = '.';       word[len + 1] = '.';       word[len + 2] = 0;       byte[] il = new byte[len + 3];       for (i = 0; i < len + 1; i++) {\n        searchPatterns(word, i, il);\n      }\n\n                              for (i = 0; i < len; i++) {\n        if (((il[i + 1] & 1) == 1) && i >= remainCharCount\n            && i <= (len - pushCharCount)) {\n          result[k++] = i + iIgnoreAtBeginning;\n        }\n      }\n    }\n\n    if (k > 0) {\n            int[] res = new int[k+2];\n      System.arraycopy(result, 0, res, 1, k);\n                  res[0]=0;\n      res[k+1]=len;\n      return new Hyphenation(res);\n    } else {\n      return null;\n    }\n  }
574	public QualityQuery[] readQueries(BufferedReader reader) throws IOException {\n    ArrayList<QualityQuery> res = new ArrayList<>();\n    String line;\n    try {\n      while (null!=(line=reader.readLine())) {\n        line = line.trim();\n        if (line.startsWith("#")) {\n          continue;\n        }\n                int k = line.indexOf(":");\n        String id = line.substring(0,k).trim();\n                String qtext = line.substring(k+1).trim();\n                HashMap<String,String> fields = new HashMap<>();\n        fields.put(name,qtext);\n                QualityQuery topic = new QualityQuery(id,fields);\n        res.add(topic);\n      }\n    } finally {\n      reader.close();\n    }\n        QualityQuery qq[] = res.toArray(new QualityQuery[0]);\n    Arrays.sort(qq);\n    return qq;\n  }
575	private double[][] parsePoints(List<Object> o) throws ParseException {\n    double[] lats = new double[o.size()];\n    double[] lons = new double[o.size()];\n    for(int i=0;i<o.size();i++) {\n      Object point = o.get(i);\n      if (point instanceof List == false) {\n        throw newParseException("elements of coordinates array must [lat, lon] array, but got: " + point);\n      }\n      List<Object> pointList = (List<Object>) point;\n      if (pointList.size() != 2) {\n        throw newParseException("elements of coordinates array must [lat, lon] array, but got wrong element count: " + pointList);\n      }\n      if (pointList.get(0) instanceof Double == false) {\n        throw newParseException("elements of coordinates array must [lat, lon] array, but first element is not a Double: " + pointList.get(0));\n      }\n      if (pointList.get(1) instanceof Double == false) {\n        throw newParseException("elements of coordinates array must [lat, lon] array, but second element is not a Double: " + pointList.get(1));\n      }\n\n            lons[i] = ((Double) pointList.get(0)).doubleValue();\n      lats[i] = ((Double) pointList.get(1)).doubleValue();\n    }\n\n    return new double[][] {lats, lons};\n  }
576	protected synchronized boolean maybeStall(IndexWriter writer) {\n    long startStallTime = 0;\n    while (writer.hasPendingMerges() && mergeThreadCount() >= maxMergeCount) {\n\n                                                      \n      if (mergeThreads.contains(Thread.currentThread())) {\n                                return false;\n      }\n\n      if (verbose() && startStallTime == 0) {\n        message("    too many merges; stalling...");\n      }\n      startStallTime = System.currentTimeMillis();\n      doStall();\n    }\n\n    if (verbose() && startStallTime != 0) {\n      message("  stalled for " + (System.currentTimeMillis()-startStallTime) + " msec");\n    }\n\n    return true;\n  }
577	protected int split(byte[] minPackedValue, byte[] maxPackedValue, int[] parentSplits) {\n                int maxNumSplits = 0;\n    for (int numSplits : parentSplits) {\n      maxNumSplits = Math.max(maxNumSplits, numSplits);\n    }\n    for (int dim = 0; dim < numDims; ++dim) {\n      final int offset = dim * bytesPerDim;\n      if (parentSplits[dim] < maxNumSplits / 2 &&\n          StringHelper.compare(bytesPerDim, minPackedValue, offset, maxPackedValue, offset) != 0) {\n        return dim;\n      }\n    }\n\n        int splitDim = -1;\n    for(int dim=0;dim<numDims;dim++) {\n      NumericUtils.subtract(bytesPerDim, dim, maxPackedValue, minPackedValue, scratchDiff);\n      if (splitDim == -1 || StringHelper.compare(bytesPerDim, scratchDiff, 0, scratch1, 0) > 0) {\n        System.arraycopy(scratchDiff, 0, scratch1, 0, bytesPerDim);\n        splitDim = dim;\n      }\n    }\n\n        return splitDim;\n  }
578	public String[] suggestSimilar(String word, int numSug, IndexReader ir,\n      String field, SuggestMode suggestMode, float accuracy) throws IOException {\n        final IndexSearcher indexSearcher = obtainSearcher();\n    try {\n      if (ir == null || field == null) {\n        suggestMode = SuggestMode.SUGGEST_ALWAYS;\n      }\n      if (suggestMode == SuggestMode.SUGGEST_ALWAYS) {\n        ir = null;\n        field = null;\n      }\n\n      final int lengthWord = word.length();\n\n      final int freq = (ir != null && field != null) ? ir.docFreq(new Term(field, word)) : 0;\n      final int goalFreq = suggestMode==SuggestMode.SUGGEST_MORE_POPULAR ? freq : 0;\n            if (suggestMode==SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX && freq > 0) {\n        return new String[] { word };\n      }\n\n      BooleanQuery.Builder query = new BooleanQuery.Builder();\n      String[] grams;\n      String key;\n\n      for (int ng = getMin(lengthWord); ng <= getMax(lengthWord); ng++) {\n\n        key = "gram" + ng; \n        grams = formGrams(word, ng); \n        if (grams.length == 0) {\n          continue;         }\n\n        if (bStart > 0) {           add(query, "start" + ng, grams[0], bStart); \n        }\n        if (bEnd > 0) {           add(query, "end" + ng, grams[grams.length - 1], bEnd); \n        }\n        for (int i = 0; i < grams.length; i++) {\n          add(query, key, grams[i]);\n        }\n      }\n\n      int maxHits = 10 * numSug;\n\n        ScoreDoc[] hits = indexSearcher.search(query.build(), maxHits).scoreDocs;\n        SuggestWordQueue sugQueue = new SuggestWordQueue(numSug, comparator);\n\n            int stop = Math.min(hits.length, maxHits);\n      SuggestWord sugWord = new SuggestWord();\n      for (int i = 0; i < stop; i++) {\n\n        sugWord.string = indexSearcher.doc(hits[i].doc).get(F_WORD); \n                if (sugWord.string.equals(word)) {\n          continue;\n        }\n\n                sugWord.score = sd.getDistance(word,sugWord.string);\n        if (sugWord.score < accuracy) {\n          continue;\n        }\n\n        if (ir != null && field != null) {           sugWord.freq = ir.docFreq(new Term(field, sugWord.string));                     if ((suggestMode==SuggestMode.SUGGEST_MORE_POPULAR && goalFreq > sugWord.freq) || sugWord.freq < 1) {\n            continue;\n          }\n        }\n        sugQueue.insertWithOverflow(sugWord);\n        if (sugQueue.size() == numSug) {\n                    accuracy = sugQueue.top().score;\n        }\n        sugWord = new SuggestWord();\n      }\n\n            String[] list = new String[sugQueue.size()];\n      for (int i = sugQueue.size() - 1; i >= 0; i--) {\n        list[i] = sugQueue.pop().string;\n      }\n\n      return list;\n    } finally {\n      releaseSearcher(indexSearcher);\n    }\n  }
579	public static PostingsEnum getTermPositionsEnum(IndexReader r, String field, BytesRef term, int flags) throws IOException {\n    assert field != null;\n    assert term != null;\n    final Terms terms = getTerms(r, field);\n    if (terms != null) {\n      final TermsEnum termsEnum = terms.iterator();\n      if (termsEnum.seekExact(term)) {\n        return termsEnum.postings(null, flags);\n      }\n    }\n    return null;\n  }
580	protected Query getMultiFieldQuery(List<Query> queries) throws ParseException {\n    if (queries.isEmpty()) {\n      return null;     }\n    BooleanQuery.Builder query = newBooleanQuery();\n    for (Query sub : queries) {\n      query.add(sub, BooleanClause.Occur.SHOULD);\n    }\n    return query.build();\n  }
581	static String writeSpatialArgs(SpatialArgs args) {\n    StringBuilder str = new StringBuilder();\n    str.append(args.getOperation().getName());\n    str.append('(');\n    str.append(args.getShape().toString());\n    if (args.getDistErrPct() != null)\n      str.append(" distErrPct=").append(String.format(Locale.ROOT, "%.2f%%", args.getDistErrPct() * 100d));\n    if (args.getDistErr() != null)\n      str.append(" distErr=").append(args.getDistErr());\n    str.append(')');\n    return str.toString();\n  }
582	public static void rm(Path... locations) throws IOException {\n    LinkedHashMap<Path,Throwable> unremoved = rm(new LinkedHashMap<Path,Throwable>(), locations);\n    if (!unremoved.isEmpty()) {\n      StringBuilder b = new StringBuilder("Could not remove the following files (in the order of attempts):\n");\n      for (Map.Entry<Path,Throwable> kv : unremoved.entrySet()) {\n        b.append("   ")\n         .append(kv.getKey().toAbsolutePath())\n         .append(": ")\n         .append(kv.getValue())\n         .append("\n");\n      }\n      throw new IOException(b.toString());\n    }\n  }
583	public Automaton convert(Automaton utf32) {\n    if (utf32.getNumStates() == 0) {\n      return utf32;\n    }\n\n    int[] map = new int[utf32.getNumStates()];\n    Arrays.fill(map, -1);\n\n    List<Integer> pending = new ArrayList<>();\n    int utf32State = 0;\n    pending.add(utf32State);\n    utf8 = new Automaton.Builder();\n       \n    int utf8State = utf8.createState();\n\n    utf8.setAccept(utf8State, utf32.isAccept(utf32State));\n\n    map[utf32State] = utf8State;\n    \n    Transition scratch = new Transition();\n    \n    while (pending.size() != 0) {\n      utf32State = pending.remove(pending.size()-1);\n      utf8State = map[utf32State];\n      assert utf8State != -1;\n\n      int numTransitions = utf32.getNumTransitions(utf32State);\n      utf32.initTransition(utf32State, scratch);\n      for(int i=0;i<numTransitions;i++) {\n        utf32.getNextTransition(scratch);\n        int destUTF32 = scratch.dest;\n        int destUTF8 = map[destUTF32];\n        if (destUTF8 == -1) {\n          destUTF8 = utf8.createState();\n          utf8.setAccept(destUTF8, utf32.isAccept(destUTF32));\n          map[destUTF32] = destUTF8;\n          pending.add(destUTF32);\n        }\n\n                convertOneEdge(utf8State, destUTF8, scratch.min, scratch.max);\n      }\n    }\n\n    return utf8.finish();\n  }
584	public static void checkDocIds(String mes, int[] results, ScoreDoc[] hits) {\n    Assert.assertEquals(mes + " nr of hits", hits.length, results.length);\n    for (int i = 0; i < results.length; i++) {\n      Assert.assertEquals(mes + " doc nrs for hit " + i, results[i], hits[i].doc);\n    }\n  }
585	public static Automaton minimize(Automaton a, int maxDeterminizedStates) {\n    if (a.getNumStates() == 0 || (a.isAccept(0) == false && a.getNumTransitions(0) == 0)) {\n            return new Automaton();\n    }\n    a = Operations.determinize(a, maxDeterminizedStates);\n        if (a.getNumTransitions(0) == 1) {\n      Transition t = new Transition();\n      a.getTransition(0, 0, t);\n      if (t.dest == 0 && t.min == Character.MIN_CODE_POINT\n          && t.max == Character.MAX_CODE_POINT) {\n                return a;\n      }\n    }\n    a = Operations.totalize(a);\n    \n        final int[] sigma = a.getStartPoints();\n    final int sigmaLen = sigma.length, statesLen = a.getNumStates();\n\n    @SuppressWarnings({"rawtypes","unchecked"}) final ArrayList<Integer>[][] reverse =\n      (ArrayList<Integer>[][]) new ArrayList[statesLen][sigmaLen];\n    @SuppressWarnings({"rawtypes","unchecked"}) final HashSet<Integer>[] partition =\n      (HashSet<Integer>[]) new HashSet[statesLen];\n    @SuppressWarnings({"rawtypes","unchecked"}) final ArrayList<Integer>[] splitblock =\n      (ArrayList<Integer>[]) new ArrayList[statesLen];\n    final int[] block = new int[statesLen];\n    final StateList[][] active = new StateList[statesLen][sigmaLen];\n    final StateListNode[][] active2 = new StateListNode[statesLen][sigmaLen];\n    final LinkedList<IntPair> pending = new LinkedList<>();\n    final BitSet pending2 = new BitSet(sigmaLen*statesLen);\n    final BitSet split = new BitSet(statesLen), \n      refine = new BitSet(statesLen), refine2 = new BitSet(statesLen);\n    for (int q = 0; q < statesLen; q++) {\n      splitblock[q] = new ArrayList<>();\n      partition[q] = new HashSet<>();\n      for (int x = 0; x < sigmaLen; x++) {\n        active[q][x] = new StateList();\n      }\n    }\n        for (int q = 0; q < statesLen; q++) {\n      final int j = a.isAccept(q) ? 0 : 1;\n      partition[j].add(q);\n      block[q] = j;\n      for (int x = 0; x < sigmaLen; x++) {\n        final ArrayList<Integer>[] r = reverse[a.step(q, sigma[x])];\n        if (r[x] == null) {\n          r[x] = new ArrayList<>();\n        }\n        r[x].add(q);\n      }\n    }\n        for (int j = 0; j <= 1; j++) {\n      for (int x = 0; x < sigmaLen; x++) {\n        for (int q : partition[j]) {\n          if (reverse[q][x] != null) {\n            active2[q][x] = active[j][x].add(q);\n          }\n        }\n      }\n    }\n\n        for (int x = 0; x < sigmaLen; x++) {\n      final int j = (active[0][x].size <= active[1][x].size) ? 0 : 1;\n      pending.add(new IntPair(j, x));\n      pending2.set(x*statesLen + j);\n    }\n\n        int k = 2;\n        while (!pending.isEmpty()) {\n            final IntPair ip = pending.removeFirst();\n      final int p = ip.n1;\n      final int x = ip.n2;\n            pending2.clear(x*statesLen + p);\n            for (StateListNode m = active[p][x].first; m != null; m = m.next) {\n        final ArrayList<Integer> r = reverse[m.q][x];\n        if (r != null) {\n          for (int i : r) {\n            if (!split.get(i)) {\n              split.set(i);\n              final int j = block[i];\n              splitblock[j].add(i);\n              if (!refine2.get(j)) {\n                refine2.set(j);\n                refine.set(j);\n              }\n            }\n          }\n        }\n      }\n\n            for (int j = refine.nextSetBit(0); j >= 0; j = refine.nextSetBit(j+1)) {\n        final ArrayList<Integer> sb = splitblock[j];\n        if (sb.size() < partition[j].size()) {\n          final HashSet<Integer> b1 = partition[j];\n          final HashSet<Integer> b2 = partition[k];\n          for (int s : sb) {\n            b1.remove(s);\n            b2.add(s);\n            block[s] = k;\n            for (int c = 0; c < sigmaLen; c++) {\n              final StateListNode sn = active2[s][c];\n              if (sn != null && sn.sl == active[j][c]) {\n                sn.remove();\n                active2[s][c] = active[k][c].add(s);\n              }\n            }\n          }\n                    for (int c = 0; c < sigmaLen; c++) {\n            final int aj = active[j][c].size,\n              ak = active[k][c].size,\n              ofs = c*statesLen;\n            if (!pending2.get(ofs + j) && 0 < aj && aj <= ak) {\n              pending2.set(ofs + j);\n              pending.add(new IntPair(j, c));\n            } else {\n              pending2.set(ofs + k);\n              pending.add(new IntPair(k, c));\n            }\n          }\n          k++;\n        }\n        refine2.clear(j);\n        for (int s : sb) {\n          split.clear(s);\n        }\n        sb.clear();\n      }\n      refine.clear();\n    }\n\n    Automaton result = new Automaton();\n\n    Transition t = new Transition();\n\n    \n        int[] stateMap = new int[statesLen];\n    int[] stateRep = new int[k];\n\n    result.createState();\n\n        for (int n = 0; n < k; n++) {\n      \n      boolean isInitial = false;\n      for (int q : partition[n]) {\n        if (q == 0) {\n          isInitial = true;\n                    break;\n        }\n      }\n\n      int newState;\n      if (isInitial) {\n        newState = 0;\n      } else {\n        newState = result.createState();\n      }\n\n      \n      for (int q : partition[n]) {\n        stateMap[q] = newState;\n                result.setAccept(newState, a.isAccept(q));\n        stateRep[newState] = q;         }\n    }\n\n        for (int n = 0; n < k; n++) {\n      int numTransitions = a.initTransition(stateRep[n], t);\n      for(int i=0;i<numTransitions;i++) {\n        a.getNextTransition(t);\n                result.addTransition(n, stateMap[t.dest], t.min, t.max);\n      }\n    }\n    result.finishState();\n    \n    return Operations.removeDeadStates(result);\n  }
586	private static String[] formGrams(String text, int ng) {\n    int len = text.length();\n    String[] res = new String[len - ng + 1];\n    for (int i = 0; i < len - ng + 1; i++) {\n      res[i] = text.substring(i, i + ng);\n    }\n    return res;\n  }
587	private void interpolate() {\n    StringBuffer buffer = new StringBuffer();\n    for (Map.Entry<?,?> entry : entrySet()) {\n      buffer.setLength(0);\n      Matcher matcher = PROPERTY_REFERENCE_PATTERN.matcher(entry.getValue().toString());\n      while (matcher.find()) {\n        String interpolatedValue = getProperty(matcher.group(1));\n        if (null != interpolatedValue) {\n          matcher.appendReplacement(buffer, interpolatedValue);\n        }\n      }\n      matcher.appendTail(buffer);\n      setProperty((String) entry.getKey(), buffer.toString());\n    }\n  }
588	private TSTNode deleteNodeRecursion(TSTNode currentNode) {\n    if (currentNode == null) {\n      return null;\n    }\n    if (currentNode.relatives[TSTNode.EQKID] != null\n            || currentNode.data != null) {\n      return null;\n    }\n        TSTNode currentParent = currentNode.relatives[TSTNode.PARENT];\n    boolean lokidNull = currentNode.relatives[TSTNode.LOKID] == null;\n    boolean hikidNull = currentNode.relatives[TSTNode.HIKID] == null;\n    int childType;\n    if (currentParent.relatives[TSTNode.LOKID] == currentNode) {\n      childType = TSTNode.LOKID;\n    } else if (currentParent.relatives[TSTNode.EQKID] == currentNode) {\n      childType = TSTNode.EQKID;\n    } else if (currentParent.relatives[TSTNode.HIKID] == currentNode) {\n      childType = TSTNode.HIKID;\n    } else {\n      rootNode = null;\n      return null;\n    }\n    if (lokidNull && hikidNull) {\n      currentParent.relatives[childType] = null;\n      return currentParent;\n    }\n    if (lokidNull) {\n      currentParent.relatives[childType] = currentNode.relatives[TSTNode.HIKID];\n      currentNode.relatives[TSTNode.HIKID].relatives[TSTNode.PARENT] = currentParent;\n      return currentParent;\n    }\n    if (hikidNull) {\n      currentParent.relatives[childType] = currentNode.relatives[TSTNode.LOKID];\n      currentNode.relatives[TSTNode.LOKID].relatives[TSTNode.PARENT] = currentParent;\n      return currentParent;\n    }\n    int deltaHi = currentNode.relatives[TSTNode.HIKID].splitchar\n            - currentNode.splitchar;\n    int deltaLo = currentNode.splitchar\n            - currentNode.relatives[TSTNode.LOKID].splitchar;\n    int movingKid;\n    TSTNode targetNode;\n    if (deltaHi == deltaLo) {\n      if (Math.random() < 0.5) {\n        deltaHi++;\n      } else {\n        deltaLo++;\n      }\n    }\n    if (deltaHi > deltaLo) {\n      movingKid = TSTNode.HIKID;\n      targetNode = currentNode.relatives[TSTNode.LOKID];\n    } else {\n      movingKid = TSTNode.LOKID;\n      targetNode = currentNode.relatives[TSTNode.HIKID];\n    }\n    while (targetNode.relatives[movingKid] != null) {\n      targetNode = targetNode.relatives[movingKid];\n    }\n    targetNode.relatives[movingKid] = currentNode.relatives[movingKid];\n    currentParent.relatives[childType] = targetNode;\n    targetNode.relatives[TSTNode.PARENT] = currentParent;\n    if (!lokidNull) {\n      currentNode.relatives[TSTNode.LOKID] = null;\n    }\n    if (!hikidNull) {\n      currentNode.relatives[TSTNode.HIKID] = null;\n    }\n    return currentParent;\n  }
589	public synchronized void startUpdateThread(long intervalMillis, String threadName) {\n    ensureOpen();\n    if (updateThread != null && updateThread.isAlive()) {\n      throw new IllegalStateException(\n          "cannot start an update thread when one is running, must first call 'stopUpdateThread()'");\n    }\n    threadName = threadName == null ? INFO_STREAM_COMPONENT : "ReplicationThread-" + threadName;\n    updateThread = new ReplicationThread(intervalMillis);\n    updateThread.setName(threadName);\n    updateThread.start();\n        assert updateThread.isAlive() : "updateThread started but not alive?";\n  }
590	public int stem(char s[], int len) {\n    int numVowels = numVowels(s, len);\n    \n    for (int i = 0; i < affixes.length; i++) {\n      Affix affix = affixes[i];\n      if (numVowels > affix.vc && len >= affix.affix.length + 3 && endsWith(s, len, affix.affix)) {\n        len -= affix.affix.length;\n        return affix.palatalizes ? unpalatalize(s, len) : len;\n      }\n    }\n    \n    return len;\n  }
591	public static Plane constructNormalizedZPlane(final Vector... planePoints) {\n        double bestDistance = 0.0;\n    Vector bestPoint = null;\n    for (final Vector point : planePoints) {\n      final double pointDist = point.x * point.x + point.y * point.y;\n      if (pointDist > bestDistance) {\n        bestDistance = pointDist;\n        bestPoint = point;\n      }\n    }\n    return constructNormalizedZPlane(bestPoint.x, bestPoint.y);\n  }
592	public static Automaton removeDeadStates(Automaton a) {\n    int numStates = a.getNumStates();\n    BitSet liveSet = getLiveStates(a);\n\n    int[] map = new int[numStates];\n\n    Automaton result = new Automaton();\n        for(int i=0;i<numStates;i++) {\n      if (liveSet.get(i)) {\n        map[i] = result.createState();\n        result.setAccept(map[i], a.isAccept(i));\n      }\n    }\n\n    Transition t = new Transition();\n\n    for (int i=0;i<numStates;i++) {\n      if (liveSet.get(i)) {\n        int numTransitions = a.initTransition(i, t);\n                for(int j=0;j<numTransitions;j++) {\n          a.getNextTransition(t);\n          if (liveSet.get(t.dest)) {\n            result.addTransition(map[i], map[t.dest], t.min, t.max);\n          }\n        }\n      }\n    }\n\n    result.finishState();\n    assert hasDeadStates(result) == false;\n    return result;\n  }
593	private static Edge createTree(Edge edges[], int low, int high) {\n    if (low > high) {\n      return null;\n    }\n        int mid = (low + high) >>> 1;\n    Edge newNode = edges[mid];\n        newNode.left = createTree(edges, low, mid - 1);\n    newNode.right = createTree(edges, mid + 1, high);\n        if (newNode.left != null) {\n      newNode.max = Math.max(newNode.max, newNode.left.max);\n    }\n    if (newNode.right != null) {\n      newNode.max = Math.max(newNode.max, newNode.right.max);\n    }\n    return newNode;\n  }
594	public synchronized boolean waitForGeneration(long targetGen, int maxMS) throws InterruptedException {\n    if (targetGen > searchingGen) {\n                        reopenLock.lock();\n\n                  waitingGen = Math.max(waitingGen, targetGen);\n\n      try {\n        reopenCond.signal();\n      } finally {\n        reopenLock.unlock();\n      }\n\n      long startMS = System.nanoTime()/1000000;\n\n      while (targetGen > searchingGen) {\n        if (maxMS < 0) {\n          wait();\n        } else {\n          long msLeft = (startMS + maxMS) - System.nanoTime()/1000000;\n          if (msLeft <= 0) {\n            return false;\n          } else {\n            wait(msLeft);\n          }\n        }\n      }\n    }\n\n    return true;\n  }
595	public synchronized void resetInputs() throws IOException {\n    source.printStatistics("docs");\n        setConfig(config, source);\n    source.resetInputs();\n    numDocsCreated.set(0);\n    resetLeftovers();\n  }
596	protected Query newFuzzyQuery(String text, int fuzziness) {\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    for (Map.Entry<String,Float> entry : weights.entrySet()) {\n      final String fieldName = entry.getKey();\n      final BytesRef term = getAnalyzer().normalize(fieldName, text);\n      Query q = new FuzzyQuery(new Term(fieldName, term), fuzziness);\n      float boost = entry.getValue();\n      if (boost != 1f) {\n        q = new BoostQuery(q, boost);\n      }\n      bq.add(q, BooleanClause.Occur.SHOULD);\n    }\n    return simplify(bq.build());\n  }
597	private Query makeXDL(boolean crossedDateLine, Query query) {\n    if (!ctx.isGeo()) {\n      assert !crossedDateLine;\n      return query;\n    }\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    bq.add(this.makeXDL(crossedDateLine), BooleanClause.Occur.MUST);\n    bq.add(query, BooleanClause.Occur.MUST);\n    return bq.build();\n  }
598	public synchronized MergePolicy.OneMerge getNextMerge() {\n    if (pendingMerges.size() == 0) {\n      return null;\n    } else {\n            MergePolicy.OneMerge merge = pendingMerges.removeFirst();\n      runningMerges.add(merge);\n      return merge;\n    }\n  }
599	private List<Lock> acquireWriteLocks(Directory... dirs) throws IOException {\n    List<Lock> locks = new ArrayList<>(dirs.length);\n    for(int i=0;i<dirs.length;i++) {\n      boolean success = false;\n      try {\n        Lock lock = dirs[i].obtainLock(WRITE_LOCK_NAME);\n        locks.add(lock);\n        success = true;\n      } finally {\n        if (success == false) {\n                              IOUtils.closeWhileHandlingException(locks);\n        }\n      }\n    }\n    return locks;\n  }
600	public IndexSearcher createSearcher() {\n    MemoryIndexReader reader = new MemoryIndexReader();\n    IndexSearcher searcher = new IndexSearcher(reader);     searcher.setSimilarity(normSimilarity);\n    searcher.setQueryCache(null);\n    return searcher;\n  }
601	public static GeoPolygon makeLargeGeoPolygon(final PlanetModel planetModel,\n    final List<PolygonDescription> shapesList) {\n      \n            \n    final List<List<GeoPoint>> pointsList = new ArrayList<>();\n    \n    BestShape testPointShape = null;\n    for (final PolygonDescription shape : shapesList) {\n                        testPointShape = convertPolygon(pointsList, shape, testPointShape, true);\n    }\n    \n        if (testPointShape == null) {\n      throw new IllegalArgumentException("couldn't find a non-degenerate polygon for in-set determination");\n    }\n    \n            final Random generator = new Random(1234);\n    for (int counter = 0; counter < 1000000; counter++) {\n            final GeoPoint pole = pickPole(generator, planetModel, testPointShape.points);\n            final Boolean isPoleInside = isInsidePolygon(pole, testPointShape.points);\n      if (isPoleInside != null) {\n                if (isPoleInside == testPointShape.poleMustBeInside) {\n          return new GeoComplexPolygon(planetModel, pointsList, pole, isPoleInside);\n        } else {\n          return new GeoComplexPolygon(planetModel, pointsList, new GeoPoint(-pole.x, -pole.y, -pole.z), !isPoleInside);\n        }\n      }\n          }\n    throw new IllegalArgumentException("cannot find a point that is inside the polygon "+testPointShape);\n\n  }
602	public int numDeletedDocs(SegmentCommitInfo info) {\n    ensureOpen(false);\n    int delCount = info.getDelCount();\n\n    final ReadersAndUpdates rld = readerPool.get(info, false);\n    if (rld != null) {\n      delCount += rld.getPendingDeleteCount();\n    }\n    return delCount;\n  }
603	public Bounds addXValue(final double x) {\n    final double small = x - FUDGE_FACTOR;\n    if (minX == null || minX > small) {\n      minX = new Double(small);\n    }\n    final double large = x + FUDGE_FACTOR;\n    if (maxX == null || maxX < large) {\n      maxX = new Double(large);\n    }\n    return this;\n  }
604	static void indexDoc(IndexWriter writer, Path file, long lastModified) throws IOException {\n    try (InputStream stream = Files.newInputStream(file)) {\n            Document doc = new Document();\n      \n                              Field pathField = new StringField("path", file.toString(), Field.Store.YES);\n      doc.add(pathField);\n      \n                                                doc.add(new LongPoint("modified", lastModified));\n      \n                              doc.add(new TextField("contents", new BufferedReader(new InputStreamReader(stream, StandardCharsets.UTF_8))));\n      \n      if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n                System.out.println("adding " + file);\n        writer.addDocument(doc);\n      } else {\n                                System.out.println("updating " + file);\n        writer.updateDocument(new Term("path", file.toString()), doc);\n      }\n    }\n  }
605	private void flushUnigram() {\n    clearAttributes();\n    char termBuffer[] = termAtt.resizeBuffer(2);     int len = Character.toChars(buffer[index], termBuffer, 0);\n    termAtt.setLength(len);\n    offsetAtt.setOffset(startOffset[index], endOffset[index]);\n    typeAtt.setType(SINGLE_TYPE);\n    index++;\n  }
606	public Pair<A,B> newPair(A a, B b) {\n    if (a.equals(outputs1.getNoOutput())) {\n      a = outputs1.getNoOutput();\n    }\n    if (b.equals(outputs2.getNoOutput())) {\n      b = outputs2.getNoOutput();\n    }\n\n    if (a == outputs1.getNoOutput() && b == outputs2.getNoOutput()) {\n      return NO_OUTPUT;\n    } else {\n      final Pair<A,B> p = new Pair<>(a, b);\n      assert valid(p);\n      return p;\n    }\n  }
607	public final String[] getBestFragments(\n    TokenStream tokenStream,\n    String text,\n    int maxNumFragments)\n    throws IOException, InvalidTokenOffsetsException\n  {\n    maxNumFragments = Math.max(1, maxNumFragments); \n    TextFragment[] frag =getBestTextFragments(tokenStream,text, true,maxNumFragments);\n\n        ArrayList<String> fragTexts = new ArrayList<>();\n    for (int i = 0; i < frag.length; i++)\n    {\n      if ((frag[i] != null) && (frag[i].getScore() > 0))\n      {\n        fragTexts.add(frag[i].toString());\n      }\n    }\n    return fragTexts.toArray(new String[0]);\n  }
608	public synchronized long addDocument(String id, Document doc) throws IOException {\n    assert buffer.getFilePointer() == 0;\n    buffer.writeByte(OP_ADD_DOCUMENT);\n    encode(id, doc);\n    return flushBuffer();\n  }
609	@SuppressWarnings("fallthrough")\n  public static long round(long time, Resolution resolution) {\n    final Calendar calInstance = TL_CAL.get();\n    calInstance.setTimeInMillis(time);\n    \n    switch (resolution) {\n            case YEAR:\n        calInstance.set(Calendar.MONTH, 0);\n      case MONTH:\n        calInstance.set(Calendar.DAY_OF_MONTH, 1);\n      case DAY:\n        calInstance.set(Calendar.HOUR_OF_DAY, 0);\n      case HOUR:\n        calInstance.set(Calendar.MINUTE, 0);\n      case MINUTE:\n        calInstance.set(Calendar.SECOND, 0);\n      case SECOND:\n        calInstance.set(Calendar.MILLISECOND, 0);\n      case MILLISECOND:\n                break;\n      default:\n        throw new IllegalArgumentException("unknown resolution " + resolution);\n    }\n    return calInstance.getTimeInMillis();\n  }
610	private int findInTable(short knownHashIndex, char[] charArray) {\n    if (charArray == null || charArray.length == 0)\n      return -1;\n\n    char[][] items = wordItem_charArrayTable[wordIndexTable[knownHashIndex]];\n    int start = 0, end = items.length - 1;\n    int mid = (start + end) / 2, cmpResult;\n\n        while (start <= end) {\n      cmpResult = Utility.compareArray(items[mid], 0, charArray, 1);\n\n      if (cmpResult == 0)\n        return mid;      else if (cmpResult < 0)\n        start = mid + 1;\n      else if (cmpResult > 0)\n        end = mid - 1;\n\n      mid = (start + end) / 2;\n    }\n    return -1;\n  }
611	protected Query analyzePhrase(String field, TokenStream stream, int slop) throws IOException {\n    PhraseQuery.Builder builder = new PhraseQuery.Builder();\n    builder.setSlop(slop);\n    \n    TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class);\n    int position = -1;    \n    \n    stream.reset();\n    while (stream.incrementToken()) {\n      if (enablePositionIncrements) {\n        position += posIncrAtt.getPositionIncrement();\n      } else {\n        position += 1;\n      }\n      builder.add(new Term(field, termAtt.getBytesRef()), position);\n    }\n\n    return builder.build();\n  }
612	public double getLongitude() {\n    double lon = this.longitude;    if (lon == Double.NEGATIVE_INFINITY) {\n      if (Math.abs(x) < MINIMUM_RESOLUTION && Math.abs(y) < MINIMUM_RESOLUTION)\n        this.longitude = lon = 0.0;\n      else\n        this.longitude = lon = Math.atan2(y,x);\n    }\n    return lon;\n  }
613	static SerializableObject readObject(final InputStream inputStream, final Class<?> clazz) throws IOException {\n    try {\n            final Constructor<?> c = clazz.getDeclaredConstructor(InputStream.class);\n            final Object object = c.newInstance(inputStream);\n            if (!(object instanceof SerializableObject)) {\n        throw new IOException("Object "+clazz.getName()+" does not implement SerializableObject");\n      }\n      return (SerializableObject)object;\n    } catch (InstantiationException e) {\n      throw new IOException("Instantiation exception for class "+clazz.getName()+": "+e.getMessage(), e);\n    } catch (IllegalAccessException e) {\n      throw new IOException("Illegal access creating class "+clazz.getName()+": "+e.getMessage(), e);\n    } catch (NoSuchMethodException e) {\n      throw new IOException("No such method exception for class "+clazz.getName()+": "+e.getMessage(), e);\n    } catch (InvocationTargetException e) {\n      throw new IOException("Exception instantiating class "+clazz.getName()+": "+e.getMessage(), e);\n    }\n\n  }
614	public static BytesRef toBytesRef(IntsRef input, BytesRefBuilder scratch) {\n    scratch.grow(input.length);\n    for(int i=0;i<input.length;i++) {\n      int value = input.ints[i+input.offset];\n            assert value >= Byte.MIN_VALUE && value <= 255: "value " + value + " doesn't fit into byte";\n      scratch.setByteAt(i, (byte) value);\n    }\n    scratch.setLength(input.length);\n    return scratch.get();\n  }
615	public int fillCounts(int[] counts) {\n        missingCount = 0;\n    leafUpto = 0;\n    rollup(root, counts, false);\n    return missingCount;\n  }
616	private BooleanQuery addMinShouldMatchToBoolean(BooleanQuery query, float fraction) {\n    BooleanQuery.Builder builder = new BooleanQuery.Builder();\n    builder.setMinimumNumberShouldMatch((int) (fraction * query.clauses().size()));\n    for (BooleanClause clause : query) {\n      builder.add(clause);\n    }\n\n    return builder.build();\n  }
617	private boolean collectVersionConflictsToIgnore() {\n    log("Checking for orphans in " + ignoreConflictsFile.getName(), verboseLevel);\n    boolean orphansFound = false;\n    InterpolatedProperties properties = new InterpolatedProperties();\n    try (InputStream inputStream = new FileInputStream(ignoreConflictsFile);\n         Reader reader = new InputStreamReader(inputStream, StandardCharsets.UTF_8)) {\n      properties.load(reader);\n    } catch (IOException e) {\n      throw new BuildException("Exception reading " + ignoreConflictsFile + ": " + e.toString(), e);\n    }\n    for (Object obj : properties.keySet()) {\n      String coordinate = (String)obj;\n      if (COORDINATE_KEY_PATTERN.matcher(coordinate).matches()) {\n        if ( ! directDependencies.containsKey(coordinate)) {\n          orphansFound = true;\n          log("ORPHAN coordinate key '" + coordinate + "' in " + ignoreConflictsFile.getName()\n                  + " is not found in " + centralizedVersionsFile.getName(),\n              Project.MSG_ERR);\n        } else {\n          String versionsToIgnore = properties.getProperty(coordinate);\n          List<String> ignore = Arrays.asList(versionsToIgnore.trim().split("\\s*,\\s*|\\s+"));\n          ignoreConflictVersions.put(coordinate, new HashSet<>(ignore));\n        }\n      }\n    }\n    return ! orphansFound;\n  }
618	public int stem(char s[], int len) {\n    len = removeCase(s, len);\n    len = removePossessives(s, len);\n    if (len > 0) {\n      len = normalize(s, len);\n    }\n    return len;\n  }
619	private static final CharSequence escapeWhiteChar(CharSequence str,\n      Locale locale) {\n    if (str == null || str.length() == 0)\n      return str;\n\n    CharSequence buffer = str;\n\n    for (int i = 0; i < escapableWhiteChars.length; i++) {\n      buffer = replaceIgnoreCase(buffer, escapableWhiteChars[i].toLowerCase(locale),\n          "\\", locale);\n    }\n    return buffer;\n  }
